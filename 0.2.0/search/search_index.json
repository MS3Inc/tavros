{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Tavros \u00b6 Tavros is a cost-effective, cloud-native, and modular integration platform composed of best-of-breed, and seamlessly integrated open-source components. Ansible Collection \u00b6 The objective of the ms3_inc.tavros Ansible Collection is to provide the necessary Ansible Playbooks to configure, provision, and manage the Tavros Kubernetes Cluster and supported components. Provision Playbook \u00b6 The provision playbook provisions a Kubernetes cluster and configures Tavros's platform components, application environments, etc. All of the components are configurable through Ansible variables or the default configuration can be chosen. See the provision playbook's documentation for more information. Supported Platform Components \u00b6 Concern Component Version Platform GitOps Flux v2 0.10.0 Platform GitOps Sealed Secrets 0.15.0 API Gateway and Manager Kong 2.3.3 API Portal Kong Enterprise Edition 2.3.3 Service Mesh Kuma 1.2.0 Identity and Access Management Keycloak 12.0.4 Artifact Management Nexus Repository Manager 3.28.1 Continuous Delivery Jenkins 2.277.4 Observability Elastic Cloud 7.13.4 Observability Jaeger 1.22.0 Static Code Qualitative Analysis Sonarqube 8.5 Roadmap \u00b6 The Tavros team will maintain an up to date roadmap for major and minor releases through its Milestones . For items that are not yet targeting a milestone, you can see our Backlog Architectural Decision Log \u00b6 This project documents significant architectural decisions in MADR, a lightweight format for recording architectural decisions in Markdown. See our Architectural Decision Log .","title":"About"},{"location":"#tavros","text":"Tavros is a cost-effective, cloud-native, and modular integration platform composed of best-of-breed, and seamlessly integrated open-source components.","title":"Tavros"},{"location":"#ansible-collection","text":"The objective of the ms3_inc.tavros Ansible Collection is to provide the necessary Ansible Playbooks to configure, provision, and manage the Tavros Kubernetes Cluster and supported components.","title":"Ansible Collection"},{"location":"#provision-playbook","text":"The provision playbook provisions a Kubernetes cluster and configures Tavros's platform components, application environments, etc. All of the components are configurable through Ansible variables or the default configuration can be chosen. See the provision playbook's documentation for more information.","title":"Provision Playbook"},{"location":"#supported-platform-components","text":"Concern Component Version Platform GitOps Flux v2 0.10.0 Platform GitOps Sealed Secrets 0.15.0 API Gateway and Manager Kong 2.3.3 API Portal Kong Enterprise Edition 2.3.3 Service Mesh Kuma 1.2.0 Identity and Access Management Keycloak 12.0.4 Artifact Management Nexus Repository Manager 3.28.1 Continuous Delivery Jenkins 2.277.4 Observability Elastic Cloud 7.13.4 Observability Jaeger 1.22.0 Static Code Qualitative Analysis Sonarqube 8.5","title":"Supported Platform Components"},{"location":"#roadmap","text":"The Tavros team will maintain an up to date roadmap for major and minor releases through its Milestones . For items that are not yet targeting a milestone, you can see our Backlog","title":"Roadmap"},{"location":"#architectural-decision-log","text":"This project documents significant architectural decisions in MADR, a lightweight format for recording architectural decisions in Markdown. See our Architectural Decision Log .","title":"Architectural Decision Log"},{"location":"adr/","text":"Architectural Decision Records \u00b6 This log lists the architectural decisions for Tavros. ADR-0000 - Prefer Proven FOSS Components with Optional Support for Licensed Derivatives ADR-0001 - Apache Camel as the Default Integration Framework ADR-0002 - Spring Boot as the Base Application Framework ADR-0003 - DataSonnet as the Default Data Transformation Language ADR-0004 - OpenTracing for In-Process Tracing API ADR-0005 - Kubernetes as the Computing Platform ADR-0006 - Kops to Provision a Kubernetes Cluster ADR-0007 - Flux to Provide Platform GitOps ADR-0008 - Kubeseal to Securely Manage Secrets in GitOps ADR-0009 - Keycloak for Indetity and Access Management ADR-0010 - Kong as Kubernetes Ingress and API gateway ADR-0011 - PostgreSQL as the Platform's Default Database ADR-0012 - Gitea for a Lightweight Git Server ADR-0013 - Kuma for Service Mesh ADR-0014 - Jenkins for Continuous Integration ADR-0015 - Sonarqube for Application Static Code Analysis ADR-0016 - Elastic Cloud for Observability Data Aggregation and Visualization ADR-0017 - Jaeger for Tracing with Elasticsearch Backend ADR-0018 - Nexus Repository Manager for Artifact Management ADR-0019 - Prefer Daemonsets Over Sidecars ADR-0020 - Spring Cloud Config for Application Configuration Management ADR-0021 - Prefer Kong Enterprise Edition ADR-0022 - Use Ansible as the Provisioning Engine ADR-0023 - Helm and Operators for Component Installation and Management ADR-0024 - Use Ansible Collection to Structure and Package Ansible Code ADR-0025 - Setup Sandbox and Production Kuma Meshes and Kong Ingress Controllers ADR-0026 - Setup Sandbox and Production Keycloak Realms ADR-0027 - cert-manager for Certificate Management ADR-0028 - Use Markdown Architectural Decision Records ADR-0029 - Tavros as a Single Tenant Platform For new ADRs, please use template.md as basis. More information on MADR is available at https://adr.github.io/madr/ . General information about architectural decision records is available at https://adr.github.io/ .","title":"Overview"},{"location":"adr/#architectural-decision-records","text":"This log lists the architectural decisions for Tavros. ADR-0000 - Prefer Proven FOSS Components with Optional Support for Licensed Derivatives ADR-0001 - Apache Camel as the Default Integration Framework ADR-0002 - Spring Boot as the Base Application Framework ADR-0003 - DataSonnet as the Default Data Transformation Language ADR-0004 - OpenTracing for In-Process Tracing API ADR-0005 - Kubernetes as the Computing Platform ADR-0006 - Kops to Provision a Kubernetes Cluster ADR-0007 - Flux to Provide Platform GitOps ADR-0008 - Kubeseal to Securely Manage Secrets in GitOps ADR-0009 - Keycloak for Indetity and Access Management ADR-0010 - Kong as Kubernetes Ingress and API gateway ADR-0011 - PostgreSQL as the Platform's Default Database ADR-0012 - Gitea for a Lightweight Git Server ADR-0013 - Kuma for Service Mesh ADR-0014 - Jenkins for Continuous Integration ADR-0015 - Sonarqube for Application Static Code Analysis ADR-0016 - Elastic Cloud for Observability Data Aggregation and Visualization ADR-0017 - Jaeger for Tracing with Elasticsearch Backend ADR-0018 - Nexus Repository Manager for Artifact Management ADR-0019 - Prefer Daemonsets Over Sidecars ADR-0020 - Spring Cloud Config for Application Configuration Management ADR-0021 - Prefer Kong Enterprise Edition ADR-0022 - Use Ansible as the Provisioning Engine ADR-0023 - Helm and Operators for Component Installation and Management ADR-0024 - Use Ansible Collection to Structure and Package Ansible Code ADR-0025 - Setup Sandbox and Production Kuma Meshes and Kong Ingress Controllers ADR-0026 - Setup Sandbox and Production Keycloak Realms ADR-0027 - cert-manager for Certificate Management ADR-0028 - Use Markdown Architectural Decision Records ADR-0029 - Tavros as a Single Tenant Platform For new ADRs, please use template.md as basis. More information on MADR is available at https://adr.github.io/madr/ . General information about architectural decision records is available at https://adr.github.io/ .","title":"Architectural Decision Records"},{"location":"adr/0000-prefer-proven-foss-components-with-optional-support-for-licensed-derivatives/","text":"Prefer Proven FOSS Components with Optional Support for Licensed Derivatives \u00b6 Status: accepted Deciders: @k2merlinsix, @jam01 Date: 2020-08 Context and Problem Statement \u00b6 Should we include licensed or non-FOSS components in the Tavros platform for a given component or component's feature? Decision Drivers \u00b6 Total cost of ownership Providing the necessary features for a competitive product Decision Outcome \u00b6 We will prioritize FOSS components, while providing optional support for paid or licensed derivatives, e.g.: Elastic Stack Open Source vs Enterprise subscription, Apache Camel vs JBoss Fuse, etc. Ultimately total cost of ownership will be the deciding factor for our customers when comparing to established alternatives. There are many FOSS components that address different concerns that we can incorporate and still provide a best-in-class platform. Negative Consequences \u00b6 High number of components to configure and integrate","title":"ADR-0000"},{"location":"adr/0000-prefer-proven-foss-components-with-optional-support-for-licensed-derivatives/#prefer-proven-foss-components-with-optional-support-for-licensed-derivatives","text":"Status: accepted Deciders: @k2merlinsix, @jam01 Date: 2020-08","title":"Prefer Proven FOSS Components with Optional Support for Licensed Derivatives"},{"location":"adr/0000-prefer-proven-foss-components-with-optional-support-for-licensed-derivatives/#context-and-problem-statement","text":"Should we include licensed or non-FOSS components in the Tavros platform for a given component or component's feature?","title":"Context and Problem Statement"},{"location":"adr/0000-prefer-proven-foss-components-with-optional-support-for-licensed-derivatives/#decision-drivers","text":"Total cost of ownership Providing the necessary features for a competitive product","title":"Decision Drivers "},{"location":"adr/0000-prefer-proven-foss-components-with-optional-support-for-licensed-derivatives/#decision-outcome","text":"We will prioritize FOSS components, while providing optional support for paid or licensed derivatives, e.g.: Elastic Stack Open Source vs Enterprise subscription, Apache Camel vs JBoss Fuse, etc. Ultimately total cost of ownership will be the deciding factor for our customers when comparing to established alternatives. There are many FOSS components that address different concerns that we can incorporate and still provide a best-in-class platform.","title":"Decision Outcome"},{"location":"adr/0000-prefer-proven-foss-components-with-optional-support-for-licensed-derivatives/#negative-consequences","text":"High number of components to configure and integrate","title":"Negative Consequences "},{"location":"adr/0001-apache-camel-as-the-default-integration-framework/","text":"Apache Camel as the Default Integration Framework \u00b6 Status: accepted Deciders: @k2merlinsix, @jam01, @mnorton Date: 2020-08 Context and Problem Statement \u00b6 What should be our main/default software framework for integration services? Decision Drivers \u00b6 Modern framework Low learning curve Maturity Solid documentation and community Cost Considered Options \u00b6 Spring Boot Spring Integration Apache Camel Python Flask Alpakka Go Decision Outcome \u00b6 We'll use and extend Apache Camel as our default integration framework. Given the proficiency with Java and Enterprise Integration Patterns within our company and the industry in general, Apache Camel gives our customers a straight forward and low cost migration path from existing implementations. Positive Consequences \u00b6 Existing proficiency with Java and EIP Enables re-use of Maven based artifacts, e.g.: custom exceptions, domain classes, logging layouts, CI/CD pipelines Lower barrier for our customers finding professional resources Links \u00b6 Enterprise Integration Patterns Apache Camel Spring Boot Spring Integration Alpakka","title":"ADR-0001"},{"location":"adr/0001-apache-camel-as-the-default-integration-framework/#apache-camel-as-the-default-integration-framework","text":"Status: accepted Deciders: @k2merlinsix, @jam01, @mnorton Date: 2020-08","title":"Apache Camel as the Default Integration Framework"},{"location":"adr/0001-apache-camel-as-the-default-integration-framework/#context-and-problem-statement","text":"What should be our main/default software framework for integration services?","title":"Context and Problem Statement"},{"location":"adr/0001-apache-camel-as-the-default-integration-framework/#decision-drivers","text":"Modern framework Low learning curve Maturity Solid documentation and community Cost","title":"Decision Drivers "},{"location":"adr/0001-apache-camel-as-the-default-integration-framework/#considered-options","text":"Spring Boot Spring Integration Apache Camel Python Flask Alpakka Go","title":"Considered Options"},{"location":"adr/0001-apache-camel-as-the-default-integration-framework/#decision-outcome","text":"We'll use and extend Apache Camel as our default integration framework. Given the proficiency with Java and Enterprise Integration Patterns within our company and the industry in general, Apache Camel gives our customers a straight forward and low cost migration path from existing implementations.","title":"Decision Outcome"},{"location":"adr/0001-apache-camel-as-the-default-integration-framework/#positive-consequences","text":"Existing proficiency with Java and EIP Enables re-use of Maven based artifacts, e.g.: custom exceptions, domain classes, logging layouts, CI/CD pipelines Lower barrier for our customers finding professional resources","title":"Positive Consequences "},{"location":"adr/0001-apache-camel-as-the-default-integration-framework/#links","text":"Enterprise Integration Patterns Apache Camel Spring Boot Spring Integration Alpakka","title":"Links "},{"location":"adr/0002-spring-boot-as-the-base-application-framework/","text":"Spring Boot as the Base Application Framework \u00b6 Status: accepted Deciders: @k2merlinsix, @jam01, @mnorton Date: 2020-08 Context and Problem Statement \u00b6 Should we add a base application framework to Apache Camel such as Spring Boot or Quarkus? Decision Drivers \u00b6 Speed up development Maturity Solid documentation and community Considered Options \u00b6 Spring Boot Quarkus Decision Outcome \u00b6 We'll use Spring Boot as the base application framework to Apache Camel. We found that Spring Boot's auto-configuration features greatly speed up development time and it is well known and documented Positive Consequences \u00b6 Existing proficiency with Spring Boot as part of our internal bootcamp Access to a bigger ecosystem, e.g.: Spring Cloud Config Links \u00b6 Spring Boot Quarkus","title":"ADR-0002"},{"location":"adr/0002-spring-boot-as-the-base-application-framework/#spring-boot-as-the-base-application-framework","text":"Status: accepted Deciders: @k2merlinsix, @jam01, @mnorton Date: 2020-08","title":"Spring Boot as the Base Application Framework"},{"location":"adr/0002-spring-boot-as-the-base-application-framework/#context-and-problem-statement","text":"Should we add a base application framework to Apache Camel such as Spring Boot or Quarkus?","title":"Context and Problem Statement"},{"location":"adr/0002-spring-boot-as-the-base-application-framework/#decision-drivers","text":"Speed up development Maturity Solid documentation and community","title":"Decision Drivers "},{"location":"adr/0002-spring-boot-as-the-base-application-framework/#considered-options","text":"Spring Boot Quarkus","title":"Considered Options"},{"location":"adr/0002-spring-boot-as-the-base-application-framework/#decision-outcome","text":"We'll use Spring Boot as the base application framework to Apache Camel. We found that Spring Boot's auto-configuration features greatly speed up development time and it is well known and documented","title":"Decision Outcome"},{"location":"adr/0002-spring-boot-as-the-base-application-framework/#positive-consequences","text":"Existing proficiency with Spring Boot as part of our internal bootcamp Access to a bigger ecosystem, e.g.: Spring Cloud Config","title":"Positive Consequences "},{"location":"adr/0002-spring-boot-as-the-base-application-framework/#links","text":"Spring Boot Quarkus","title":"Links "},{"location":"adr/0003-datasonnet-as-the-default-data-transformation-language/","text":"DataSonnet as the Default Data Transformation Language \u00b6 Status: accepted Deciders: @k2merlinsix, @jam01, @JakeMHughes Date: 2020-08 Context and Problem Statement \u00b6 Does DataSonnet, or can we make it, meet functional and performance requirements for modern integration workloads? Decision Drivers \u00b6 Provide the necessary transformation functions Performance Decision Outcome \u00b6 We'll extend DataSonnet and use it as our default data transformation language. Extending ModusBox' work on top of DataBrick's sjsonnet project we delivered a feature-full and very performant language. Positive Consequences \u00b6 Joint ownership with ModusBox offers great visibility to our company and offerings Apache 2.0 License opens possibilities of adoption by the larger community or existing projects in the same space Negative Consequences \u00b6 Lead time to delivery of the next major release Responsibility of maintaining and stewarding the project with the community Links \u00b6 DataSonnet Mapper Project DataSonnet Jsonnet sjsonnet Project","title":"ADR-0003"},{"location":"adr/0003-datasonnet-as-the-default-data-transformation-language/#datasonnet-as-the-default-data-transformation-language","text":"Status: accepted Deciders: @k2merlinsix, @jam01, @JakeMHughes Date: 2020-08","title":"DataSonnet as the Default Data Transformation Language"},{"location":"adr/0003-datasonnet-as-the-default-data-transformation-language/#context-and-problem-statement","text":"Does DataSonnet, or can we make it, meet functional and performance requirements for modern integration workloads?","title":"Context and Problem Statement"},{"location":"adr/0003-datasonnet-as-the-default-data-transformation-language/#decision-drivers","text":"Provide the necessary transformation functions Performance","title":"Decision Drivers "},{"location":"adr/0003-datasonnet-as-the-default-data-transformation-language/#decision-outcome","text":"We'll extend DataSonnet and use it as our default data transformation language. Extending ModusBox' work on top of DataBrick's sjsonnet project we delivered a feature-full and very performant language.","title":"Decision Outcome"},{"location":"adr/0003-datasonnet-as-the-default-data-transformation-language/#positive-consequences","text":"Joint ownership with ModusBox offers great visibility to our company and offerings Apache 2.0 License opens possibilities of adoption by the larger community or existing projects in the same space","title":"Positive Consequences "},{"location":"adr/0003-datasonnet-as-the-default-data-transformation-language/#negative-consequences","text":"Lead time to delivery of the next major release Responsibility of maintaining and stewarding the project with the community","title":"Negative Consequences "},{"location":"adr/0003-datasonnet-as-the-default-data-transformation-language/#links","text":"DataSonnet Mapper Project DataSonnet Jsonnet sjsonnet Project","title":"Links "},{"location":"adr/0004-opentracing-for-in-process-tracing-api/","text":"OpenTracing for In-Process Tracing API \u00b6 Status: accepted Deciders: @jam01 Date: 2020-08 Context and Problem Statement \u00b6 Which in-process tracing API should we use, OpenTracing or the new project OpenTelemetry? Decision Drivers \u00b6 Existing library integrations Considered Options \u00b6 OpenTracing OpenTelemetry Decision Outcome \u00b6 We'll use OpenTracing for in-process tracing API. Having contributed to the OpenTracing project, and refactoring the camel-opentracing component significantly, OpenTracing provides the most functionality now while OpenTelemetry's design stabilizes. Negative Consequences \u00b6 Will need to migrate to OpenTelemetry as it eventually deprecates OpenTracing Links \u00b6 OpenTracing OpenTelemetry","title":"ADR-0004"},{"location":"adr/0004-opentracing-for-in-process-tracing-api/#opentracing-for-in-process-tracing-api","text":"Status: accepted Deciders: @jam01 Date: 2020-08","title":"OpenTracing for In-Process Tracing API"},{"location":"adr/0004-opentracing-for-in-process-tracing-api/#context-and-problem-statement","text":"Which in-process tracing API should we use, OpenTracing or the new project OpenTelemetry?","title":"Context and Problem Statement"},{"location":"adr/0004-opentracing-for-in-process-tracing-api/#decision-drivers","text":"Existing library integrations","title":"Decision Drivers "},{"location":"adr/0004-opentracing-for-in-process-tracing-api/#considered-options","text":"OpenTracing OpenTelemetry","title":"Considered Options"},{"location":"adr/0004-opentracing-for-in-process-tracing-api/#decision-outcome","text":"We'll use OpenTracing for in-process tracing API. Having contributed to the OpenTracing project, and refactoring the camel-opentracing component significantly, OpenTracing provides the most functionality now while OpenTelemetry's design stabilizes.","title":"Decision Outcome"},{"location":"adr/0004-opentracing-for-in-process-tracing-api/#negative-consequences","text":"Will need to migrate to OpenTelemetry as it eventually deprecates OpenTracing","title":"Negative Consequences "},{"location":"adr/0004-opentracing-for-in-process-tracing-api/#links","text":"OpenTracing OpenTelemetry","title":"Links "},{"location":"adr/0005-kubernetes-as-the-computing-platform/","text":"Kubernetes as the Computing Platform \u00b6 Status: accepted Deciders: @k2merlinsix, @jam01, Mohammad Naeem Date: 2020-08 Context and Problem Statement \u00b6 What should be our base platform? Decision Drivers \u00b6 Existing tooling and integrations to speed up delivery Decision Outcome \u00b6 We'll use Kubernetes as Tavros's computing platform. The adoption and support for Kubernetes has been evident for some time, most importantly tools like Kops, Helm, Operators, and Ansible's Kubernetes modules, make a great base for us to focus on delivering our platform.","title":"ADR-0005"},{"location":"adr/0005-kubernetes-as-the-computing-platform/#kubernetes-as-the-computing-platform","text":"Status: accepted Deciders: @k2merlinsix, @jam01, Mohammad Naeem Date: 2020-08","title":"Kubernetes as the Computing Platform"},{"location":"adr/0005-kubernetes-as-the-computing-platform/#context-and-problem-statement","text":"What should be our base platform?","title":"Context and Problem Statement"},{"location":"adr/0005-kubernetes-as-the-computing-platform/#decision-drivers","text":"Existing tooling and integrations to speed up delivery","title":"Decision Drivers "},{"location":"adr/0005-kubernetes-as-the-computing-platform/#decision-outcome","text":"We'll use Kubernetes as Tavros's computing platform. The adoption and support for Kubernetes has been evident for some time, most importantly tools like Kops, Helm, Operators, and Ansible's Kubernetes modules, make a great base for us to focus on delivering our platform.","title":"Decision Outcome"},{"location":"adr/0006-kops-to-provision-a-kubernetes-cluster/","text":"Kops to Provision a Kubernetes Cluster \u00b6 Status: accepted Deciders: Mohammad Naeem Date: 2020-08 Context and Problem Statement \u00b6 In order to automate the provisioning of the Kubernetes cluster, what tools should we use? Decision Outcome \u00b6 We'll utilize Kops to provision Kubernetes clusters. Positive Consequences \u00b6 Support for multiple cloud providers Links \u00b6 Kops","title":"ADR-0006"},{"location":"adr/0006-kops-to-provision-a-kubernetes-cluster/#kops-to-provision-a-kubernetes-cluster","text":"Status: accepted Deciders: Mohammad Naeem Date: 2020-08","title":"Kops to Provision a Kubernetes Cluster"},{"location":"adr/0006-kops-to-provision-a-kubernetes-cluster/#context-and-problem-statement","text":"In order to automate the provisioning of the Kubernetes cluster, what tools should we use?","title":"Context and Problem Statement"},{"location":"adr/0006-kops-to-provision-a-kubernetes-cluster/#decision-outcome","text":"We'll utilize Kops to provision Kubernetes clusters.","title":"Decision Outcome"},{"location":"adr/0006-kops-to-provision-a-kubernetes-cluster/#positive-consequences","text":"Support for multiple cloud providers","title":"Positive Consequences "},{"location":"adr/0006-kops-to-provision-a-kubernetes-cluster/#links","text":"Kops","title":"Links "},{"location":"adr/0007-flux-to-provide-platform-gitops/","text":"Flux v2 Toolkit to Provide Platform GitOps \u00b6 Status: accepted Deciders: Mohammad Naeem, @jam01, @rmccright-ms3 Date: 2020-09 Context and Problem Statement \u00b6 We want to enable continuous delivery of platform and application workloads in a GitOps way. What tools should we use? Decision Drivers \u00b6 Simplicity Integration with tools like Helm and Kustomize Considered Options \u00b6 Flux Flux v2 GitOps Toolkit Argo CD Decision Outcome \u00b6 We'll use Flux v2 GitOps Toolkit to enable continuous delivery of the platform and application workloads. Having had experience with Flux v1 internally, along with the newer features of v2 while still maintaining a simple workflow, it's the more appropriate tool. Positive Consequences \u00b6 Flux v2 Custom Resource Definitions make it easy to utilize Flux Helm functionality before the source Git repository is up Alert features through integrations like Slack Negative Consequences \u00b6 Have to be careful with the 'chicken and egg problem' between Flux managing the platform, and provisioning platform components through Flux Links \u00b6 GitOps Guide Flux v2 GitOps Toolkit Argo CD","title":"ADR-0007"},{"location":"adr/0007-flux-to-provide-platform-gitops/#flux-v2-toolkit-to-provide-platform-gitops","text":"Status: accepted Deciders: Mohammad Naeem, @jam01, @rmccright-ms3 Date: 2020-09","title":"Flux v2 Toolkit to Provide Platform GitOps"},{"location":"adr/0007-flux-to-provide-platform-gitops/#context-and-problem-statement","text":"We want to enable continuous delivery of platform and application workloads in a GitOps way. What tools should we use?","title":"Context and Problem Statement"},{"location":"adr/0007-flux-to-provide-platform-gitops/#decision-drivers","text":"Simplicity Integration with tools like Helm and Kustomize","title":"Decision Drivers "},{"location":"adr/0007-flux-to-provide-platform-gitops/#considered-options","text":"Flux Flux v2 GitOps Toolkit Argo CD","title":"Considered Options"},{"location":"adr/0007-flux-to-provide-platform-gitops/#decision-outcome","text":"We'll use Flux v2 GitOps Toolkit to enable continuous delivery of the platform and application workloads. Having had experience with Flux v1 internally, along with the newer features of v2 while still maintaining a simple workflow, it's the more appropriate tool.","title":"Decision Outcome"},{"location":"adr/0007-flux-to-provide-platform-gitops/#positive-consequences","text":"Flux v2 Custom Resource Definitions make it easy to utilize Flux Helm functionality before the source Git repository is up Alert features through integrations like Slack","title":"Positive Consequences "},{"location":"adr/0007-flux-to-provide-platform-gitops/#negative-consequences","text":"Have to be careful with the 'chicken and egg problem' between Flux managing the platform, and provisioning platform components through Flux","title":"Negative Consequences "},{"location":"adr/0007-flux-to-provide-platform-gitops/#links","text":"GitOps Guide Flux v2 GitOps Toolkit Argo CD","title":"Links "},{"location":"adr/0008-kubeseal-to-securely-manage-secrets-in-gitops/","text":"Kubeseal to Securely Manage Secrets in GitOps \u00b6 Status: accepted Deciders: @jam01, @rmccright-ms3 Date: 2020-09 Context and Problem Statement \u00b6 In order to store secrets safely in a public or private Git repository, what tool do we use? Decision Drivers \u00b6 Simplicity Integration with Flux Decision Outcome \u00b6 We'll use Bitnami's Sealed Secrets controller to securely manage secrets in GitOps. The sealed secrets can be decrypted only by the controller running in your cluster and nobody else can obtain the original secret, even if they have access to the Git repository. Links \u00b6 Flux Sealed Secrets recommendation Sealed Secrets project","title":"ADR-0008"},{"location":"adr/0008-kubeseal-to-securely-manage-secrets-in-gitops/#kubeseal-to-securely-manage-secrets-in-gitops","text":"Status: accepted Deciders: @jam01, @rmccright-ms3 Date: 2020-09","title":"Kubeseal to Securely Manage Secrets in GitOps"},{"location":"adr/0008-kubeseal-to-securely-manage-secrets-in-gitops/#context-and-problem-statement","text":"In order to store secrets safely in a public or private Git repository, what tool do we use?","title":"Context and Problem Statement"},{"location":"adr/0008-kubeseal-to-securely-manage-secrets-in-gitops/#decision-drivers","text":"Simplicity Integration with Flux","title":"Decision Drivers "},{"location":"adr/0008-kubeseal-to-securely-manage-secrets-in-gitops/#decision-outcome","text":"We'll use Bitnami's Sealed Secrets controller to securely manage secrets in GitOps. The sealed secrets can be decrypted only by the controller running in your cluster and nobody else can obtain the original secret, even if they have access to the Git repository.","title":"Decision Outcome"},{"location":"adr/0008-kubeseal-to-securely-manage-secrets-in-gitops/#links","text":"Flux Sealed Secrets recommendation Sealed Secrets project","title":"Links "},{"location":"adr/0009-keycloak-for-indetity-and-access-management/","text":"Keycloak for Identity and Access Management \u00b6 Status: accepted Deciders: Mohammad Naeem Date: 2020-08 Context and Problem Statement \u00b6 To provide user identity and access management, what component do we use? Decision Outcome \u00b6 We'll use Keycloak for identity and access management. Links \u00b6 Keycloak","title":"ADR-0009"},{"location":"adr/0009-keycloak-for-indetity-and-access-management/#keycloak-for-identity-and-access-management","text":"Status: accepted Deciders: Mohammad Naeem Date: 2020-08","title":"Keycloak for Identity and Access Management"},{"location":"adr/0009-keycloak-for-indetity-and-access-management/#context-and-problem-statement","text":"To provide user identity and access management, what component do we use?","title":"Context and Problem Statement"},{"location":"adr/0009-keycloak-for-indetity-and-access-management/#decision-outcome","text":"We'll use Keycloak for identity and access management.","title":"Decision Outcome"},{"location":"adr/0009-keycloak-for-indetity-and-access-management/#links","text":"Keycloak","title":"Links "},{"location":"adr/0010-kong-as-kubernetes-ingress-and-api-gateway/","text":"Kong as Kubernetes Ingress Controller and API Gateway \u00b6 Status: accepted Deciders: @k2merlinsix Date: 2020-08 Context and Problem Statement \u00b6 Which component should serve as our Kubernetes Ingress Controller, to do load balancing and proxying? Which component should serve as our API Gateway? How easy is it to tie into the application networking of the Ingress Controller? Decision Drivers \u00b6 Network performance Feature set of API Gateway Considered Options \u00b6 NGINX Kong Apigee KrakenD Decision Outcome \u00b6 Kong will be our Kubernetes Ingress Controller and API Gateway as well. Having a single component perform both functions should make it easier to maintain and more performant. Positive Consequences \u00b6 Enterprise Edition pricing is more cost effective than some alternatives Negative Consequences \u00b6 Lua as the main language for developing plugins Links \u00b6 Kong NGINX Apigee KrakenD","title":"ADR-0010"},{"location":"adr/0010-kong-as-kubernetes-ingress-and-api-gateway/#kong-as-kubernetes-ingress-controller-and-api-gateway","text":"Status: accepted Deciders: @k2merlinsix Date: 2020-08","title":"Kong as Kubernetes Ingress Controller and API Gateway"},{"location":"adr/0010-kong-as-kubernetes-ingress-and-api-gateway/#context-and-problem-statement","text":"Which component should serve as our Kubernetes Ingress Controller, to do load balancing and proxying? Which component should serve as our API Gateway? How easy is it to tie into the application networking of the Ingress Controller?","title":"Context and Problem Statement"},{"location":"adr/0010-kong-as-kubernetes-ingress-and-api-gateway/#decision-drivers","text":"Network performance Feature set of API Gateway","title":"Decision Drivers "},{"location":"adr/0010-kong-as-kubernetes-ingress-and-api-gateway/#considered-options","text":"NGINX Kong Apigee KrakenD","title":"Considered Options"},{"location":"adr/0010-kong-as-kubernetes-ingress-and-api-gateway/#decision-outcome","text":"Kong will be our Kubernetes Ingress Controller and API Gateway as well. Having a single component perform both functions should make it easier to maintain and more performant.","title":"Decision Outcome"},{"location":"adr/0010-kong-as-kubernetes-ingress-and-api-gateway/#positive-consequences","text":"Enterprise Edition pricing is more cost effective than some alternatives","title":"Positive Consequences "},{"location":"adr/0010-kong-as-kubernetes-ingress-and-api-gateway/#negative-consequences","text":"Lua as the main language for developing plugins","title":"Negative Consequences "},{"location":"adr/0010-kong-as-kubernetes-ingress-and-api-gateway/#links","text":"Kong NGINX Apigee KrakenD","title":"Links "},{"location":"adr/0011-postgresql-as-the-platform%27s-default-database/","text":"PostgreSQL as the Platform's Default Database \u00b6 Status: accepted Deciders: Mohammad Naeem Date: 2020-09 Context and Problem Statement \u00b6 Some components require a PostgreSQL database, how do we accommodate each one and future components? Decision Outcome \u00b6 We'll use PostgreSQL as the platform's default database. Since Gitea and Keycloak require a PostgreSQL database we'll setup a single server and dynamically create what's needed for each component that uses PostgreSQL. If it's an option to use PostgreSQL for future components, we'll use that. Positive Consequences \u00b6 Single instance to backup, and restore in case of a disaster recovery","title":"PostgreSQL as the Platform's Default Database"},{"location":"adr/0011-postgresql-as-the-platform%27s-default-database/#postgresql-as-the-platforms-default-database","text":"Status: accepted Deciders: Mohammad Naeem Date: 2020-09","title":"PostgreSQL as the Platform's Default Database"},{"location":"adr/0011-postgresql-as-the-platform%27s-default-database/#context-and-problem-statement","text":"Some components require a PostgreSQL database, how do we accommodate each one and future components?","title":"Context and Problem Statement"},{"location":"adr/0011-postgresql-as-the-platform%27s-default-database/#decision-outcome","text":"We'll use PostgreSQL as the platform's default database. Since Gitea and Keycloak require a PostgreSQL database we'll setup a single server and dynamically create what's needed for each component that uses PostgreSQL. If it's an option to use PostgreSQL for future components, we'll use that.","title":"Decision Outcome"},{"location":"adr/0011-postgresql-as-the-platform%27s-default-database/#positive-consequences","text":"Single instance to backup, and restore in case of a disaster recovery","title":"Positive Consequences "},{"location":"adr/0012-gitea-for-a-lightweight-git-server/","text":"Gitea for a Lightweight Git Server \u00b6 Status: accepted Deciders: Mohammad Naeem, @jam01 Date: 2020-09 Context and Problem Statement \u00b6 Given that Flux requires a Git repository to provide GitOps, and that our CI/CD pipelines will require the same for continuous delivery, what component should be our default/bundled Git server? Decision Drivers \u00b6 Lightweight as we expect a number of customers will already have a Git saas Easy to integrate Considered Options \u00b6 GitLab Gitea Decision Outcome \u00b6 We'll use Gitea as our bundled and lightweight Git server. Gitea is more lightweight than the alternatives, and has the necessary APIs for us to integrate with. Negative Consequences \u00b6 No out of the box integration with Flux Links \u00b6 Gitea GitLab","title":"ADR-0012"},{"location":"adr/0012-gitea-for-a-lightweight-git-server/#gitea-for-a-lightweight-git-server","text":"Status: accepted Deciders: Mohammad Naeem, @jam01 Date: 2020-09","title":"Gitea for a Lightweight Git Server"},{"location":"adr/0012-gitea-for-a-lightweight-git-server/#context-and-problem-statement","text":"Given that Flux requires a Git repository to provide GitOps, and that our CI/CD pipelines will require the same for continuous delivery, what component should be our default/bundled Git server?","title":"Context and Problem Statement"},{"location":"adr/0012-gitea-for-a-lightweight-git-server/#decision-drivers","text":"Lightweight as we expect a number of customers will already have a Git saas Easy to integrate","title":"Decision Drivers "},{"location":"adr/0012-gitea-for-a-lightweight-git-server/#considered-options","text":"GitLab Gitea","title":"Considered Options"},{"location":"adr/0012-gitea-for-a-lightweight-git-server/#decision-outcome","text":"We'll use Gitea as our bundled and lightweight Git server. Gitea is more lightweight than the alternatives, and has the necessary APIs for us to integrate with.","title":"Decision Outcome"},{"location":"adr/0012-gitea-for-a-lightweight-git-server/#negative-consequences","text":"No out of the box integration with Flux","title":"Negative Consequences "},{"location":"adr/0012-gitea-for-a-lightweight-git-server/#links","text":"Gitea GitLab","title":"Links "},{"location":"adr/0013-kuma-for-service-mesh/","text":"Kuma for Service Mesh \u00b6 Status: accepted Deciders: @k2merlinsix Date: 2020-08 Context and Problem Statement \u00b6 Service meshes helps to address cross cutting concerns so that application developers don't have to, what service mesh component should we use? Decision Drivers \u00b6 Performance Feature set Considered Options \u00b6 Kuma Istio Decision Outcome \u00b6 We'll use Kuma for service mesh. Positive Consequences \u00b6 Seamless integration with Kong Links \u00b6 Kuma","title":"ADR-0013"},{"location":"adr/0013-kuma-for-service-mesh/#kuma-for-service-mesh","text":"Status: accepted Deciders: @k2merlinsix Date: 2020-08","title":"Kuma for Service Mesh"},{"location":"adr/0013-kuma-for-service-mesh/#context-and-problem-statement","text":"Service meshes helps to address cross cutting concerns so that application developers don't have to, what service mesh component should we use?","title":"Context and Problem Statement"},{"location":"adr/0013-kuma-for-service-mesh/#decision-drivers","text":"Performance Feature set","title":"Decision Drivers "},{"location":"adr/0013-kuma-for-service-mesh/#considered-options","text":"Kuma Istio","title":"Considered Options"},{"location":"adr/0013-kuma-for-service-mesh/#decision-outcome","text":"We'll use Kuma for service mesh.","title":"Decision Outcome"},{"location":"adr/0013-kuma-for-service-mesh/#positive-consequences","text":"Seamless integration with Kong","title":"Positive Consequences "},{"location":"adr/0013-kuma-for-service-mesh/#links","text":"Kuma","title":"Links "},{"location":"adr/0014-jenkins-for-continuous-integration/","text":"Jenkins for Continuous Integration \u00b6 Status: accepted Deciders: @jam01 Date: 2020-09 Context and Problem Statement \u00b6 We'll be using Flux for continuous deployment, leaving us to choose a component for continuous delivery, i.e.: building and running tests against artifacts before deploying. Decision Drivers \u00b6 Existing proficiency and pipelines Simplicity Considered Options \u00b6 Jenkins Jenkins X Tekton Decision Outcome \u00b6 We'll use Jenkins as our CI component. Since we're using Flux for deployment we don't need too Kubernetes specific features like Jenkins X has, and Jenkins can support for complex pipelines than Tekton. Positive Consequences \u00b6 Can re-use existing pipelines with little modification Negative Consequences \u00b6 Less 'modern' than other options Links \u00b6 Jenkins X Jenkins Tekton Project","title":"ADR-0014"},{"location":"adr/0014-jenkins-for-continuous-integration/#jenkins-for-continuous-integration","text":"Status: accepted Deciders: @jam01 Date: 2020-09","title":"Jenkins for Continuous Integration"},{"location":"adr/0014-jenkins-for-continuous-integration/#context-and-problem-statement","text":"We'll be using Flux for continuous deployment, leaving us to choose a component for continuous delivery, i.e.: building and running tests against artifacts before deploying.","title":"Context and Problem Statement"},{"location":"adr/0014-jenkins-for-continuous-integration/#decision-drivers","text":"Existing proficiency and pipelines Simplicity","title":"Decision Drivers "},{"location":"adr/0014-jenkins-for-continuous-integration/#considered-options","text":"Jenkins Jenkins X Tekton","title":"Considered Options"},{"location":"adr/0014-jenkins-for-continuous-integration/#decision-outcome","text":"We'll use Jenkins as our CI component. Since we're using Flux for deployment we don't need too Kubernetes specific features like Jenkins X has, and Jenkins can support for complex pipelines than Tekton.","title":"Decision Outcome"},{"location":"adr/0014-jenkins-for-continuous-integration/#positive-consequences","text":"Can re-use existing pipelines with little modification","title":"Positive Consequences "},{"location":"adr/0014-jenkins-for-continuous-integration/#negative-consequences","text":"Less 'modern' than other options","title":"Negative Consequences "},{"location":"adr/0014-jenkins-for-continuous-integration/#links","text":"Jenkins X Jenkins Tekton Project","title":"Links "},{"location":"adr/0015-sonarqube-for-application-static-code-analysis/","text":"Sonarqube for Application Static Code Analysis \u00b6 Status: accepted Deciders: @jam01 Date: 2020-10 Context and Problem Statement \u00b6 We understand the value of automated code qualitative analysis and that it's often an afterthought. Should we bundle a static code analysis component? Decision Outcome \u00b6 We'll use Sonarqube for application static code analysis. As part of our effort to offer a ready best-practices platform we'll setup Sonarqube and tie it into template or default CI/CD pipelines. Links \u00b6 Sonarqube","title":"ADR-0015"},{"location":"adr/0015-sonarqube-for-application-static-code-analysis/#sonarqube-for-application-static-code-analysis","text":"Status: accepted Deciders: @jam01 Date: 2020-10","title":"Sonarqube for Application Static Code Analysis"},{"location":"adr/0015-sonarqube-for-application-static-code-analysis/#context-and-problem-statement","text":"We understand the value of automated code qualitative analysis and that it's often an afterthought. Should we bundle a static code analysis component?","title":"Context and Problem Statement"},{"location":"adr/0015-sonarqube-for-application-static-code-analysis/#decision-outcome","text":"We'll use Sonarqube for application static code analysis. As part of our effort to offer a ready best-practices platform we'll setup Sonarqube and tie it into template or default CI/CD pipelines.","title":"Decision Outcome"},{"location":"adr/0015-sonarqube-for-application-static-code-analysis/#links","text":"Sonarqube","title":"Links "},{"location":"adr/0016-elastic-cloud-for-observability-data-aggregation-and-visualization/","text":"Elastic Cloud for Observability Data Aggregation and Visualization \u00b6 Status: accepted Deciders: @jam01, @k2merlinsix Date: 2020-10 Context and Problem Statement \u00b6 In a microservices architectural system observability is imperative, what components should we use for that? Decision Drivers \u00b6 Cost Feature set Considered Options \u00b6 Elastic Cloud Jaeger Decision Outcome \u00b6 We'll use Elastic Cloud on Kubernetes for Observability Data Aggregation and Visualization. Elastic, Logstash and Kibana offer what we need for logging data. Aditionally, we can use APM server to get trace data from either Elastic's own apm agent or a Jaeger client. Positive Consequences \u00b6 A single pane of glass for observability Less components to coordinate Negative Consequences \u00b6 Valuable service dependency DAG only on license subscription Links \u00b6 Elastic Cloud on Kubernetes Elastic Stack Pricing Elastic with Jaeger ECK project Follow up decision to use Jaeger for Tracing ADR-0017","title":"ADR-0016"},{"location":"adr/0016-elastic-cloud-for-observability-data-aggregation-and-visualization/#elastic-cloud-for-observability-data-aggregation-and-visualization","text":"Status: accepted Deciders: @jam01, @k2merlinsix Date: 2020-10","title":"Elastic Cloud for Observability Data Aggregation and Visualization"},{"location":"adr/0016-elastic-cloud-for-observability-data-aggregation-and-visualization/#context-and-problem-statement","text":"In a microservices architectural system observability is imperative, what components should we use for that?","title":"Context and Problem Statement"},{"location":"adr/0016-elastic-cloud-for-observability-data-aggregation-and-visualization/#decision-drivers","text":"Cost Feature set","title":"Decision Drivers "},{"location":"adr/0016-elastic-cloud-for-observability-data-aggregation-and-visualization/#considered-options","text":"Elastic Cloud Jaeger","title":"Considered Options"},{"location":"adr/0016-elastic-cloud-for-observability-data-aggregation-and-visualization/#decision-outcome","text":"We'll use Elastic Cloud on Kubernetes for Observability Data Aggregation and Visualization. Elastic, Logstash and Kibana offer what we need for logging data. Aditionally, we can use APM server to get trace data from either Elastic's own apm agent or a Jaeger client.","title":"Decision Outcome"},{"location":"adr/0016-elastic-cloud-for-observability-data-aggregation-and-visualization/#positive-consequences","text":"A single pane of glass for observability Less components to coordinate","title":"Positive Consequences "},{"location":"adr/0016-elastic-cloud-for-observability-data-aggregation-and-visualization/#negative-consequences","text":"Valuable service dependency DAG only on license subscription","title":"Negative Consequences "},{"location":"adr/0016-elastic-cloud-for-observability-data-aggregation-and-visualization/#links","text":"Elastic Cloud on Kubernetes Elastic Stack Pricing Elastic with Jaeger ECK project Follow up decision to use Jaeger for Tracing ADR-0017","title":"Links "},{"location":"adr/0017-jaeger-for-tracing-with-elasticsearch-backend/","text":"Jaeger for Tracing with Elasticsearch Backend \u00b6 Status: accepted Deciders: @jam01 Date: 2020-10 Context and Problem Statement \u00b6 In a microservices architectural system observability is imperative, and Elastic Stack Open Source does not offer service dependency DAG. Can/should we fill in that feature with another component? Decision Drivers \u00b6 Cost Feature set Considered Options \u00b6 Elastic Stack Jaeger Decision Outcome \u00b6 We'll use Jaeger by default for tracing data, with Elasticsearch as the backend. Using Jaeger enables a service DAG that's very valuable and using elasticsearch as the backend enables data aggregation and analysis in Kibana. Positive Consequences \u00b6 Value of the service DAG dependency graph Maintain the ability to cross reference logs and trace data in a single pane Jaeger has closer participation to OpenTracing/Telemetry projects than Elastic Negative Consequences \u00b6 Another integration point Must correlate logs and traces in Camel through MDC Links \u00b6 Jaeger Elastic with Jaeger Jaeger Operator Article Jaeger Elasticsearch and Kibana Article Distributed Tracing with Jaeger and the ELK Stack Article Exploring Jaeger traces with Elastic APM","title":"ADR-0017"},{"location":"adr/0017-jaeger-for-tracing-with-elasticsearch-backend/#jaeger-for-tracing-with-elasticsearch-backend","text":"Status: accepted Deciders: @jam01 Date: 2020-10","title":"Jaeger for Tracing with Elasticsearch Backend"},{"location":"adr/0017-jaeger-for-tracing-with-elasticsearch-backend/#context-and-problem-statement","text":"In a microservices architectural system observability is imperative, and Elastic Stack Open Source does not offer service dependency DAG. Can/should we fill in that feature with another component?","title":"Context and Problem Statement"},{"location":"adr/0017-jaeger-for-tracing-with-elasticsearch-backend/#decision-drivers","text":"Cost Feature set","title":"Decision Drivers "},{"location":"adr/0017-jaeger-for-tracing-with-elasticsearch-backend/#considered-options","text":"Elastic Stack Jaeger","title":"Considered Options"},{"location":"adr/0017-jaeger-for-tracing-with-elasticsearch-backend/#decision-outcome","text":"We'll use Jaeger by default for tracing data, with Elasticsearch as the backend. Using Jaeger enables a service DAG that's very valuable and using elasticsearch as the backend enables data aggregation and analysis in Kibana.","title":"Decision Outcome"},{"location":"adr/0017-jaeger-for-tracing-with-elasticsearch-backend/#positive-consequences","text":"Value of the service DAG dependency graph Maintain the ability to cross reference logs and trace data in a single pane Jaeger has closer participation to OpenTracing/Telemetry projects than Elastic","title":"Positive Consequences "},{"location":"adr/0017-jaeger-for-tracing-with-elasticsearch-backend/#negative-consequences","text":"Another integration point Must correlate logs and traces in Camel through MDC","title":"Negative Consequences "},{"location":"adr/0017-jaeger-for-tracing-with-elasticsearch-backend/#links","text":"Jaeger Elastic with Jaeger Jaeger Operator Article Jaeger Elasticsearch and Kibana Article Distributed Tracing with Jaeger and the ELK Stack Article Exploring Jaeger traces with Elastic APM","title":"Links "},{"location":"adr/0018-nexus-repository-manager-for-artifact-management/","text":"Nexus Repository Manager for Artifact Management \u00b6 Status: accepted Deciders: @jam01, @k2merlinsix Date: 2020-10 Context and Problem Statement \u00b6 In a solid continuous delivery configuration an enterprise needs to have a history of application builds an ability to rollback deployments as necessary. What artifact manager component should we use? Decision Drivers \u00b6 Stability Considered Options \u00b6 Nexus Repository Manager JFrog Artifactory Decision Outcome \u00b6 We'll use Nexus repository manager for artifact management. Sonatype is one of the main stewards/contributors of Maven and therefore their platform is one of the most mature. In order to deliver a best practices continuous delivery configuration we'll tie in Nexus into our CI/CD pipelines. Positive Consequences \u00b6 Available commercial support from Nexus Links \u00b6 Nexus Repository Manager OSS JFrog Artifactory","title":"ADR-0018"},{"location":"adr/0018-nexus-repository-manager-for-artifact-management/#nexus-repository-manager-for-artifact-management","text":"Status: accepted Deciders: @jam01, @k2merlinsix Date: 2020-10","title":"Nexus Repository Manager for Artifact Management"},{"location":"adr/0018-nexus-repository-manager-for-artifact-management/#context-and-problem-statement","text":"In a solid continuous delivery configuration an enterprise needs to have a history of application builds an ability to rollback deployments as necessary. What artifact manager component should we use?","title":"Context and Problem Statement"},{"location":"adr/0018-nexus-repository-manager-for-artifact-management/#decision-drivers","text":"Stability","title":"Decision Drivers "},{"location":"adr/0018-nexus-repository-manager-for-artifact-management/#considered-options","text":"Nexus Repository Manager JFrog Artifactory","title":"Considered Options"},{"location":"adr/0018-nexus-repository-manager-for-artifact-management/#decision-outcome","text":"We'll use Nexus repository manager for artifact management. Sonatype is one of the main stewards/contributors of Maven and therefore their platform is one of the most mature. In order to deliver a best practices continuous delivery configuration we'll tie in Nexus into our CI/CD pipelines.","title":"Decision Outcome"},{"location":"adr/0018-nexus-repository-manager-for-artifact-management/#positive-consequences","text":"Available commercial support from Nexus","title":"Positive Consequences "},{"location":"adr/0018-nexus-repository-manager-for-artifact-management/#links","text":"Nexus Repository Manager OSS JFrog Artifactory","title":"Links "},{"location":"adr/0019-prefer-daemonsets-over-sidecars/","text":"Prefer Daemonsets over Sidecars \u00b6 Status: accepted Deciders: @jam01 Date: 2020-11 Context and Problem Statement \u00b6 Kubernetes supports deploying workloads as daemonsets or sidecars. For example, when deploying Jaeger Agent for reporting trace data, in a DaemonSet strategy there will be a single Agent deployment in every Kubernetes node, so all applications' Jaeger Client in a single node share the same agent. Conversely, in a side-car strategy each application will have its own dedicated Jaeger Agent deployment, requiring extra resources. Which should we favor for cross cutting concern deployments? Decision Drivers \u00b6 Cost Considered Options \u00b6 Sidecars Daemonsets Decision Outcome \u00b6 We'll prefer daemonsets over sidecar deployments whenever there is the option. Given that Tavros is designed as a single tenant platform there are computing resource savings when using daemonsets (deployment per node) vs sidecars (deployment per service). Positive Consequences \u00b6 Less resource utilization Negative Consequences \u00b6 Would have to refactor in order to support multi-tenancy Links \u00b6 DaemonSet See about single tenancy in ADR-0029","title":"ADR-0019"},{"location":"adr/0019-prefer-daemonsets-over-sidecars/#prefer-daemonsets-over-sidecars","text":"Status: accepted Deciders: @jam01 Date: 2020-11","title":"Prefer Daemonsets over Sidecars"},{"location":"adr/0019-prefer-daemonsets-over-sidecars/#context-and-problem-statement","text":"Kubernetes supports deploying workloads as daemonsets or sidecars. For example, when deploying Jaeger Agent for reporting trace data, in a DaemonSet strategy there will be a single Agent deployment in every Kubernetes node, so all applications' Jaeger Client in a single node share the same agent. Conversely, in a side-car strategy each application will have its own dedicated Jaeger Agent deployment, requiring extra resources. Which should we favor for cross cutting concern deployments?","title":"Context and Problem Statement"},{"location":"adr/0019-prefer-daemonsets-over-sidecars/#decision-drivers","text":"Cost","title":"Decision Drivers "},{"location":"adr/0019-prefer-daemonsets-over-sidecars/#considered-options","text":"Sidecars Daemonsets","title":"Considered Options"},{"location":"adr/0019-prefer-daemonsets-over-sidecars/#decision-outcome","text":"We'll prefer daemonsets over sidecar deployments whenever there is the option. Given that Tavros is designed as a single tenant platform there are computing resource savings when using daemonsets (deployment per node) vs sidecars (deployment per service).","title":"Decision Outcome"},{"location":"adr/0019-prefer-daemonsets-over-sidecars/#positive-consequences","text":"Less resource utilization","title":"Positive Consequences "},{"location":"adr/0019-prefer-daemonsets-over-sidecars/#negative-consequences","text":"Would have to refactor in order to support multi-tenancy","title":"Negative Consequences "},{"location":"adr/0019-prefer-daemonsets-over-sidecars/#links","text":"DaemonSet See about single tenancy in ADR-0029","title":"Links "},{"location":"adr/0020-spring-cloud-config-for-application-configuration-management/","text":"Spring Cloud Config for Application Configuration Management \u00b6 Status: accepted Deciders: @jam01 Date: 2020-11 Context and Problem Statement \u00b6 In a solid continuous delivery configuration an enterprise needs to manage application configuration properties independently of the application source code. What component should we use? Decision Drivers \u00b6 Flexible backend support Easy integration with Camel and Spring Boot Considered Options \u00b6 Spring Cloud Config Decision Outcome \u00b6 We'll use spring cloud config as our application configuration manager. Spring cloud config is very simple to integrate since we chose Spring Boot as our base application framework. We'll use a Git backend from Gitea which will allow our customers to keep a history of changes and enable rollback. Positive Consequences \u00b6 Simple integration to Spring Boot Links \u00b6 Spring Cloud Config","title":"ADR-0020"},{"location":"adr/0020-spring-cloud-config-for-application-configuration-management/#spring-cloud-config-for-application-configuration-management","text":"Status: accepted Deciders: @jam01 Date: 2020-11","title":"Spring Cloud Config for Application Configuration Management"},{"location":"adr/0020-spring-cloud-config-for-application-configuration-management/#context-and-problem-statement","text":"In a solid continuous delivery configuration an enterprise needs to manage application configuration properties independently of the application source code. What component should we use?","title":"Context and Problem Statement"},{"location":"adr/0020-spring-cloud-config-for-application-configuration-management/#decision-drivers","text":"Flexible backend support Easy integration with Camel and Spring Boot","title":"Decision Drivers "},{"location":"adr/0020-spring-cloud-config-for-application-configuration-management/#considered-options","text":"Spring Cloud Config","title":"Considered Options"},{"location":"adr/0020-spring-cloud-config-for-application-configuration-management/#decision-outcome","text":"We'll use spring cloud config as our application configuration manager. Spring cloud config is very simple to integrate since we chose Spring Boot as our base application framework. We'll use a Git backend from Gitea which will allow our customers to keep a history of changes and enable rollback.","title":"Decision Outcome"},{"location":"adr/0020-spring-cloud-config-for-application-configuration-management/#positive-consequences","text":"Simple integration to Spring Boot","title":"Positive Consequences "},{"location":"adr/0020-spring-cloud-config-for-application-configuration-management/#links","text":"Spring Cloud Config","title":"Links "},{"location":"adr/0021-prefer-kong-enterprise-edition/","text":"Prefer Kong Enterprise Edition \u00b6 Status: accepted Deciders: @k2merlinsix Date: 2020-11 Context and Problem Statement \u00b6 Given that we've chosen Kong as our Ingress Controller and API Gateway, but we're still missing an API Manager and Developer Portal. Decision Drivers \u00b6 Feature set Decision Outcome \u00b6 We'll recommend Kong enterprise edition in order to enable API manager and developer portal features. API manager and developer portal features are not necessary but they are valuable, supporting Kong EE as an optional component is an acceptable compromise to offer that value to our customers. Positive Consequences \u00b6 Single component for all API related functionality Negative Consequences \u00b6 Requires a license Links \u00b6 Kong Enterprise","title":"ADR-0021"},{"location":"adr/0021-prefer-kong-enterprise-edition/#prefer-kong-enterprise-edition","text":"Status: accepted Deciders: @k2merlinsix Date: 2020-11","title":"Prefer Kong Enterprise Edition"},{"location":"adr/0021-prefer-kong-enterprise-edition/#context-and-problem-statement","text":"Given that we've chosen Kong as our Ingress Controller and API Gateway, but we're still missing an API Manager and Developer Portal.","title":"Context and Problem Statement"},{"location":"adr/0021-prefer-kong-enterprise-edition/#decision-drivers","text":"Feature set","title":"Decision Drivers "},{"location":"adr/0021-prefer-kong-enterprise-edition/#decision-outcome","text":"We'll recommend Kong enterprise edition in order to enable API manager and developer portal features. API manager and developer portal features are not necessary but they are valuable, supporting Kong EE as an optional component is an acceptable compromise to offer that value to our customers.","title":"Decision Outcome"},{"location":"adr/0021-prefer-kong-enterprise-edition/#positive-consequences","text":"Single component for all API related functionality","title":"Positive Consequences "},{"location":"adr/0021-prefer-kong-enterprise-edition/#negative-consequences","text":"Requires a license","title":"Negative Consequences "},{"location":"adr/0021-prefer-kong-enterprise-edition/#links","text":"Kong Enterprise","title":"Links "},{"location":"adr/0022-use-ansible-as-the-provisioning-engine/","text":"Use Ansible as Provisioning Engine \u00b6 Status: accepted Deciders: Mohammad Naeem, @jam01 Date: 2020-11 Context and Problem Statement \u00b6 [Describe the context and problem statement, e.g., in free form using two to three sentences. You may want to articulate the problem in form of a question.] Decision Drivers \u00b6 Flexibility Maintainability Considered Options \u00b6 Bash Ansible Decision Outcome \u00b6 We'll use Ansible as the provisioning engine. Ansible modules, variable handling, Jinja 2 templating, and Kubernetes module make it easier to install and configure components. Helm Charts use the same templating language, and the Operator SDK has support for Ansible, if we decide to build an Operator. Positive Consequences \u00b6 Ansible being a desired-state engine enables idempotency Simpler setup Negative Consequences \u00b6 A learning curve to Ansible, playbooks, roles, etc Links \u00b6 Ansible Kubernetes Ansible Ansible Operator SDK","title":"ADR-0022"},{"location":"adr/0022-use-ansible-as-the-provisioning-engine/#use-ansible-as-provisioning-engine","text":"Status: accepted Deciders: Mohammad Naeem, @jam01 Date: 2020-11","title":"Use Ansible as Provisioning Engine"},{"location":"adr/0022-use-ansible-as-the-provisioning-engine/#context-and-problem-statement","text":"[Describe the context and problem statement, e.g., in free form using two to three sentences. You may want to articulate the problem in form of a question.]","title":"Context and Problem Statement"},{"location":"adr/0022-use-ansible-as-the-provisioning-engine/#decision-drivers","text":"Flexibility Maintainability","title":"Decision Drivers "},{"location":"adr/0022-use-ansible-as-the-provisioning-engine/#considered-options","text":"Bash Ansible","title":"Considered Options"},{"location":"adr/0022-use-ansible-as-the-provisioning-engine/#decision-outcome","text":"We'll use Ansible as the provisioning engine. Ansible modules, variable handling, Jinja 2 templating, and Kubernetes module make it easier to install and configure components. Helm Charts use the same templating language, and the Operator SDK has support for Ansible, if we decide to build an Operator.","title":"Decision Outcome"},{"location":"adr/0022-use-ansible-as-the-provisioning-engine/#positive-consequences","text":"Ansible being a desired-state engine enables idempotency Simpler setup","title":"Positive Consequences "},{"location":"adr/0022-use-ansible-as-the-provisioning-engine/#negative-consequences","text":"A learning curve to Ansible, playbooks, roles, etc","title":"Negative Consequences "},{"location":"adr/0022-use-ansible-as-the-provisioning-engine/#links","text":"Ansible Kubernetes Ansible Ansible Operator SDK","title":"Links "},{"location":"adr/0023-helm-and-operators-for-component-installation-and-management/","text":"Helm and Operators for Component Installation and Management \u00b6 Status: accepted Deciders: @jam01, @rmccright-ms3 Date: 2020-11 Context and Problem Statement \u00b6 We're currently installing components ad-hoc through directly modified Kubernetes manifests from helm charts. This removes the ability to use Helm's upgrade features. This is done because we can't use Helm until Flux is up and running, and Flux depends on other components being installed before. Decision Drivers \u00b6 Ability to use Helm upgrades Minimize hand crafted manifests Considered Options \u00b6 Helm releases through Flux v2 Operators Decision Outcome \u00b6 We'll use Helm releases and Operators custom resources for component installation and management. Given that we're now using Flux v2 we can use their Helm release functionality before any Git repository is available, this way we can do Helm releases through Flux and eventually commit them to Git to enable GitOps from that point on. Kubernets Operators enable a higher level of component lifecycle management, these should always be preferred to Helm whenever available. Positive Consequences \u00b6 Upon provisioning the platform it will be entirely driven by GitOps Will be able to do component upgrades through Helm releases Less custom code by using official functionality as available Links \u00b6 Helm Operator Pattern Operator Hub Flux v2 Helm Controller","title":"ADR-0023"},{"location":"adr/0023-helm-and-operators-for-component-installation-and-management/#helm-and-operators-for-component-installation-and-management","text":"Status: accepted Deciders: @jam01, @rmccright-ms3 Date: 2020-11","title":"Helm and Operators for Component Installation and Management"},{"location":"adr/0023-helm-and-operators-for-component-installation-and-management/#context-and-problem-statement","text":"We're currently installing components ad-hoc through directly modified Kubernetes manifests from helm charts. This removes the ability to use Helm's upgrade features. This is done because we can't use Helm until Flux is up and running, and Flux depends on other components being installed before.","title":"Context and Problem Statement"},{"location":"adr/0023-helm-and-operators-for-component-installation-and-management/#decision-drivers","text":"Ability to use Helm upgrades Minimize hand crafted manifests","title":"Decision Drivers "},{"location":"adr/0023-helm-and-operators-for-component-installation-and-management/#considered-options","text":"Helm releases through Flux v2 Operators","title":"Considered Options"},{"location":"adr/0023-helm-and-operators-for-component-installation-and-management/#decision-outcome","text":"We'll use Helm releases and Operators custom resources for component installation and management. Given that we're now using Flux v2 we can use their Helm release functionality before any Git repository is available, this way we can do Helm releases through Flux and eventually commit them to Git to enable GitOps from that point on. Kubernets Operators enable a higher level of component lifecycle management, these should always be preferred to Helm whenever available.","title":"Decision Outcome"},{"location":"adr/0023-helm-and-operators-for-component-installation-and-management/#positive-consequences","text":"Upon provisioning the platform it will be entirely driven by GitOps Will be able to do component upgrades through Helm releases Less custom code by using official functionality as available","title":"Positive Consequences "},{"location":"adr/0023-helm-and-operators-for-component-installation-and-management/#links","text":"Helm Operator Pattern Operator Hub Flux v2 Helm Controller","title":"Links "},{"location":"adr/0024-use-ansible-collection-to-structure-and-package-ansible-code/","text":"Use Ansible Collection to Structure and Package Ansible Code \u00b6 Status: accepted Deciders: @jam01 Date: 2020-11 Context and Problem Statement \u00b6 How do we package multiple playbooks, plugins, and how do we distribute them when creating a customer's platform? Designing pre-configured components and their extension points through Kustomizations is increasingly complex. Is there a way to simplify and make it more maintainable? Decision Drivers \u00b6 Maintainability of the code Easier to add customer configurability of components Support for distribution Considered Options \u00b6 Ansible Collection Decision Outcome \u00b6 We'll use Ansible Collection structure and packaging for our Ansible code. We'll refactor the platform from multiple layers of Kustomizations to be entirely driven by an Ansible Collection. Ansible is migrating all their re-usable artifacts to be Collections so that seems to be where all support and tooling is to be found, including distribution from a git repository. Moving the component configuration and extension points to Ansible makes it much easier to structure and maintain, as well as add points of extension. Positive Consequences \u00b6 Higher maintainability as it's all Ansible Easier to add customer configurability as everything can be templated Negative Consequences \u00b6 A bit more complexity Links \u00b6 Using Collections Blog The Future of Ansible Content Delivery Blog Hands on with Ansible collections","title":"ADR-0024"},{"location":"adr/0024-use-ansible-collection-to-structure-and-package-ansible-code/#use-ansible-collection-to-structure-and-package-ansible-code","text":"Status: accepted Deciders: @jam01 Date: 2020-11","title":"Use Ansible Collection to Structure and Package Ansible Code"},{"location":"adr/0024-use-ansible-collection-to-structure-and-package-ansible-code/#context-and-problem-statement","text":"How do we package multiple playbooks, plugins, and how do we distribute them when creating a customer's platform? Designing pre-configured components and their extension points through Kustomizations is increasingly complex. Is there a way to simplify and make it more maintainable?","title":"Context and Problem Statement"},{"location":"adr/0024-use-ansible-collection-to-structure-and-package-ansible-code/#decision-drivers","text":"Maintainability of the code Easier to add customer configurability of components Support for distribution","title":"Decision Drivers "},{"location":"adr/0024-use-ansible-collection-to-structure-and-package-ansible-code/#considered-options","text":"Ansible Collection","title":"Considered Options"},{"location":"adr/0024-use-ansible-collection-to-structure-and-package-ansible-code/#decision-outcome","text":"We'll use Ansible Collection structure and packaging for our Ansible code. We'll refactor the platform from multiple layers of Kustomizations to be entirely driven by an Ansible Collection. Ansible is migrating all their re-usable artifacts to be Collections so that seems to be where all support and tooling is to be found, including distribution from a git repository. Moving the component configuration and extension points to Ansible makes it much easier to structure and maintain, as well as add points of extension.","title":"Decision Outcome"},{"location":"adr/0024-use-ansible-collection-to-structure-and-package-ansible-code/#positive-consequences","text":"Higher maintainability as it's all Ansible Easier to add customer configurability as everything can be templated","title":"Positive Consequences "},{"location":"adr/0024-use-ansible-collection-to-structure-and-package-ansible-code/#negative-consequences","text":"A bit more complexity","title":"Negative Consequences "},{"location":"adr/0024-use-ansible-collection-to-structure-and-package-ansible-code/#links","text":"Using Collections Blog The Future of Ansible Content Delivery Blog Hands on with Ansible collections","title":"Links "},{"location":"adr/0025-setup-sandbox-and-production-kuma-meshes-and-kong-ingress-controllers/","text":"Setup Sandbox and Production Kuma Meshes and Kong Ingress Controllers \u00b6 Status: accepted Deciders: @jam01, @rmccright-ms3 Date: 2020-11 Context and Problem Statement \u00b6 What should be our default service mesh and application environments look like? Given that we'll enable mutual TLS on the meshes, each mesh will require a Kong Ingress Controller which in turn requires a Load Balancer from the cloud provider. Decision Drivers \u00b6 Must reflect best practice configuration Segregate production from non-production workloads as much as possible Satisfy 'common' enterprise requirements Cost Considered Options \u00b6 One dev, one test, and one production environment, all segregated through Kuma meshes Dev and test environments separated by kuma meshes in one cluster, production in another Dev and test environments in one 'sandbox' kuma mesh, production in a 'production' mesh Decision Outcome \u00b6 We'll setup a Sandbox and Production Kuma mesh, sandbox will have a dev and test namespaced environment, and production will have the production namespaced environment. The service mesh and mutual TLS plugin enforces the segregation of non-production (aka sandbox) environments and the production environment to where we don't fuctionally need a separate cluster. Moreover aggregating dev and test into a sandbox mesh saves us provisioning a load balancer for each environment, so we could support any arbitrary environment configuration needs. Positive Consequences \u00b6 Reduced cost of extra load balancer Reduced complexity of dedicated cluster Negative Consequences \u00b6 Learning curve of service mesh mutual TLS enforcement Sandboxed environments can still communicate with each other Links \u00b6 Kuma mTLS Kuma Gateway","title":"ADR-0025"},{"location":"adr/0025-setup-sandbox-and-production-kuma-meshes-and-kong-ingress-controllers/#setup-sandbox-and-production-kuma-meshes-and-kong-ingress-controllers","text":"Status: accepted Deciders: @jam01, @rmccright-ms3 Date: 2020-11","title":"Setup Sandbox and Production Kuma Meshes and Kong Ingress Controllers"},{"location":"adr/0025-setup-sandbox-and-production-kuma-meshes-and-kong-ingress-controllers/#context-and-problem-statement","text":"What should be our default service mesh and application environments look like? Given that we'll enable mutual TLS on the meshes, each mesh will require a Kong Ingress Controller which in turn requires a Load Balancer from the cloud provider.","title":"Context and Problem Statement"},{"location":"adr/0025-setup-sandbox-and-production-kuma-meshes-and-kong-ingress-controllers/#decision-drivers","text":"Must reflect best practice configuration Segregate production from non-production workloads as much as possible Satisfy 'common' enterprise requirements Cost","title":"Decision Drivers "},{"location":"adr/0025-setup-sandbox-and-production-kuma-meshes-and-kong-ingress-controllers/#considered-options","text":"One dev, one test, and one production environment, all segregated through Kuma meshes Dev and test environments separated by kuma meshes in one cluster, production in another Dev and test environments in one 'sandbox' kuma mesh, production in a 'production' mesh","title":"Considered Options"},{"location":"adr/0025-setup-sandbox-and-production-kuma-meshes-and-kong-ingress-controllers/#decision-outcome","text":"We'll setup a Sandbox and Production Kuma mesh, sandbox will have a dev and test namespaced environment, and production will have the production namespaced environment. The service mesh and mutual TLS plugin enforces the segregation of non-production (aka sandbox) environments and the production environment to where we don't fuctionally need a separate cluster. Moreover aggregating dev and test into a sandbox mesh saves us provisioning a load balancer for each environment, so we could support any arbitrary environment configuration needs.","title":"Decision Outcome"},{"location":"adr/0025-setup-sandbox-and-production-kuma-meshes-and-kong-ingress-controllers/#positive-consequences","text":"Reduced cost of extra load balancer Reduced complexity of dedicated cluster","title":"Positive Consequences "},{"location":"adr/0025-setup-sandbox-and-production-kuma-meshes-and-kong-ingress-controllers/#negative-consequences","text":"Learning curve of service mesh mutual TLS enforcement Sandboxed environments can still communicate with each other","title":"Negative Consequences "},{"location":"adr/0025-setup-sandbox-and-production-kuma-meshes-and-kong-ingress-controllers/#links","text":"Kuma mTLS Kuma Gateway","title":"Links "},{"location":"adr/0026-setup-sandbox-and-production-keycloak-realms/","text":"Setup Sandbox and Production Keycloak Realms \u00b6 Status: accepted Deciders: @jam01, @rmccright-ms3 Date: 2020-11 Context and Problem Statement \u00b6 Keycloak enables separation of sets of users, groups, roles, etc. through Realms. Should we create separate realms by default, which ones? Decision Drivers \u00b6 Must reflect best practice configuration Segregate production from non-production workloads as much as possible Satisfy 'common' enterprise requirements Considered Options \u00b6 Leave single Master realm Create one production realm Create sandbox and production realms Decision Outcome \u00b6 We'll create sandbox and production keycloak realms. Given the existing inclusion of sandbox and production concepts through service mesh and ingress controllers, these realms make a simple and easy to understand separation of users that allows customers to also test and promote identity and access management policies in a similar way to application workloads. We've seen enterprises do this with okta and okta preview instances for example. Positive Consequences \u00b6 Simple, easy to understand Enables identity and access management separation Negative Consequences \u00b6 May be unnecessary for some organizations Links \u00b6 Keycloak Concetps","title":"ADR-0026"},{"location":"adr/0026-setup-sandbox-and-production-keycloak-realms/#setup-sandbox-and-production-keycloak-realms","text":"Status: accepted Deciders: @jam01, @rmccright-ms3 Date: 2020-11","title":"Setup Sandbox and Production Keycloak Realms"},{"location":"adr/0026-setup-sandbox-and-production-keycloak-realms/#context-and-problem-statement","text":"Keycloak enables separation of sets of users, groups, roles, etc. through Realms. Should we create separate realms by default, which ones?","title":"Context and Problem Statement"},{"location":"adr/0026-setup-sandbox-and-production-keycloak-realms/#decision-drivers","text":"Must reflect best practice configuration Segregate production from non-production workloads as much as possible Satisfy 'common' enterprise requirements","title":"Decision Drivers "},{"location":"adr/0026-setup-sandbox-and-production-keycloak-realms/#considered-options","text":"Leave single Master realm Create one production realm Create sandbox and production realms","title":"Considered Options"},{"location":"adr/0026-setup-sandbox-and-production-keycloak-realms/#decision-outcome","text":"We'll create sandbox and production keycloak realms. Given the existing inclusion of sandbox and production concepts through service mesh and ingress controllers, these realms make a simple and easy to understand separation of users that allows customers to also test and promote identity and access management policies in a similar way to application workloads. We've seen enterprises do this with okta and okta preview instances for example.","title":"Decision Outcome"},{"location":"adr/0026-setup-sandbox-and-production-keycloak-realms/#positive-consequences","text":"Simple, easy to understand Enables identity and access management separation","title":"Positive Consequences "},{"location":"adr/0026-setup-sandbox-and-production-keycloak-realms/#negative-consequences","text":"May be unnecessary for some organizations","title":"Negative Consequences "},{"location":"adr/0026-setup-sandbox-and-production-keycloak-realms/#links","text":"Keycloak Concetps","title":"Links "},{"location":"adr/0027-cert-manager-for-certificate-management/","text":"cert-manager for Certificate Management \u00b6 Status: accepted Deciders: @jam01 Date: 2020-11 Context and Problem Statement \u00b6 The platform will required TLS certificates to signed by well known CAs. What tool do we use for generate those certificates? Decision Drivers \u00b6 Automation, including rotation before expiration Cost Considered Options \u00b6 cert-manager Decision Outcome \u00b6 We'll use cert-manager as our certificate manager. cert-manager is the best known certificate manager for Kubernetes, it will automatically generate certificates as they're request by Ingress TLS configuration and will automatically re-generate them before they expire. For CA we'll use Let's Encrypt which is free. Positive Consequences \u00b6 Automatic generation and re-generation Negative Consequences \u00b6 Let's Encrypt limit of 50 certificates per week Links \u00b6 cert-manager Securing Ingress Resources ACME Issuers Let's Encrypt Docs","title":"ADR-0027"},{"location":"adr/0027-cert-manager-for-certificate-management/#cert-manager-for-certificate-management","text":"Status: accepted Deciders: @jam01 Date: 2020-11","title":"cert-manager for Certificate Management"},{"location":"adr/0027-cert-manager-for-certificate-management/#context-and-problem-statement","text":"The platform will required TLS certificates to signed by well known CAs. What tool do we use for generate those certificates?","title":"Context and Problem Statement"},{"location":"adr/0027-cert-manager-for-certificate-management/#decision-drivers","text":"Automation, including rotation before expiration Cost","title":"Decision Drivers "},{"location":"adr/0027-cert-manager-for-certificate-management/#considered-options","text":"cert-manager","title":"Considered Options"},{"location":"adr/0027-cert-manager-for-certificate-management/#decision-outcome","text":"We'll use cert-manager as our certificate manager. cert-manager is the best known certificate manager for Kubernetes, it will automatically generate certificates as they're request by Ingress TLS configuration and will automatically re-generate them before they expire. For CA we'll use Let's Encrypt which is free.","title":"Decision Outcome"},{"location":"adr/0027-cert-manager-for-certificate-management/#positive-consequences","text":"Automatic generation and re-generation","title":"Positive Consequences "},{"location":"adr/0027-cert-manager-for-certificate-management/#negative-consequences","text":"Let's Encrypt limit of 50 certificates per week","title":"Negative Consequences "},{"location":"adr/0027-cert-manager-for-certificate-management/#links","text":"cert-manager Securing Ingress Resources ACME Issuers Let's Encrypt Docs","title":"Links "},{"location":"adr/0028-use-markdown-architectural-decision-records/","text":"Use Markdown Architectural Decision Records \u00b6 Context and Problem Statement \u00b6 We want to record architectural decisions made in this project. Which format and structure should these records follow? Considered Options \u00b6 MADR 2.1.2 \u2013 The Markdown Architectural Decision Records Michael Nygard's template \u2013 The first incarnation of the term \"ADR\" Sustainable Architectural Decisions \u2013 The Y-Statements Other templates listed at https://github.com/joelparkerhenderson/architecture_decision_record Formless \u2013 No conventions for file format and structure Decision Outcome \u00b6 Chosen option: \"MADR 2.1.2\", because Implicit assumptions should be made explicit. Design documentation is important to enable people understanding the decisions later on. See also A rational design process: How and why to fake it . The MADR format is lean and fits our development style. The MADR structure is comprehensible and facilitates usage & maintenance. The MADR project is vivid. Version 2.1.2 is the latest one available when starting to document ADRs.","title":"ADR-0028"},{"location":"adr/0028-use-markdown-architectural-decision-records/#use-markdown-architectural-decision-records","text":"","title":"Use Markdown Architectural Decision Records"},{"location":"adr/0028-use-markdown-architectural-decision-records/#context-and-problem-statement","text":"We want to record architectural decisions made in this project. Which format and structure should these records follow?","title":"Context and Problem Statement"},{"location":"adr/0028-use-markdown-architectural-decision-records/#considered-options","text":"MADR 2.1.2 \u2013 The Markdown Architectural Decision Records Michael Nygard's template \u2013 The first incarnation of the term \"ADR\" Sustainable Architectural Decisions \u2013 The Y-Statements Other templates listed at https://github.com/joelparkerhenderson/architecture_decision_record Formless \u2013 No conventions for file format and structure","title":"Considered Options"},{"location":"adr/0028-use-markdown-architectural-decision-records/#decision-outcome","text":"Chosen option: \"MADR 2.1.2\", because Implicit assumptions should be made explicit. Design documentation is important to enable people understanding the decisions later on. See also A rational design process: How and why to fake it . The MADR format is lean and fits our development style. The MADR structure is comprehensible and facilitates usage & maintenance. The MADR project is vivid. Version 2.1.2 is the latest one available when starting to document ADRs.","title":"Decision Outcome"},{"location":"adr/0029-tavros-as-a-single-tenant-platform/","text":"Tavros as a Single Tenant Platform \u00b6 Status: accepted Deciders: @jam01 Date: 2020-11 Context and Problem Statement \u00b6 A single platform for an indefinite amount of tenants would allow us to provide Tavros in a cloud 'as-a-service' offering to our customers, instead of only as managed services. However, there is an unknown complexity and level of effort behind multi-tenancy. Decision Drivers \u00b6 Scope creep Speed of delivery Complexity Considered Options \u00b6 Build multi-tenancy from the ground up Automated single-tenant offered as PaaS Decision Outcome \u00b6 We'll build Tavros as a single tenant platform. The Ansible automation can be developed in a way that accommodates two modes of operation: Build a tavros cluster to be owned by the client and optionally operated by us, as was the original objective Build a tavros cluster to be owned and operated by us, transparently to the client. The second mode allows us to offer a PaaS while keeping the platform simple. Positive Consequences \u00b6 Explicit separation to other clusters Simpler to build and consequently faster to deliver Can still offer as PaaS Negative Consequences \u00b6 May complicate day-2 operations on multiple clusters at once","title":"ADR-0029"},{"location":"adr/0029-tavros-as-a-single-tenant-platform/#tavros-as-a-single-tenant-platform","text":"Status: accepted Deciders: @jam01 Date: 2020-11","title":"Tavros as a Single Tenant Platform"},{"location":"adr/0029-tavros-as-a-single-tenant-platform/#context-and-problem-statement","text":"A single platform for an indefinite amount of tenants would allow us to provide Tavros in a cloud 'as-a-service' offering to our customers, instead of only as managed services. However, there is an unknown complexity and level of effort behind multi-tenancy.","title":"Context and Problem Statement"},{"location":"adr/0029-tavros-as-a-single-tenant-platform/#decision-drivers","text":"Scope creep Speed of delivery Complexity","title":"Decision Drivers "},{"location":"adr/0029-tavros-as-a-single-tenant-platform/#considered-options","text":"Build multi-tenancy from the ground up Automated single-tenant offered as PaaS","title":"Considered Options"},{"location":"adr/0029-tavros-as-a-single-tenant-platform/#decision-outcome","text":"We'll build Tavros as a single tenant platform. The Ansible automation can be developed in a way that accommodates two modes of operation: Build a tavros cluster to be owned by the client and optionally operated by us, as was the original objective Build a tavros cluster to be owned and operated by us, transparently to the client. The second mode allows us to offer a PaaS while keeping the platform simple.","title":"Decision Outcome"},{"location":"adr/0029-tavros-as-a-single-tenant-platform/#positive-consequences","text":"Explicit separation to other clusters Simpler to build and consequently faster to deliver Can still offer as PaaS","title":"Positive Consequences "},{"location":"adr/0029-tavros-as-a-single-tenant-platform/#negative-consequences","text":"May complicate day-2 operations on multiple clusters at once","title":"Negative Consequences "},{"location":"adr/template/","text":"[short title of solved problem and solution] \u00b6 Status: [proposed | rejected | accepted | deprecated | \u2026 | superseded by ADR-0005 ] Deciders: [list everyone involved in the decision] Date: [YYYY-MM-DD when the decision was last updated] Technical Story: [description | ticket/issue URL] Context and Problem Statement \u00b6 [Describe the context and problem statement, e.g., in free form using two to three sentences. You may want to articulate the problem in form of a question.] Decision Drivers \u00b6 [driver 1, e.g., a force, facing concern, \u2026] [driver 2, e.g., a force, facing concern, \u2026] \u2026 Considered Options \u00b6 [option 1] [option 2] [option 3] \u2026 Decision Outcome \u00b6 Chosen option: \"[option 1]\", because [justification. e.g., only option, which meets k.o. criterion decision driver | which resolves force force | \u2026 | comes out best (see below)]. Positive Consequences \u00b6 [e.g., improvement of quality attribute satisfaction, follow-up decisions required, \u2026] \u2026 Negative Consequences \u00b6 [e.g., compromising quality attribute, follow-up decisions required, \u2026] \u2026 Pros and Cons of the Options \u00b6 [option 1] \u00b6 [example | description | pointer to more information | \u2026] Good, because [argument a] Good, because [argument b] Bad, because [argument c] \u2026 [option 2] \u00b6 [example | description | pointer to more information | \u2026] Good, because [argument a] Good, because [argument b] Bad, because [argument c] \u2026 [option 3] \u00b6 [example | description | pointer to more information | \u2026] Good, because [argument a] Good, because [argument b] Bad, because [argument c] \u2026 Links \u00b6 [Link type] [Link to ADR] \u2026","title":"ADR-TEMP"},{"location":"adr/template/#short-title-of-solved-problem-and-solution","text":"Status: [proposed | rejected | accepted | deprecated | \u2026 | superseded by ADR-0005 ] Deciders: [list everyone involved in the decision] Date: [YYYY-MM-DD when the decision was last updated] Technical Story: [description | ticket/issue URL]","title":"[short title of solved problem and solution]"},{"location":"adr/template/#context-and-problem-statement","text":"[Describe the context and problem statement, e.g., in free form using two to three sentences. You may want to articulate the problem in form of a question.]","title":"Context and Problem Statement"},{"location":"adr/template/#decision-drivers","text":"[driver 1, e.g., a force, facing concern, \u2026] [driver 2, e.g., a force, facing concern, \u2026] \u2026","title":"Decision Drivers "},{"location":"adr/template/#considered-options","text":"[option 1] [option 2] [option 3] \u2026","title":"Considered Options"},{"location":"adr/template/#decision-outcome","text":"Chosen option: \"[option 1]\", because [justification. e.g., only option, which meets k.o. criterion decision driver | which resolves force force | \u2026 | comes out best (see below)].","title":"Decision Outcome"},{"location":"adr/template/#positive-consequences","text":"[e.g., improvement of quality attribute satisfaction, follow-up decisions required, \u2026] \u2026","title":"Positive Consequences "},{"location":"adr/template/#negative-consequences","text":"[e.g., compromising quality attribute, follow-up decisions required, \u2026] \u2026","title":"Negative Consequences "},{"location":"adr/template/#pros-and-cons-of-the-options","text":"","title":"Pros and Cons of the Options "},{"location":"adr/template/#option-1","text":"[example | description | pointer to more information | \u2026] Good, because [argument a] Good, because [argument b] Bad, because [argument c] \u2026","title":"[option 1]"},{"location":"adr/template/#option-2","text":"[example | description | pointer to more information | \u2026] Good, because [argument a] Good, because [argument b] Bad, because [argument c] \u2026","title":"[option 2]"},{"location":"adr/template/#option-3","text":"[example | description | pointer to more information | \u2026] Good, because [argument a] Good, because [argument b] Bad, because [argument c] \u2026","title":"[option 3]"},{"location":"adr/template/#links","text":"[Link type] [Link to ADR] \u2026","title":"Links "},{"location":"contribute/","text":"Contributing to Tavros \u00b6 We love your input! We want to make contributing to this project as easy and transparent as possible, whether it's: Reporting a bug Discussing the current state of the code Submitting a fix Proposing new features Becoming a maintainer We Develop with Github \u00b6 We use github to host code, to track issues and feature requests, as well as accept pull requests. We Use Github Flow , So All Code Changes Happen Through Pull Requests \u00b6 Pull requests are the best way to propose changes to the codebase (we use Github Flow ). We actively welcome your pull requests: Fork the repo and create your branch from master . If you've added code that should be tested, add tests. If you've changed APIs, update the documentation. Ensure the test suite passes. Make sure your code lints. Issue that pull request! Any contributions you make will be under the MIT Software License \u00b6 In short, when you submit code changes, your submissions are understood to be under the same MIT License that covers the project. Feel free to contact the maintainers if that's a concern. Report bugs using Github's issues \u00b6 We use GitHub issues to track public bugs. Report a bug by opening a new issue ; it's that easy! Write bug reports with detail, background, and sample code \u00b6 This is an example of a bug report I wrote, and I think it's not a bad model. Here's another example from Craig Hockenberry , an app developer whom I greatly respect. Great Bug Reports tend to have: A quick summary and/or background Steps to reproduce Be specific! Give sample code if you can. My stackoverflow question includes sample code that anyone with a base R setup can run to reproduce what I was seeing What you expected would happen What actually happens Notes (possibly including why you think this might be happening, or stuff you tried that didn't work) People love thorough bug reports. I'm not even kidding. Use a Consistent Coding Style \u00b6 I'm again borrowing these from Facebook's Guidelines 2 spaces for indentation rather than tabs You can try running npm run lint for style unification License \u00b6 By contributing, you agree that your contributions will be licensed under its MIT License. References \u00b6 This document was adapted from the open-source contribution guidelines for Facebook's Draft","title":"How to Contribute"},{"location":"contribute/#contributing-to-tavros","text":"We love your input! We want to make contributing to this project as easy and transparent as possible, whether it's: Reporting a bug Discussing the current state of the code Submitting a fix Proposing new features Becoming a maintainer","title":"Contributing to Tavros"},{"location":"contribute/#we-develop-with-github","text":"We use github to host code, to track issues and feature requests, as well as accept pull requests.","title":"We Develop with Github"},{"location":"contribute/#we-use-github-flow-so-all-code-changes-happen-through-pull-requests","text":"Pull requests are the best way to propose changes to the codebase (we use Github Flow ). We actively welcome your pull requests: Fork the repo and create your branch from master . If you've added code that should be tested, add tests. If you've changed APIs, update the documentation. Ensure the test suite passes. Make sure your code lints. Issue that pull request!","title":"We Use Github Flow, So All Code Changes Happen Through Pull Requests"},{"location":"contribute/#any-contributions-you-make-will-be-under-the-mit-software-license","text":"In short, when you submit code changes, your submissions are understood to be under the same MIT License that covers the project. Feel free to contact the maintainers if that's a concern.","title":"Any contributions you make will be under the MIT Software License"},{"location":"contribute/#report-bugs-using-githubs-issues","text":"We use GitHub issues to track public bugs. Report a bug by opening a new issue ; it's that easy!","title":"Report bugs using Github's issues"},{"location":"contribute/#write-bug-reports-with-detail-background-and-sample-code","text":"This is an example of a bug report I wrote, and I think it's not a bad model. Here's another example from Craig Hockenberry , an app developer whom I greatly respect. Great Bug Reports tend to have: A quick summary and/or background Steps to reproduce Be specific! Give sample code if you can. My stackoverflow question includes sample code that anyone with a base R setup can run to reproduce what I was seeing What you expected would happen What actually happens Notes (possibly including why you think this might be happening, or stuff you tried that didn't work) People love thorough bug reports. I'm not even kidding.","title":"Write bug reports with detail, background, and sample code"},{"location":"contribute/#use-a-consistent-coding-style","text":"I'm again borrowing these from Facebook's Guidelines 2 spaces for indentation rather than tabs You can try running npm run lint for style unification","title":"Use a Consistent Coding Style"},{"location":"contribute/#license","text":"By contributing, you agree that your contributions will be licensed under its MIT License.","title":"License"},{"location":"contribute/#references","text":"This document was adapted from the open-source contribution guidelines for Facebook's Draft","title":"References"},{"location":"contribute/developing/","text":"Developing using Docker \u00b6","title":"Developing"},{"location":"contribute/developing/#developing-using-docker","text":"","title":"Developing using Docker"},{"location":"contribute/documentation/","text":"Documentation Guidelines \u00b6","title":"Documentation Guidelines"},{"location":"contribute/documentation/#documentation-guidelines","text":"","title":"Documentation Guidelines"},{"location":"contribute/release-process/","text":"","title":"Release Process"},{"location":"contribute/tavros-collection/","text":"","title":"Build Tools"},{"location":"contribute/testing/","text":"","title":"Testing"},{"location":"features/cicd/","text":"","title":"Application CICD"},{"location":"features/cluster/","text":"","title":"Cluster Managment"},{"location":"features/gateway/","text":"","title":"Gateway"},{"location":"features/gitops/","text":"","title":"GitOps"},{"location":"features/mesh/","text":"","title":"Service Mesh"},{"location":"features/observability/","text":"","title":"Observability"},{"location":"features/repository/","text":"","title":"Repository"},{"location":"features/security/","text":"","title":"Security"},{"location":"getting-started/disaster-recovery/","text":"","title":"Disaster Recovery"},{"location":"getting-started/installation/","text":"Getting Started with Tavros \u00b6 Prerequisites \u00b6 Install Container Runtime \u00b6 We provide a Tavros Collection Image pre-installed with the latest version of Tavros and all its required Tooling. To utilize this you will need a Container Runtime such as Docker or Podman. Get Docker Get Podman Pull Tavros Collection \u00b6 Get the latest Tavros Collection Image. This OSI Image contains all the required tooling to run Tavros. docker pull ghcr.io/ms3inc/tavros-collection Prepare a FQDN for DNS \u00b6 Tavros requires a FQDN to be provided for its Root Domain. This allows the Gatway to expose deployed components on Sub Domains of the provided FQDN. DNS resolution for these various FQDNs will need to be configured for the corresponding IP of the Gateways LoadBalancer. Note: If using a Cluster Provisioning Role such as kops or aks this will be configured for you. For installing to existing Clusters the DNS Role will output a list of DNS Records to be created manually durring Playbook execution. DNS Resolution is currently required for select components. Theirfor the DNS Role will wait for you to configure this. Prepare Kubernetes Cluster \u00b6 Tavros is Kubernetes Native so you will need access to a Cluster to provision its components. You can utilize an existing Cluster or have Tavros provision a new one for you. Existing Create AKS Create AWS For Existing Clusters you will need to provide Client access to the Tavros container via a Kube config file. Your cluster must meet the following requirements: K8s 1.19,1.20,1.21 Has a default Storage Class Supports Service of Type Loadbalancer Azure Kubernetes Services You will need an Azure account with an available Subcription capable of provisioning Service Principals, AKS Clusters, DNS Zones, Resource Groups, and Storage Accounts on demand. Install Azure CLI tool \u00b6 You can follow the official instructions on how to install the Azure CLI Login to Azure \u00b6 This will redirect you and output your Tennant and Subscription info. az login Create Service Principal \u00b6 A Service Principal will be used by the AKS Role to provision the required componenets. az ad sp create-for-rbac --name tavros --role owner --sdk-auth Create Resource Group \u00b6 This resrouce group will be used to namespace the Azure resource used. az group create -n tavros-aks --location eastus Create Storage Account \u00b6 You'll also need to provide a storage location for your Tavros configuration. az storage account create -n tavros01234 -g tavros-aks Create DNS Zone \u00b6 You will need to create a DNS Zone for the Host az network dns zone create -n az.ms3-inc.com -g tavros-aks KOps Kubernetes on Amazon Web Services IAM \u00b6 For Tavros cluster on AWS, IAM should be configured as follows: #!/bin/bash aws iam create-group --group-name tavros-provisioner \u200b # required for kops # https://github.com/kubernetes/kops/blob/master/docs/getting_started/aws.md#setup-iam-user aws iam attach-group-policy --policy-arn arn:aws:iam::aws:policy/AmazonEC2FullAccess --group-name tavros-provisioner aws iam attach-group-policy --policy-arn arn:aws:iam::aws:policy/AmazonRoute53FullAccess --group-name tavros-provisioner aws iam attach-group-policy --policy-arn arn:aws:iam::aws:policy/AmazonS3FullAccess --group-name tavros-provisioner aws iam attach-group-policy --policy-arn arn:aws:iam::aws:policy/IAMFullAccess --group-name tavros-provisioner aws iam attach-group-policy --policy-arn arn:aws:iam::aws:policy/AmazonVPCFullAccess --group-name tavros-provisioner \u200b aws iam create-user --user-name tavros-ci aws iam add-user-to-group --user-name tavros-ci --group-name tavros-provisioner aws iam create-access-key --user-name tavros-ci The resulting Access Key and Secret should be passed to the Ansible Playbook. For more detailed information see https://kops.sigs.k8s.io/getting_started/aws/ Route53 \u00b6 Route53 should manage the domain to be used for the cluster as a Hosted Zone. It is not necessary for Route53 to serve as the root domain registrar. For more information see Configuring Amazon Route 53 as your DNS service . For more detailed information see https://kops.sigs.k8s.io/getting_started/aws/ Prepare Inventory File \u00b6 The Tavros Provisioning Playbook is deisned to be configured using a Yaml Inventory file. We provide defaults which can be used to get started with Tavros. At minimum you will need to provide a Cluster Name, FQDN, Admin Email, and Credentials for either an existing K8s Cluster or for a supported Provisioning Role. --- all: vars: cluster_fqdn: '' cluster_admin_email: '' kubernetes_cluster: cloud_provider: 'aws' dns_zone: \"{{ cluster_fqdn }}\" keycloak: realm: prod kops: enabled: true master_count: 3 master_size: 't2.large' master_zones: 'us-east-1a,us-east-1b' node_count: 2 node_size: 't2.xlarge' node_zones: 'us-east-1a,us-east-1b' state_bucket: \"{{ cluster_fqdn }}-tavros\" state_bucket_region: \"us-east-1\" kong: enabled: true default_ingress_class: 'prod' ee_creds: [] instances: - name: 'sandbox-kong' hybrid: false ingress_class: 'sandbox' kuma_mesh_name: 'sandbox' ee: enabled: false - name: 'prod-kong' hybrid: true ingress_class: 'prod' kuma_mesh_name: 'prod' ee: enabled: false kuma: enabled: true meshes: - name: 'sandbox' mtls: enabled: true traffictrace: enabled: true - name: 'prod' mtls: enabled: true traffictrace: enabled: true namespaces: - name: 'dev' kuma_mesh_name: 'sandbox' - name: 'test' kuma_mesh_name: 'sandbox' - name: 'prod' kuma_mesh_name: 'prod' keycloak: enabled: true realms: - name: sandbox - name: prod postgresql: {} cert_manager: enabled: true gitea: enabled: true keycloak: realm: 'prod' nexus: enabled: true keycloak: realm: 'prod' elastic_cloud: ee: enabled: false enabled: true jaeger: enabled: true keycloak: realm: 'prod' jenkins: enabled: true keycloak: realm: 'prod' flux: {} Installation \u00b6 Shell into Tavros Collection Instance \u00b6 docker run -it --rm -v $PWD:$PWD:Z -w $PWD ghcr.io/ms3inc/tavros-collection:latest Run Tavros Provision Playbook \u00b6 You can dry run first to make sure there are no issues with the Templeting phase ansible-playbook playbooks/provision_playbook.yaml --inventory <inventory_path>.yaml --tags all,dry-run Provisoion the Tavros Cluster with ansible-playbook playbooks/provision_playbook.yaml --inventory <inventory_path>.yaml --tags all","title":"Installation"},{"location":"getting-started/installation/#getting-started-with-tavros","text":"","title":"Getting Started with Tavros"},{"location":"getting-started/installation/#prerequisites","text":"","title":"Prerequisites"},{"location":"getting-started/installation/#install-container-runtime","text":"We provide a Tavros Collection Image pre-installed with the latest version of Tavros and all its required Tooling. To utilize this you will need a Container Runtime such as Docker or Podman. Get Docker Get Podman","title":"Install Container Runtime"},{"location":"getting-started/installation/#pull-tavros-collection","text":"Get the latest Tavros Collection Image. This OSI Image contains all the required tooling to run Tavros. docker pull ghcr.io/ms3inc/tavros-collection","title":"Pull Tavros Collection"},{"location":"getting-started/installation/#prepare-a-fqdn-for-dns","text":"Tavros requires a FQDN to be provided for its Root Domain. This allows the Gatway to expose deployed components on Sub Domains of the provided FQDN. DNS resolution for these various FQDNs will need to be configured for the corresponding IP of the Gateways LoadBalancer. Note: If using a Cluster Provisioning Role such as kops or aks this will be configured for you. For installing to existing Clusters the DNS Role will output a list of DNS Records to be created manually durring Playbook execution. DNS Resolution is currently required for select components. Theirfor the DNS Role will wait for you to configure this.","title":"Prepare a FQDN for DNS"},{"location":"getting-started/installation/#prepare-kubernetes-cluster","text":"Tavros is Kubernetes Native so you will need access to a Cluster to provision its components. You can utilize an existing Cluster or have Tavros provision a new one for you. Existing Create AKS Create AWS For Existing Clusters you will need to provide Client access to the Tavros container via a Kube config file. Your cluster must meet the following requirements: K8s 1.19,1.20,1.21 Has a default Storage Class Supports Service of Type Loadbalancer Azure Kubernetes Services You will need an Azure account with an available Subcription capable of provisioning Service Principals, AKS Clusters, DNS Zones, Resource Groups, and Storage Accounts on demand.","title":"Prepare Kubernetes Cluster"},{"location":"getting-started/installation/#prepare-inventory-file","text":"The Tavros Provisioning Playbook is deisned to be configured using a Yaml Inventory file. We provide defaults which can be used to get started with Tavros. At minimum you will need to provide a Cluster Name, FQDN, Admin Email, and Credentials for either an existing K8s Cluster or for a supported Provisioning Role. --- all: vars: cluster_fqdn: '' cluster_admin_email: '' kubernetes_cluster: cloud_provider: 'aws' dns_zone: \"{{ cluster_fqdn }}\" keycloak: realm: prod kops: enabled: true master_count: 3 master_size: 't2.large' master_zones: 'us-east-1a,us-east-1b' node_count: 2 node_size: 't2.xlarge' node_zones: 'us-east-1a,us-east-1b' state_bucket: \"{{ cluster_fqdn }}-tavros\" state_bucket_region: \"us-east-1\" kong: enabled: true default_ingress_class: 'prod' ee_creds: [] instances: - name: 'sandbox-kong' hybrid: false ingress_class: 'sandbox' kuma_mesh_name: 'sandbox' ee: enabled: false - name: 'prod-kong' hybrid: true ingress_class: 'prod' kuma_mesh_name: 'prod' ee: enabled: false kuma: enabled: true meshes: - name: 'sandbox' mtls: enabled: true traffictrace: enabled: true - name: 'prod' mtls: enabled: true traffictrace: enabled: true namespaces: - name: 'dev' kuma_mesh_name: 'sandbox' - name: 'test' kuma_mesh_name: 'sandbox' - name: 'prod' kuma_mesh_name: 'prod' keycloak: enabled: true realms: - name: sandbox - name: prod postgresql: {} cert_manager: enabled: true gitea: enabled: true keycloak: realm: 'prod' nexus: enabled: true keycloak: realm: 'prod' elastic_cloud: ee: enabled: false enabled: true jaeger: enabled: true keycloak: realm: 'prod' jenkins: enabled: true keycloak: realm: 'prod' flux: {}","title":"Prepare Inventory File"},{"location":"getting-started/installation/#installation","text":"","title":"Installation"},{"location":"getting-started/installation/#shell-into-tavros-collection-instance","text":"docker run -it --rm -v $PWD:$PWD:Z -w $PWD ghcr.io/ms3inc/tavros-collection:latest","title":"Shell into Tavros Collection Instance"},{"location":"getting-started/installation/#run-tavros-provision-playbook","text":"You can dry run first to make sure there are no issues with the Templeting phase ansible-playbook playbooks/provision_playbook.yaml --inventory <inventory_path>.yaml --tags all,dry-run Provisoion the Tavros Cluster with ansible-playbook playbooks/provision_playbook.yaml --inventory <inventory_path>.yaml --tags all","title":"Run Tavros Provision Playbook"},{"location":"getting-started/teardown/","text":"","title":"Teardown"},{"location":"getting-started/troubleshooting/","text":"","title":"Troubleshooting"},{"location":"getting-started/upgrades/","text":"","title":"Upgrades"},{"location":"playbooks/deprovision_playbook/","text":"","title":"Deprovision"},{"location":"playbooks/overview/","text":"","title":"Overview"},{"location":"playbooks/provision_playbook/","text":"Tavros Provision Playbook \u00b6 Requirements For clusters on AWS IAM Route53 Default Configuration Configuration Variables Kubernetes Cluster Object Kong Object Kong EE Credentials Object Image Registry Object Kong Instance Object Kong Instance EE Object Kuma Object Kuma Mesh Object Kuma mTLS Object Namespace Object Keycloak Object Nexus Object Elastic Cloud Object Gitea Jaeger Table of contents generated with markdown-toc This playbook will use provision a Kubernetes Cluster on AWS. It will then configure the platform components sequentially as configured, and finally commit all resource manifests to Git, for Flux to manage from that point on. The order of component configuration is as follows: * Flux v2 Toolkit - In order to provide platform GitOps * Kubeseal - In order to safely store secrets in GitOps * PostgreSQL - A central configuration database for multiple components * Namespaces - Application namespaced environments * Kuma - Service Meshes * cert-manager - TLS certificate manager for the given domain * Kong - As a API Gateway and Manager, with enterprise edition features if that is enabled * Keycloak - To provide Identity and Access Management, if enabled * Nexus - To provide repository for varios formats, if enabled * Elastic Cloud - To provide observability, if enabled * Gitea - To provide source control, if enabled * Jaeger - To provide observability, if enabled Requirements \u00b6 For clusters on AWS \u00b6 IAM \u00b6 For Tavros cluster on AWS, IAM should be configured as follows: #!/bin/bash aws iam create-group --group-name tavros-provisioner \u200b # required for kops # https://github.com/kubernetes/kops/blob/master/docs/getting_started/aws.md#setup-iam-user aws iam attach-group-policy --policy-arn arn:aws:iam::aws:policy/AmazonEC2FullAccess --group-name tavros-provisioner aws iam attach-group-policy --policy-arn arn:aws:iam::aws:policy/AmazonRoute53FullAccess --group-name tavros-provisioner aws iam attach-group-policy --policy-arn arn:aws:iam::aws:policy/AmazonS3FullAccess --group-name tavros-provisioner aws iam attach-group-policy --policy-arn arn:aws:iam::aws:policy/IAMFullAccess --group-name tavros-provisioner aws iam attach-group-policy --policy-arn arn:aws:iam::aws:policy/AmazonVPCFullAccess --group-name tavros-provisioner \u200b aws iam create-user --user-name tavros-ci aws iam add-user-to-group --user-name tavros-ci --group-name tavros-provisioner aws iam create-access-key --user-name tavros-ci The resulting Access Key and Secret should be passed to the Ansible Playbook. For more detailed information see https://kops.sigs.k8s.io/getting_started/aws/ Route53 \u00b6 Route53 should manage the domain to be used for the cluster as a Hosted Zone. It is not necessary for Route53 to serve as the root domain registrar. For more information see Configuring Amazon Route 53 as your DNS service . For more detailed information see https://kops.sigs.k8s.io/getting_started/aws/ Default Configuration \u00b6 There is a default configuration vars file that results in the following: * A Kubernetes cluster on AWS with 3x T2.XLarge masters and 2x T2.Large worker nodes. * A single Keycloak instance with two realms: 'sandbox' and 'prod'. * 2x Kuma meshes: 'sandbox' and 'prod'. * 2x Kong ingress controllers: 'sandbox' and 'prod'. The ingress controllers are part of the Kuma meshes, respectively. * 3x application namespaced environments: 'dev', 'test', and 'prod'. 'dev' and 'test' belong to the 'sandbox' Kuma mesh, and 'prod' to the 'prod' Kuma mesh. To use the default configuration: ansible-playbook playbooks/provision_playbook.yaml \\ --extra-vars '{\"cluster_name\":\"tavros\",\"cluster_domain\":\"example.com\",\"cluster_admin_email\":\"ops@example.com\"}' \\ --inventory \"playbooks/provision_playbook/default_vars.yaml\" Configuration Variables \u00b6 Field Name Type Description Default Value cluster_name String Required The name of the Tavros Kubernetes cluster cluster_domain String Required The domain name to use for the platform. This should be managed by the cloud provider chosen in order to setup routes and certificates cluster_admin_email String Required The email for alerts and general notifications. kubernetes_cluster Kubernetes Cluster Object Required Configuration for the Kubernetes Cluster to be provisioned kong Kong Object Configuration for Kong kuma Kuma Object Configuration for Kuma namespaces [ Namespace Object ] An array of Namespace configurations keycloak Keycloak Object Configuration for Keycloak Kubernetes Cluster Object \u00b6 Field Name Type Description Default Value cloud String The cloud provider to provision the cluster in 'aws' master_count Integer The number of master nodes 3 master_size String The machine instance type for master nodes 'T2.Large' node_count Integer The number of worker nodes 2 node_size String The machine instance type for worker nodes 'T2.XLarge' zones String A comma separated list of availability zones in which to place the machines 'us-east-1,us-east-2' state_bucket String The name of the S3 bucket to place the cluster state in 'troubaodur' ssh_public_key String The SSH public key to setup as authorized user on provisioned machines read from ~/.ssh/id_rsa.pub aws_access_key_id String The AWS IAM AccessKeyId uses aws cli logged in user aws_secret_access_key The AWS IAM SecretAccessKey uses aws cli logged in user keycloak Kubernetes Cluster Keycloak Object Keycloak Config { \"realm\": \"\", \"client_secret\": \"\" } Kubernetes Cluster Keycloak Object \u00b6 Field Name Type Description Default Value realm String Keycloak Realm Name client_secret String Client Secret Kong Object \u00b6 Field Name Type Description Default Value default_ingress_class String The default ingress controller class for other components to use 'prod' ee_creds [ Kong EE Credentials Object ] An array of Kong Enterprise Edition Credentials available for Kong instances to use instances [ Kong Instance Object ] An array of Kong instance object to be configured Kong EE Credentials Object \u00b6 Field Name Type Description Default Value license String Required The Enterprise Edition license name String Required Identifier for EE Kong Instance Kong Instance Object \u00b6 Field Name Type Description Default Value name String Required The name of the Kong instance hybrid Boolean Required Deployment Type ingress_class String Required The name of the ingress class kuma_mesh_name String The name of the Kuma mesh that the Kong instance should be part of ee Kong Instance EE Object The EE configuration for the Kong instance Kong Instance EE Object \u00b6 Field Name Type Description Default Value enabled Boolean Whether to use Enterprise Edition false creds String The name of the Kong EE Credentials resource to use 'default' keycloak Kong Keycloak Object Keycloak Config { \"realm\": \"\", \"client_secret\": \"\" } Kong Keycloak Object \u00b6 Field Name Type Description Default Value realm String Keycloak Realm Name client_secret String Client Secret Kuma Object \u00b6 Field Name Type Description Default Value meshes [ Kuma Mesh Object ] The Kuma mesh configuration object Kuma Mesh Object \u00b6 Field Name Type Description Default Value name String Required The name of the Kuma mesh mtls Kuma mTLS Object The mTLS configuration for the Kuma mesh Kuma mTLS Object \u00b6 Field Name Type Description Default Value enabled Boolean Whether to enable mTLS false Namespace Object \u00b6 Field Name Type Description Default Value name String Required The name of the Namespace kuma_mesh_name String The name of the Kuma mesh this namespace should be a part of Keycloak Object \u00b6 Field Name Type Description Default Value enabled Boolean Whether to use Keycloak true realms Array of Keycloak Realms Object Enumeration of Desired Realms [{\"name\": \"sandbox\"}, {\"name\": \"prod\"}] Keycloak Realms Object \u00b6 Field Name Type Description Default Value name Boolean Whether to use Keycloak Nexus Object \u00b6 Field Name Type Description Default Value enabled Boolean Whether to use Elastic Cloud true keycloak Nexus Keycloak Object Keycloak Config { \"realm\": \"\", \"client_secret\": \"\" } Nexus Keycloak Object \u00b6 Field Name Type Description Default Value realm String Keycloak Realm Name client_secret String Client Secret Elastic Cloud Object \u00b6 Field Name Type Description Default Value enabled Boolean Whether to use Elastic Cloud true ee Elastic Cloud EE Object EE Config { \"enabled\": false } Elastic Cloud EE Object \u00b6 Field Name Type Description Default Value enabled Boolean Whether to use EE trial Boolean Whether to use 30 day cluster trial license licnese String License JSON keycloak Elastic Cloud Keycloak Object Keycloak Config { \"realm\": \"\", \"client_secret\": \"\" } Elastic Cloud Keycloak Object \u00b6 Field Name Type Description Default Value realm String Keycloak Realm Name client_secret String Client Secret Gitea Object \u00b6 Field Name Type Description Default Value enabled Boolean Whether to use Gitea true Jaeger Object \u00b6 Field Name Type Description Default Value enabled Boolean Whether to use Jaeger true keycloak Jaeger Keycloak Object Keycloak Config { \"realm\": \"\", \"client_secret\": \"\" } Jaeger Keycloak Object \u00b6 Field Name Type Description Default Value realm String Keycloak Realm Name client_secret String Client Secret Jenkins Object \u00b6 Field Name Type Description Default Value enabled Boolean Whether to use Jenkins true keycloak Jenkins Keycloak Object Keycloak Config { \"realm\": \"\" } Jenkins Keycloak Object \u00b6 Field Name Type Description Default Value realm String Keycloak Realm Name","title":"Provision"},{"location":"playbooks/provision_playbook/#tavros-provision-playbook","text":"Requirements For clusters on AWS IAM Route53 Default Configuration Configuration Variables Kubernetes Cluster Object Kong Object Kong EE Credentials Object Image Registry Object Kong Instance Object Kong Instance EE Object Kuma Object Kuma Mesh Object Kuma mTLS Object Namespace Object Keycloak Object Nexus Object Elastic Cloud Object Gitea Jaeger Table of contents generated with markdown-toc This playbook will use provision a Kubernetes Cluster on AWS. It will then configure the platform components sequentially as configured, and finally commit all resource manifests to Git, for Flux to manage from that point on. The order of component configuration is as follows: * Flux v2 Toolkit - In order to provide platform GitOps * Kubeseal - In order to safely store secrets in GitOps * PostgreSQL - A central configuration database for multiple components * Namespaces - Application namespaced environments * Kuma - Service Meshes * cert-manager - TLS certificate manager for the given domain * Kong - As a API Gateway and Manager, with enterprise edition features if that is enabled * Keycloak - To provide Identity and Access Management, if enabled * Nexus - To provide repository for varios formats, if enabled * Elastic Cloud - To provide observability, if enabled * Gitea - To provide source control, if enabled * Jaeger - To provide observability, if enabled","title":"Tavros Provision Playbook"},{"location":"playbooks/provision_playbook/#requirements","text":"","title":"Requirements"},{"location":"playbooks/provision_playbook/#for-clusters-on-aws","text":"","title":"For clusters on AWS"},{"location":"playbooks/provision_playbook/#default-configuration","text":"There is a default configuration vars file that results in the following: * A Kubernetes cluster on AWS with 3x T2.XLarge masters and 2x T2.Large worker nodes. * A single Keycloak instance with two realms: 'sandbox' and 'prod'. * 2x Kuma meshes: 'sandbox' and 'prod'. * 2x Kong ingress controllers: 'sandbox' and 'prod'. The ingress controllers are part of the Kuma meshes, respectively. * 3x application namespaced environments: 'dev', 'test', and 'prod'. 'dev' and 'test' belong to the 'sandbox' Kuma mesh, and 'prod' to the 'prod' Kuma mesh. To use the default configuration: ansible-playbook playbooks/provision_playbook.yaml \\ --extra-vars '{\"cluster_name\":\"tavros\",\"cluster_domain\":\"example.com\",\"cluster_admin_email\":\"ops@example.com\"}' \\ --inventory \"playbooks/provision_playbook/default_vars.yaml\"","title":"Default Configuration"},{"location":"playbooks/provision_playbook/#configuration-variables","text":"Field Name Type Description Default Value cluster_name String Required The name of the Tavros Kubernetes cluster cluster_domain String Required The domain name to use for the platform. This should be managed by the cloud provider chosen in order to setup routes and certificates cluster_admin_email String Required The email for alerts and general notifications. kubernetes_cluster Kubernetes Cluster Object Required Configuration for the Kubernetes Cluster to be provisioned kong Kong Object Configuration for Kong kuma Kuma Object Configuration for Kuma namespaces [ Namespace Object ] An array of Namespace configurations keycloak Keycloak Object Configuration for Keycloak","title":"Configuration Variables"},{"location":"playbooks/provision_playbook/#kubernetes-cluster-object","text":"Field Name Type Description Default Value cloud String The cloud provider to provision the cluster in 'aws' master_count Integer The number of master nodes 3 master_size String The machine instance type for master nodes 'T2.Large' node_count Integer The number of worker nodes 2 node_size String The machine instance type for worker nodes 'T2.XLarge' zones String A comma separated list of availability zones in which to place the machines 'us-east-1,us-east-2' state_bucket String The name of the S3 bucket to place the cluster state in 'troubaodur' ssh_public_key String The SSH public key to setup as authorized user on provisioned machines read from ~/.ssh/id_rsa.pub aws_access_key_id String The AWS IAM AccessKeyId uses aws cli logged in user aws_secret_access_key The AWS IAM SecretAccessKey uses aws cli logged in user keycloak Kubernetes Cluster Keycloak Object Keycloak Config { \"realm\": \"\", \"client_secret\": \"\" }","title":"Kubernetes Cluster Object"},{"location":"playbooks/provision_playbook/#kubernetes-cluster-keycloak-object","text":"Field Name Type Description Default Value realm String Keycloak Realm Name client_secret String Client Secret","title":"Kubernetes Cluster Keycloak Object"},{"location":"playbooks/provision_playbook/#kong-object","text":"Field Name Type Description Default Value default_ingress_class String The default ingress controller class for other components to use 'prod' ee_creds [ Kong EE Credentials Object ] An array of Kong Enterprise Edition Credentials available for Kong instances to use instances [ Kong Instance Object ] An array of Kong instance object to be configured","title":"Kong Object"},{"location":"playbooks/provision_playbook/#kong-ee-credentials-object","text":"Field Name Type Description Default Value license String Required The Enterprise Edition license name String Required Identifier for EE Kong Instance","title":"Kong EE Credentials Object"},{"location":"playbooks/provision_playbook/#kong-instance-object","text":"Field Name Type Description Default Value name String Required The name of the Kong instance hybrid Boolean Required Deployment Type ingress_class String Required The name of the ingress class kuma_mesh_name String The name of the Kuma mesh that the Kong instance should be part of ee Kong Instance EE Object The EE configuration for the Kong instance","title":"Kong Instance Object"},{"location":"playbooks/provision_playbook/#kong-instance-ee-object","text":"Field Name Type Description Default Value enabled Boolean Whether to use Enterprise Edition false creds String The name of the Kong EE Credentials resource to use 'default' keycloak Kong Keycloak Object Keycloak Config { \"realm\": \"\", \"client_secret\": \"\" }","title":"Kong Instance EE Object"},{"location":"playbooks/provision_playbook/#kong-keycloak-object","text":"Field Name Type Description Default Value realm String Keycloak Realm Name client_secret String Client Secret","title":"Kong Keycloak Object"},{"location":"playbooks/provision_playbook/#kuma-object","text":"Field Name Type Description Default Value meshes [ Kuma Mesh Object ] The Kuma mesh configuration object","title":"Kuma Object"},{"location":"playbooks/provision_playbook/#kuma-mesh-object","text":"Field Name Type Description Default Value name String Required The name of the Kuma mesh mtls Kuma mTLS Object The mTLS configuration for the Kuma mesh","title":"Kuma Mesh Object"},{"location":"playbooks/provision_playbook/#kuma-mtls-object","text":"Field Name Type Description Default Value enabled Boolean Whether to enable mTLS false","title":"Kuma mTLS Object"},{"location":"playbooks/provision_playbook/#namespace-object","text":"Field Name Type Description Default Value name String Required The name of the Namespace kuma_mesh_name String The name of the Kuma mesh this namespace should be a part of","title":"Namespace Object"},{"location":"playbooks/provision_playbook/#keycloak-object","text":"Field Name Type Description Default Value enabled Boolean Whether to use Keycloak true realms Array of Keycloak Realms Object Enumeration of Desired Realms [{\"name\": \"sandbox\"}, {\"name\": \"prod\"}]","title":"Keycloak Object"},{"location":"playbooks/provision_playbook/#keycloak-realms-object","text":"Field Name Type Description Default Value name Boolean Whether to use Keycloak","title":"Keycloak Realms Object"},{"location":"playbooks/provision_playbook/#nexus-object","text":"Field Name Type Description Default Value enabled Boolean Whether to use Elastic Cloud true keycloak Nexus Keycloak Object Keycloak Config { \"realm\": \"\", \"client_secret\": \"\" }","title":"Nexus Object"},{"location":"playbooks/provision_playbook/#nexus-keycloak-object","text":"Field Name Type Description Default Value realm String Keycloak Realm Name client_secret String Client Secret","title":"Nexus Keycloak Object"},{"location":"playbooks/provision_playbook/#elastic-cloud-object","text":"Field Name Type Description Default Value enabled Boolean Whether to use Elastic Cloud true ee Elastic Cloud EE Object EE Config { \"enabled\": false }","title":"Elastic Cloud Object"},{"location":"playbooks/provision_playbook/#elastic-cloud-ee-object","text":"Field Name Type Description Default Value enabled Boolean Whether to use EE trial Boolean Whether to use 30 day cluster trial license licnese String License JSON keycloak Elastic Cloud Keycloak Object Keycloak Config { \"realm\": \"\", \"client_secret\": \"\" }","title":"Elastic Cloud EE Object"},{"location":"playbooks/provision_playbook/#elastic-cloud-keycloak-object","text":"Field Name Type Description Default Value realm String Keycloak Realm Name client_secret String Client Secret","title":"Elastic Cloud Keycloak Object"},{"location":"playbooks/provision_playbook/#gitea-object","text":"Field Name Type Description Default Value enabled Boolean Whether to use Gitea true","title":"Gitea Object"},{"location":"playbooks/provision_playbook/#jaeger-object","text":"Field Name Type Description Default Value enabled Boolean Whether to use Jaeger true keycloak Jaeger Keycloak Object Keycloak Config { \"realm\": \"\", \"client_secret\": \"\" }","title":"Jaeger Object"},{"location":"playbooks/provision_playbook/#jaeger-keycloak-object","text":"Field Name Type Description Default Value realm String Keycloak Realm Name client_secret String Client Secret","title":"Jaeger Keycloak Object"},{"location":"playbooks/provision_playbook/#jenkins-object","text":"Field Name Type Description Default Value enabled Boolean Whether to use Jenkins true keycloak Jenkins Keycloak Object Keycloak Config { \"realm\": \"\" }","title":"Jenkins Object"},{"location":"playbooks/provision_playbook/#jenkins-keycloak-object","text":"Field Name Type Description Default Value realm String Keycloak Realm Name","title":"Jenkins Keycloak Object"},{"location":"releases/0.1-NOTES/","text":"Changelog \u00b6 All notable changes to this project will be documented in this file. The format is based on Keep a Changelog , and this project adheres to Semantic Versioning . Unreleased \u00b6 0.1.0 - 2021-10-24 \u00b6 Added \u00b6 Changed \u00b6 Removed \u00b6","title":"0.1"},{"location":"releases/0.1-NOTES/#changelog","text":"All notable changes to this project will be documented in this file. The format is based on Keep a Changelog , and this project adheres to Semantic Versioning .","title":"Changelog"},{"location":"releases/0.1-NOTES/#unreleased","text":"","title":"Unreleased"},{"location":"releases/0.1-NOTES/#010-2021-10-24","text":"","title":"0.1.0 - 2021-10-24"},{"location":"releases/0.1-NOTES/#added","text":"","title":"Added"},{"location":"releases/0.1-NOTES/#changed","text":"","title":"Changed"},{"location":"releases/0.1-NOTES/#removed","text":"","title":"Removed"},{"location":"roles/roles/","text":"","title":"Overview"},{"location":"roles/aks/config/","text":"","title":"Config"},{"location":"roles/aks/overview/","text":"","title":"Overview"},{"location":"roles/cert-manager/config/","text":"","title":"Config"},{"location":"roles/cert-manager/overview/","text":"","title":"Overview"},{"location":"roles/elastic-cloud/config/","text":"","title":"Config"},{"location":"roles/elastic-cloud/overview/","text":"","title":"Overview"},{"location":"roles/flux/config/","text":"","title":"Config"},{"location":"roles/flux/overview/","text":"","title":"Overview"},{"location":"roles/gitea/config/","text":"","title":"Config"},{"location":"roles/gitea/overview/","text":"","title":"Overview"},{"location":"roles/jaeger/config/","text":"","title":"Config"},{"location":"roles/jaeger/overview/","text":"","title":"Overview"},{"location":"roles/jenkins/config/","text":"","title":"Config"},{"location":"roles/jenkins/overview/","text":"","title":"Overview"},{"location":"roles/keycloak/config/","text":"","title":"Config"},{"location":"roles/keycloak/overview/","text":"","title":"Overview"},{"location":"roles/kong/config/","text":"","title":"Config"},{"location":"roles/kong/overview/","text":"","title":"Overview"},{"location":"roles/kops/config/","text":"","title":"Config"},{"location":"roles/kops/overview/","text":"","title":"Overview"},{"location":"roles/kuma/config/","text":"","title":"Config"},{"location":"roles/kuma/overview/","text":"","title":"Overview"},{"location":"roles/namespace/config/","text":"","title":"Config"},{"location":"roles/namespace/overview/","text":"","title":"Overview"},{"location":"roles/nexus/config/","text":"","title":"Config"},{"location":"roles/nexus/overview/","text":"","title":"Overview"},{"location":"roles/opa-gatekeeper/config/","text":"","title":"Config"},{"location":"roles/opa-gatekeeper/overview/","text":"","title":"Overview"},{"location":"roles/postgresql/config/","text":"","title":"Config"},{"location":"roles/postgresql/overview/","text":"","title":"Overview"},{"location":"roles/sealed-secrets/config/","text":"","title":"Config"},{"location":"roles/sealed-secrets/overview/","text":"","title":"Overview"},{"location":"support/","text":"Enterprise Support \u00b6 https://www.ms3-inc.com/","title":"Overview"},{"location":"support/#enterprise-support","text":"https://www.ms3-inc.com/","title":"Enterprise Support"},{"location":"welcome/concepts/","text":"Tavros Core Concepts \u00b6 Cloud Deployments \u00b6 Infrastructure Networking \u00b6 Ansible \u00b6 Kubernetes \u00b6 Kustomize \u00b6 Helm \u00b6","title":"Concepts"},{"location":"welcome/concepts/#tavros-core-concepts","text":"","title":"Tavros Core Concepts"},{"location":"welcome/concepts/#cloud-deployments","text":"","title":"Cloud Deployments"},{"location":"welcome/concepts/#infrastructure-networking","text":"","title":"Infrastructure Networking"},{"location":"welcome/concepts/#ansible","text":"","title":"Ansible"},{"location":"welcome/concepts/#kubernetes","text":"","title":"Kubernetes"},{"location":"welcome/concepts/#kustomize","text":"","title":"Kustomize"},{"location":"welcome/concepts/#helm","text":"","title":"Helm"},{"location":"welcome/license/","text":"Apache License Version 2.0, January 2004 http://www.apache.org/licenses/ TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION Definitions. \"License\" shall mean the terms and conditions for use, reproduction, and distribution as defined by Sections 1 through 9 of this document. \"Licensor\" shall mean the copyright owner or entity authorized by the copyright owner that is granting the License. \"Legal Entity\" shall mean the union of the acting entity and all other entities that control, are controlled by, or are under common control with that entity. For the purposes of this definition, \"control\" means (i) the power, direct or indirect, to cause the direction or management of such entity, whether by contract or otherwise, or (ii) ownership of fifty percent (50%) or more of the outstanding shares, or (iii) beneficial ownership of such entity. \"You\" (or \"Your\") shall mean an individual or Legal Entity exercising permissions granted by this License. \"Source\" form shall mean the preferred form for making modifications, including but not limited to software source code, documentation source, and configuration files. \"Object\" form shall mean any form resulting from mechanical transformation or translation of a Source form, including but not limited to compiled object code, generated documentation, and conversions to other media types. \"Work\" shall mean the work of authorship, whether in Source or Object form, made available under the License, as indicated by a copyright notice that is included in or attached to the work (an example is provided in the Appendix below). \"Derivative Works\" shall mean any work, whether in Source or Object form, that is based on (or derived from) the Work and for which the editorial revisions, annotations, elaborations, or other modifications represent, as a whole, an original work of authorship. For the purposes of this License, Derivative Works shall not include works that remain separable from, or merely link (or bind by name) to the interfaces of, the Work and Derivative Works thereof. \"Contribution\" shall mean any work of authorship, including the original version of the Work and any modifications or additions to that Work or Derivative Works thereof, that is intentionally submitted to Licensor for inclusion in the Work by the copyright owner or by an individual or Legal Entity authorized to submit on behalf of the copyright owner. For the purposes of this definition, \"submitted\" means any form of electronic, verbal, or written communication sent to the Licensor or its representatives, including but not limited to communication on electronic mailing lists, source code control systems, and issue tracking systems that are managed by, or on behalf of, the Licensor for the purpose of discussing and improving the Work, but excluding communication that is conspicuously marked or otherwise designated in writing by the copyright owner as \"Not a Contribution.\" \"Contributor\" shall mean Licensor and any individual or Legal Entity on behalf of whom a Contribution has been received by Licensor and subsequently incorporated within the Work. Grant of Copyright License. Subject to the terms and conditions of this License, each Contributor hereby grants to You a perpetual, worldwide, non-exclusive, no-charge, royalty-free, irrevocable copyright license to reproduce, prepare Derivative Works of, publicly display, publicly perform, sublicense, and distribute the Work and such Derivative Works in Source or Object form. Grant of Patent License. Subject to the terms and conditions of this License, each Contributor hereby grants to You a perpetual, worldwide, non-exclusive, no-charge, royalty-free, irrevocable (except as stated in this section) patent license to make, have made, use, offer to sell, sell, import, and otherwise transfer the Work, where such license applies only to those patent claims licensable by such Contributor that are necessarily infringed by their Contribution(s) alone or by combination of their Contribution(s) with the Work to which such Contribution(s) was submitted. If You institute patent litigation against any entity (including a cross-claim or counterclaim in a lawsuit) alleging that the Work or a Contribution incorporated within the Work constitutes direct or contributory patent infringement, then any patent licenses granted to You under this License for that Work shall terminate as of the date such litigation is filed. Redistribution. You may reproduce and distribute copies of the Work or Derivative Works thereof in any medium, with or without modifications, and in Source or Object form, provided that You meet the following conditions: (a) You must give any other recipients of the Work or Derivative Works a copy of this License; and (b) You must cause any modified files to carry prominent notices stating that You changed the files; and (c) You must retain, in the Source form of any Derivative Works that You distribute, all copyright, patent, trademark, and attribution notices from the Source form of the Work, excluding those notices that do not pertain to any part of the Derivative Works; and (d) If the Work includes a \"NOTICE\" text file as part of its distribution, then any Derivative Works that You distribute must include a readable copy of the attribution notices contained within such NOTICE file, excluding those notices that do not pertain to any part of the Derivative Works, in at least one of the following places: within a NOTICE text file distributed as part of the Derivative Works; within the Source form or documentation, if provided along with the Derivative Works; or, within a display generated by the Derivative Works, if and wherever such third-party notices normally appear. The contents of the NOTICE file are for informational purposes only and do not modify the License. You may add Your own attribution notices within Derivative Works that You distribute, alongside or as an addendum to the NOTICE text from the Work, provided that such additional attribution notices cannot be construed as modifying the License. You may add Your own copyright statement to Your modifications and may provide additional or different license terms and conditions for use, reproduction, or distribution of Your modifications, or for any such Derivative Works as a whole, provided Your use, reproduction, and distribution of the Work otherwise complies with the conditions stated in this License. Submission of Contributions. Unless You explicitly state otherwise, any Contribution intentionally submitted for inclusion in the Work by You to the Licensor shall be under the terms and conditions of this License, without any additional terms or conditions. Notwithstanding the above, nothing herein shall supersede or modify the terms of any separate license agreement you may have executed with Licensor regarding such Contributions. Trademarks. This License does not grant permission to use the trade names, trademarks, service marks, or product names of the Licensor, except as required for reasonable and customary use in describing the origin of the Work and reproducing the content of the NOTICE file. Disclaimer of Warranty. Unless required by applicable law or agreed to in writing, Licensor provides the Work (and each Contributor provides its Contributions) on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied, including, without limitation, any warranties or conditions of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A PARTICULAR PURPOSE. You are solely responsible for determining the appropriateness of using or redistributing the Work and assume any risks associated with Your exercise of permissions under this License. Limitation of Liability. In no event and under no legal theory, whether in tort (including negligence), contract, or otherwise, unless required by applicable law (such as deliberate and grossly negligent acts) or agreed to in writing, shall any Contributor be liable to You for damages, including any direct, indirect, special, incidental, or consequential damages of any character arising as a result of this License or out of the use or inability to use the Work (including but not limited to damages for loss of goodwill, work stoppage, computer failure or malfunction, or any and all other commercial damages or losses), even if such Contributor has been advised of the possibility of such damages. Accepting Warranty or Additional Liability. While redistributing the Work or Derivative Works thereof, You may choose to offer, and charge a fee for, acceptance of support, warranty, indemnity, or other liability obligations and/or rights consistent with this License. However, in accepting such obligations, You may act only on Your own behalf and on Your sole responsibility, not on behalf of any other Contributor, and only if You agree to indemnify, defend, and hold each Contributor harmless for any liability incurred by, or claims asserted against, such Contributor by reason of your accepting any such warranty or additional liability. END OF TERMS AND CONDITIONS APPENDIX: How to apply the Apache License to your work. To apply the Apache License to your work, attach the following boilerplate notice, with the fields enclosed by brackets \"[]\" replaced with your own identifying information. (Don't include the brackets!) The text should be enclosed in the appropriate comment syntax for the file format. We also recommend that a file or class name and description of purpose be included on the same \"printed page\" as the copyright notice for easier identification within third-party archives. Copyright [yyyy] [name of copyright owner] Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.","title":"License"}]}