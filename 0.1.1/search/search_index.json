{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+","tags":false},"docs":[{"location":"","text":"<p> </p>","title":"About"},{"location":"#tavros","text":"<p>Tavros is a cost-effective, cloud-native, and modular integration platform composed of best-of-breed, and seamlessly integrated open-source components.</p>","title":"Tavros"},{"location":"#ansible-collection","text":"<p>The objective of the <code>ms3_inc.tavros</code> Ansible Collection is to provide the necessary Ansible Playbooks to configure, provision, and manage the Tavros Kubernetes Cluster and supported components.</p>","title":"Ansible Collection"},{"location":"#provision-playbook","text":"<p>The provision playbook provisions a Kubernetes cluster and configures Tavros's platform components, application environments, etc. All of the components are configurable through Ansible variables or the default configuration can be chosen. See the  provision playbook's documentation for more information.</p>","title":"Provision Playbook"},{"location":"#supported-platform-components","text":"Concern Component Version     Platform GitOps Flux v2 0.10.0   Platform GitOps Sealed Secrets 0.15.0   API Gateway and Manager Kong 2.3.3   API Portal Kong Enterprise Edition 2.3.3   Service Mesh Kuma 1.2.0   Identity and Access Management Keycloak 12.0.4   Artifact Management Nexus Repository Manager 3.28.1   Continuous Delivery Jenkins 2.277.4   Observability Elastic Cloud 7.13.4   Observability Jaeger 1.22.0   Static Code Qualitative Analysis Sonarqube 8.5","title":"Supported Platform Components"},{"location":"#roadmap","text":"<p>The Tavros team will maintain an up to date roadmap for major and minor releases through its Milestones.</p> <p>For items that are not yet targeting a milestone, you can see our Backlog</p>","title":"Roadmap"},{"location":"#architectural-decision-log","text":"<p>This project documents significant architectural decisions in MADR, a lightweight format for recording architectural decisions in Markdown. See our Architectural Decision Log.</p>","title":"Architectural Decision Log"},{"location":"adr/","text":"<p>This log lists the architectural decisions for Tavros.</p>  <ul> <li>ADR-0000 - Prefer Proven FOSS Components with Optional Support for Licensed Derivatives</li> <li>ADR-0001 - Apache Camel as the Default Integration Framework</li> <li>ADR-0002 - Spring Boot as the Base Application Framework</li> <li>ADR-0003 - DataSonnet as the Default Data Transformation Language</li> <li>ADR-0004 - OpenTracing for In-Process Tracing API</li> <li>ADR-0005 - Kubernetes as the Computing Platform</li> <li>ADR-0006 - Kops to Provision a Kubernetes Cluster</li> <li>ADR-0007 - Flux to Provide Platform GitOps</li> <li>ADR-0008 - Kubeseal to Securely Manage Secrets in GitOps</li> <li>ADR-0009 - Keycloak for Indetity and Access Management</li> <li>ADR-0010 - Kong as Kubernetes Ingress and API gateway</li> <li>ADR-0011 - PostgreSQL as the Platform's Default Database</li> <li>ADR-0012 - Gitea for a Lightweight Git Server</li> <li>ADR-0013 - Kuma for Service Mesh</li> <li>ADR-0014 - Jenkins for Continuous Integration</li> <li>ADR-0015 - Sonarqube for Application Static Code Analysis</li> <li>ADR-0016 - Elastic Cloud for Observability Data Aggregation and Visualization</li> <li>ADR-0017 - Jaeger for Tracing with Elasticsearch Backend</li> <li>ADR-0018 - Nexus Repository Manager for Artifact Management</li> <li>ADR-0019 - Prefer Daemonsets Over Sidecars</li> <li>ADR-0020 - Spring Cloud Config for Application Configuration Management</li> <li>ADR-0021 - Prefer Kong Enterprise Edition</li> <li>ADR-0022 - Use Ansible as the Provisioning Engine</li> <li>ADR-0023 - Helm and Operators for Component Installation and Management</li> <li>ADR-0024 - Use Ansible Collection to Structure and Package Ansible Code</li> <li>ADR-0025 - Setup Sandbox and Production Kuma Meshes and Kong Ingress Controllers</li> <li>ADR-0026 - Setup Sandbox and Production Keycloak Realms</li> <li>ADR-0027 - cert-manager for Certificate Management</li> <li>ADR-0028 - Use Markdown Architectural Decision Records</li> <li>ADR-0029 - Tavros as a Single Tenant Platform</li> </ul>  <p>For new ADRs, please use template.md as basis. More information on MADR is available at https://adr.github.io/madr/. General information about architectural decision records is available at https://adr.github.io/.</p>","title":"Architectural Decision Records"},{"location":"adr/0000-prefer-proven-foss-components-with-optional-support-for-licensed-derivatives/","text":"<ul> <li>Status: accepted</li> <li>Deciders: @k2merlinsix, @jam01</li> <li>Date: 2020-08</li> </ul>","title":"Prefer Proven FOSS Components with Optional Support for Licensed Derivatives"},{"location":"adr/0000-prefer-proven-foss-components-with-optional-support-for-licensed-derivatives/#context-and-problem-statement","text":"<p>Should we include licensed or non-FOSS components in the Tavros platform for a given component or component's feature?</p>","title":"Context and Problem Statement"},{"location":"adr/0000-prefer-proven-foss-components-with-optional-support-for-licensed-derivatives/#decision-drivers","text":"<ul> <li>Total cost of ownership</li> <li>Providing the necessary features for a competitive product</li> </ul>","title":"Decision Drivers"},{"location":"adr/0000-prefer-proven-foss-components-with-optional-support-for-licensed-derivatives/#decision-outcome","text":"<p>We will prioritize FOSS components, while providing optional support for paid or licensed derivatives, e.g.: Elastic Stack Open Source vs Enterprise subscription, Apache Camel vs JBoss Fuse, etc.</p> <p>Ultimately total cost of ownership will be the deciding factor for our customers when comparing to established alternatives. There are many FOSS components that address different concerns that we can incorporate and still provide a best-in-class platform.</p>","title":"Decision Outcome"},{"location":"adr/0000-prefer-proven-foss-components-with-optional-support-for-licensed-derivatives/#negative-consequences","text":"<ul> <li>High number of components to configure and integrate</li> </ul>","title":"Negative Consequences"},{"location":"adr/0001-apache-camel-as-the-default-integration-framework/","text":"<ul> <li>Status: accepted</li> <li>Deciders: @k2merlinsix, @jam01, @mnorton</li> <li>Date: 2020-08</li> </ul>","title":"Apache Camel as the Default Integration Framework"},{"location":"adr/0001-apache-camel-as-the-default-integration-framework/#context-and-problem-statement","text":"<p>What should be our main/default software framework for integration services?</p>","title":"Context and Problem Statement"},{"location":"adr/0001-apache-camel-as-the-default-integration-framework/#decision-drivers","text":"<ul> <li>Modern framework</li> <li>Low learning curve</li> <li>Maturity</li> <li>Solid documentation and community</li> <li>Cost</li> </ul>","title":"Decision Drivers"},{"location":"adr/0001-apache-camel-as-the-default-integration-framework/#considered-options","text":"<ul> <li>Spring Boot</li> <li>Spring Integration</li> <li>Apache Camel</li> <li>Python Flask</li> <li>Alpakka</li> <li>Go</li> </ul>","title":"Considered Options"},{"location":"adr/0001-apache-camel-as-the-default-integration-framework/#decision-outcome","text":"<p>We'll use and extend Apache Camel as our default integration framework. Given the proficiency with Java and Enterprise Integration Patterns within our company and the industry in general, Apache Camel gives our customers a straight forward and low cost migration path from existing implementations.</p>","title":"Decision Outcome"},{"location":"adr/0001-apache-camel-as-the-default-integration-framework/#positive-consequences","text":"<ul> <li>Existing proficiency with Java and EIP</li> <li>Enables re-use of Maven based artifacts, e.g.: custom exceptions, domain classes, logging layouts, CI/CD pipelines</li> <li>Lower barrier for our customers finding professional resources</li> </ul>","title":"Positive Consequences"},{"location":"adr/0001-apache-camel-as-the-default-integration-framework/#links","text":"<ul> <li>Enterprise Integration Patterns</li> <li>Apache Camel</li> <li>Spring Boot</li> <li>Spring Integration</li> <li>Alpakka</li> </ul>","title":"Links"},{"location":"adr/0002-spring-boot-as-the-base-application-framework/","text":"<ul> <li>Status: accepted</li> <li>Deciders: @k2merlinsix, @jam01, @mnorton</li> <li>Date: 2020-08</li> </ul>","title":"Spring Boot as the Base Application Framework"},{"location":"adr/0002-spring-boot-as-the-base-application-framework/#context-and-problem-statement","text":"<p>Should we add a base application framework to Apache Camel such as Spring Boot or Quarkus?</p>","title":"Context and Problem Statement"},{"location":"adr/0002-spring-boot-as-the-base-application-framework/#decision-drivers","text":"<ul> <li>Speed up development</li> <li>Maturity</li> <li>Solid documentation and community</li> </ul>","title":"Decision Drivers"},{"location":"adr/0002-spring-boot-as-the-base-application-framework/#considered-options","text":"<ul> <li>Spring Boot</li> <li>Quarkus</li> </ul>","title":"Considered Options"},{"location":"adr/0002-spring-boot-as-the-base-application-framework/#decision-outcome","text":"<p>We'll use Spring Boot as the base application framework to Apache Camel. We found that Spring Boot's auto-configuration features greatly speed up development time and it is well known and documented</p>","title":"Decision Outcome"},{"location":"adr/0002-spring-boot-as-the-base-application-framework/#positive-consequences","text":"<ul> <li>Existing proficiency with Spring Boot as part of our internal bootcamp</li> <li>Access to a bigger ecosystem, e.g.: Spring Cloud Config</li> </ul>","title":"Positive Consequences"},{"location":"adr/0002-spring-boot-as-the-base-application-framework/#links","text":"<ul> <li>Spring Boot</li> <li>Quarkus</li> </ul>","title":"Links"},{"location":"adr/0003-datasonnet-as-the-default-data-transformation-language/","text":"<ul> <li>Status: accepted</li> <li>Deciders: @k2merlinsix, @jam01, @JakeMHughes</li> <li>Date: 2020-08</li> </ul>","title":"DataSonnet as the Default Data Transformation Language"},{"location":"adr/0003-datasonnet-as-the-default-data-transformation-language/#context-and-problem-statement","text":"<p>Does DataSonnet, or can we make it, meet functional and performance requirements for modern integration workloads?</p>","title":"Context and Problem Statement"},{"location":"adr/0003-datasonnet-as-the-default-data-transformation-language/#decision-drivers","text":"<ul> <li>Provide the necessary transformation functions</li> <li>Performance</li> </ul>","title":"Decision Drivers"},{"location":"adr/0003-datasonnet-as-the-default-data-transformation-language/#decision-outcome","text":"<p>We'll extend DataSonnet and use it as our default data transformation language. Extending ModusBox' work on top of DataBrick's sjsonnet project we delivered a feature-full and very performant language.</p>","title":"Decision Outcome"},{"location":"adr/0003-datasonnet-as-the-default-data-transformation-language/#positive-consequences","text":"<ul> <li>Joint ownership with ModusBox offers great visibility to our company and offerings</li> <li>Apache 2.0 License opens possibilities of adoption by the larger community or existing projects in the same space</li> </ul>","title":"Positive Consequences"},{"location":"adr/0003-datasonnet-as-the-default-data-transformation-language/#negative-consequences","text":"<ul> <li>Lead time to delivery of the next major release</li> <li>Responsibility of maintaining and stewarding the project with the community</li> </ul>","title":"Negative Consequences"},{"location":"adr/0003-datasonnet-as-the-default-data-transformation-language/#links","text":"<ul> <li>DataSonnet Mapper Project</li> <li>DataSonnet</li> <li>Jsonnet</li> <li>sjsonnet Project</li> </ul>","title":"Links"},{"location":"adr/0004-opentracing-for-in-process-tracing-api/","text":"<ul> <li>Status: accepted</li> <li>Deciders: @jam01</li> <li>Date: 2020-08</li> </ul>","title":"OpenTracing for In-Process Tracing API"},{"location":"adr/0004-opentracing-for-in-process-tracing-api/#context-and-problem-statement","text":"<p>Which in-process tracing API should we use, OpenTracing or the new project OpenTelemetry?</p>","title":"Context and Problem Statement"},{"location":"adr/0004-opentracing-for-in-process-tracing-api/#decision-drivers","text":"<ul> <li>Existing library integrations</li> </ul>","title":"Decision Drivers"},{"location":"adr/0004-opentracing-for-in-process-tracing-api/#considered-options","text":"<ul> <li>OpenTracing</li> <li>OpenTelemetry</li> </ul>","title":"Considered Options"},{"location":"adr/0004-opentracing-for-in-process-tracing-api/#decision-outcome","text":"<p>We'll use OpenTracing for in-process tracing API. Having contributed to the OpenTracing project, and refactoring the camel-opentracing component significantly, OpenTracing provides the most functionality now while OpenTelemetry's design stabilizes.</p>","title":"Decision Outcome"},{"location":"adr/0004-opentracing-for-in-process-tracing-api/#negative-consequences","text":"<ul> <li>Will need to migrate to OpenTelemetry as it eventually deprecates OpenTracing</li> </ul>","title":"Negative Consequences"},{"location":"adr/0004-opentracing-for-in-process-tracing-api/#links","text":"<ul> <li>OpenTracing</li> <li>OpenTelemetry</li> </ul>","title":"Links"},{"location":"adr/0005-kubernetes-as-the-computing-platform/","text":"<ul> <li>Status: accepted</li> <li>Deciders: @k2merlinsix, @jam01, Mohammad Naeem</li> <li>Date: 2020-08</li> </ul>","title":"Kubernetes as the Computing Platform"},{"location":"adr/0005-kubernetes-as-the-computing-platform/#context-and-problem-statement","text":"<p>What should be our base platform?</p>","title":"Context and Problem Statement"},{"location":"adr/0005-kubernetes-as-the-computing-platform/#decision-drivers","text":"<ul> <li>Existing tooling and integrations to speed up delivery</li> </ul>","title":"Decision Drivers"},{"location":"adr/0005-kubernetes-as-the-computing-platform/#decision-outcome","text":"<p>We'll use Kubernetes as Tavros's computing platform. The adoption and support for Kubernetes has been evident for some time, most importantly tools like Kops, Helm, Operators, and Ansible's Kubernetes modules, make a great base for us to focus on delivering our platform.</p>","title":"Decision Outcome"},{"location":"adr/0006-kops-to-provision-a-kubernetes-cluster/","text":"<ul> <li>Status: accepted</li> <li>Deciders: Mohammad Naeem</li> <li>Date: 2020-08</li> </ul>","title":"Kops to Provision a Kubernetes Cluster"},{"location":"adr/0006-kops-to-provision-a-kubernetes-cluster/#context-and-problem-statement","text":"<p>In order to automate the provisioning of the Kubernetes cluster, what tools should we use?</p>","title":"Context and Problem Statement"},{"location":"adr/0006-kops-to-provision-a-kubernetes-cluster/#decision-outcome","text":"<p>We'll utilize Kops to provision Kubernetes clusters.</p>","title":"Decision Outcome"},{"location":"adr/0006-kops-to-provision-a-kubernetes-cluster/#positive-consequences","text":"<ul> <li>Support for multiple cloud providers</li> </ul>","title":"Positive Consequences"},{"location":"adr/0006-kops-to-provision-a-kubernetes-cluster/#links","text":"<ul> <li>Kops</li> </ul>","title":"Links"},{"location":"adr/0007-flux-to-provide-platform-gitops/","text":"<ul> <li>Status: accepted</li> <li>Deciders: Mohammad Naeem, @jam01, @rmccright-ms3</li> <li>Date: 2020-09</li> </ul>","title":"Flux v2 Toolkit to Provide Platform GitOps"},{"location":"adr/0007-flux-to-provide-platform-gitops/#context-and-problem-statement","text":"<p>We want to enable continuous delivery of platform and application workloads in a GitOps way. What tools should we use?</p>","title":"Context and Problem Statement"},{"location":"adr/0007-flux-to-provide-platform-gitops/#decision-drivers","text":"<ul> <li>Simplicity</li> <li>Integration with tools like Helm and Kustomize</li> </ul>","title":"Decision Drivers"},{"location":"adr/0007-flux-to-provide-platform-gitops/#considered-options","text":"<ul> <li>Flux</li> <li>Flux v2 GitOps Toolkit</li> <li>Argo CD</li> </ul>","title":"Considered Options"},{"location":"adr/0007-flux-to-provide-platform-gitops/#decision-outcome","text":"<p>We'll use Flux v2 GitOps Toolkit to enable continuous delivery of the platform and application workloads. Having had experience with Flux v1 internally, along with the newer features of v2 while still maintaining a simple workflow, it's the more appropriate tool.</p>","title":"Decision Outcome"},{"location":"adr/0007-flux-to-provide-platform-gitops/#positive-consequences","text":"<ul> <li>Flux v2 Custom Resource Definitions make it easy to utilize Flux Helm functionality before the source Git repository is up</li> <li>Alert features through integrations like Slack</li> </ul>","title":"Positive Consequences"},{"location":"adr/0007-flux-to-provide-platform-gitops/#negative-consequences","text":"<ul> <li>Have to be careful with the 'chicken and egg problem' between Flux managing the platform, and provisioning platform components through Flux</li> </ul>","title":"Negative Consequences"},{"location":"adr/0007-flux-to-provide-platform-gitops/#links","text":"<ul> <li>GitOps Guide</li> <li>Flux v2 GitOps Toolkit</li> <li>Argo CD</li> </ul>","title":"Links"},{"location":"adr/0008-kubeseal-to-securely-manage-secrets-in-gitops/","text":"<ul> <li>Status: accepted</li> <li>Deciders: @jam01, @rmccright-ms3</li> <li>Date: 2020-09</li> </ul>","title":"Kubeseal to Securely Manage Secrets in GitOps"},{"location":"adr/0008-kubeseal-to-securely-manage-secrets-in-gitops/#context-and-problem-statement","text":"<p>In order to store secrets safely in a public or private Git repository, what tool do we use?</p>","title":"Context and Problem Statement"},{"location":"adr/0008-kubeseal-to-securely-manage-secrets-in-gitops/#decision-drivers","text":"<ul> <li>Simplicity</li> <li>Integration with Flux</li> </ul>","title":"Decision Drivers"},{"location":"adr/0008-kubeseal-to-securely-manage-secrets-in-gitops/#decision-outcome","text":"<p>We'll use Bitnami's Sealed Secrets controller to securely manage secrets in GitOps. The sealed secrets can be decrypted only by the controller running in your cluster and nobody else can obtain the original secret, even if they have access to the Git repository.</p>","title":"Decision Outcome"},{"location":"adr/0008-kubeseal-to-securely-manage-secrets-in-gitops/#links","text":"<ul> <li>Flux Sealed Secrets recommendation</li> <li>Sealed Secrets project</li> </ul>","title":"Links"},{"location":"adr/0009-keycloak-for-indetity-and-access-management/","text":"<ul> <li>Status: accepted</li> <li>Deciders: Mohammad Naeem</li> <li>Date: 2020-08</li> </ul>","title":"Keycloak for Identity and Access Management"},{"location":"adr/0009-keycloak-for-indetity-and-access-management/#context-and-problem-statement","text":"<p>To provide user identity and access management, what component do we use?</p>","title":"Context and Problem Statement"},{"location":"adr/0009-keycloak-for-indetity-and-access-management/#decision-outcome","text":"<p>We'll use Keycloak for identity and access management.</p>","title":"Decision Outcome"},{"location":"adr/0009-keycloak-for-indetity-and-access-management/#links","text":"<ul> <li>Keycloak</li> </ul>","title":"Links"},{"location":"adr/0010-kong-as-kubernetes-ingress-and-api-gateway/","text":"<ul> <li>Status: accepted</li> <li>Deciders: @k2merlinsix</li> <li>Date: 2020-08</li> </ul>","title":"Kong as Kubernetes Ingress Controller and API Gateway"},{"location":"adr/0010-kong-as-kubernetes-ingress-and-api-gateway/#context-and-problem-statement","text":"<p>Which component should serve as our Kubernetes Ingress Controller, to do load balancing and proxying?</p> <p>Which component should serve as our API Gateway? How easy is it to tie into the application networking of the Ingress Controller?</p>","title":"Context and Problem Statement"},{"location":"adr/0010-kong-as-kubernetes-ingress-and-api-gateway/#decision-drivers","text":"<ul> <li>Network performance</li> <li>Feature set of API Gateway</li> </ul>","title":"Decision Drivers"},{"location":"adr/0010-kong-as-kubernetes-ingress-and-api-gateway/#considered-options","text":"<ul> <li>NGINX</li> <li>Kong</li> <li>Apigee</li> <li>KrakenD</li> </ul>","title":"Considered Options"},{"location":"adr/0010-kong-as-kubernetes-ingress-and-api-gateway/#decision-outcome","text":"<p>Kong will be our Kubernetes Ingress Controller and API Gateway as well. Having a single component perform both functions should make it easier to maintain and more performant.</p>","title":"Decision Outcome"},{"location":"adr/0010-kong-as-kubernetes-ingress-and-api-gateway/#positive-consequences","text":"<ul> <li>Enterprise Edition pricing is more cost effective than some alternatives</li> </ul>","title":"Positive Consequences"},{"location":"adr/0010-kong-as-kubernetes-ingress-and-api-gateway/#negative-consequences","text":"<ul> <li>Lua as the main language for developing plugins</li> </ul>","title":"Negative Consequences"},{"location":"adr/0010-kong-as-kubernetes-ingress-and-api-gateway/#links","text":"<ul> <li>Kong</li> <li>NGINX</li> <li>Apigee</li> <li>KrakenD</li> </ul>","title":"Links"},{"location":"adr/0011-postgresql-as-the-platforms-default-database/","text":"<ul> <li>Status: accepted</li> <li>Deciders: Mohammad Naeem</li> <li>Date: 2020-09</li> </ul>","title":"PostgreSQL as the Platform's Default Database"},{"location":"adr/0011-postgresql-as-the-platforms-default-database/#context-and-problem-statement","text":"<p>Some components require a PostgreSQL database, how do we accommodate each one and future components?</p>","title":"Context and Problem Statement"},{"location":"adr/0011-postgresql-as-the-platforms-default-database/#decision-outcome","text":"<p>We'll use PostgreSQL as the platform's default database. Since Gitea and Keycloak require a PostgreSQL database we'll setup a single server and dynamically create what's needed for each component that uses PostgreSQL. If it's an option to use PostgreSQL for future components, we'll use that.</p>","title":"Decision Outcome"},{"location":"adr/0011-postgresql-as-the-platforms-default-database/#positive-consequences","text":"<ul> <li>Single instance to backup, and restore in case of a disaster recovery</li> </ul>","title":"Positive Consequences"},{"location":"adr/0012-gitea-for-a-lightweight-git-server/","text":"<ul> <li>Status: accepted</li> <li>Deciders: Mohammad Naeem, @jam01</li> <li>Date: 2020-09</li> </ul>","title":"Gitea for a Lightweight Git Server"},{"location":"adr/0012-gitea-for-a-lightweight-git-server/#context-and-problem-statement","text":"<p>Given that Flux requires a Git repository to provide GitOps, and that our CI/CD pipelines will require the same for continuous delivery, what component should be our default/bundled Git server?</p>","title":"Context and Problem Statement"},{"location":"adr/0012-gitea-for-a-lightweight-git-server/#decision-drivers","text":"<ul> <li>Lightweight as we expect a number of customers will already have a Git saas</li> <li>Easy to integrate</li> </ul>","title":"Decision Drivers"},{"location":"adr/0012-gitea-for-a-lightweight-git-server/#considered-options","text":"<ul> <li>GitLab</li> <li>Gitea</li> </ul>","title":"Considered Options"},{"location":"adr/0012-gitea-for-a-lightweight-git-server/#decision-outcome","text":"<p>We'll use Gitea as our bundled and lightweight Git server. Gitea is more lightweight than the alternatives, and has the necessary APIs for us to integrate with.</p>","title":"Decision Outcome"},{"location":"adr/0012-gitea-for-a-lightweight-git-server/#negative-consequences","text":"<ul> <li>No out of the box integration with Flux</li> </ul>","title":"Negative Consequences"},{"location":"adr/0012-gitea-for-a-lightweight-git-server/#links","text":"<ul> <li>Gitea</li> <li>GitLab</li> </ul>","title":"Links"},{"location":"adr/0013-kuma-for-service-mesh/","text":"<ul> <li>Status: accepted</li> <li>Deciders: @k2merlinsix</li> <li>Date: 2020-08</li> </ul>","title":"Kuma for Service Mesh"},{"location":"adr/0013-kuma-for-service-mesh/#context-and-problem-statement","text":"<p>Service meshes helps to address cross cutting concerns so that application developers don't have to, what service mesh component should we use?</p>","title":"Context and Problem Statement"},{"location":"adr/0013-kuma-for-service-mesh/#decision-drivers","text":"<ul> <li>Performance</li> <li>Feature set</li> </ul>","title":"Decision Drivers"},{"location":"adr/0013-kuma-for-service-mesh/#considered-options","text":"<ul> <li>Kuma</li> <li>Istio</li> </ul>","title":"Considered Options"},{"location":"adr/0013-kuma-for-service-mesh/#decision-outcome","text":"<p>We'll use Kuma for service mesh.</p>","title":"Decision Outcome"},{"location":"adr/0013-kuma-for-service-mesh/#positive-consequences","text":"<ul> <li>Seamless integration with Kong</li> </ul>","title":"Positive Consequences"},{"location":"adr/0013-kuma-for-service-mesh/#links","text":"<ul> <li>Kuma</li> </ul>","title":"Links"},{"location":"adr/0014-jenkins-for-continuous-integration/","text":"<ul> <li>Status: accepted</li> <li>Deciders: @jam01</li> <li>Date: 2020-09</li> </ul>","title":"Jenkins for Continuous Integration"},{"location":"adr/0014-jenkins-for-continuous-integration/#context-and-problem-statement","text":"<p>We'll be using Flux for continuous deployment, leaving us to choose a component for continuous delivery, i.e.: building and running tests against artifacts before deploying.</p>","title":"Context and Problem Statement"},{"location":"adr/0014-jenkins-for-continuous-integration/#decision-drivers","text":"<ul> <li>Existing proficiency and pipelines</li> <li>Simplicity</li> </ul>","title":"Decision Drivers"},{"location":"adr/0014-jenkins-for-continuous-integration/#considered-options","text":"<ul> <li>Jenkins</li> <li>Jenkins X</li> <li>Tekton</li> </ul>","title":"Considered Options"},{"location":"adr/0014-jenkins-for-continuous-integration/#decision-outcome","text":"<p>We'll use Jenkins as our CI component. Since we're using Flux for deployment we don't need too Kubernetes specific features like Jenkins X has, and Jenkins can support for complex pipelines than Tekton.</p>","title":"Decision Outcome"},{"location":"adr/0014-jenkins-for-continuous-integration/#positive-consequences","text":"<ul> <li>Can re-use existing pipelines with little modification</li> </ul>","title":"Positive Consequences"},{"location":"adr/0014-jenkins-for-continuous-integration/#negative-consequences","text":"<ul> <li>Less 'modern' than other options</li> </ul>","title":"Negative Consequences"},{"location":"adr/0014-jenkins-for-continuous-integration/#links","text":"<ul> <li>Jenkins X</li> <li>Jenkins</li> <li>Tekton Project</li> </ul>","title":"Links"},{"location":"adr/0015-sonarqube-for-application-static-code-analysis/","text":"<ul> <li>Status: accepted</li> <li>Deciders: @jam01</li> <li>Date: 2020-10</li> </ul>","title":"Sonarqube for Application Static Code Analysis"},{"location":"adr/0015-sonarqube-for-application-static-code-analysis/#context-and-problem-statement","text":"<p>We understand the value of automated code qualitative analysis and that it's often an afterthought. Should we bundle a static code analysis component?</p>","title":"Context and Problem Statement"},{"location":"adr/0015-sonarqube-for-application-static-code-analysis/#decision-outcome","text":"<p>We'll use Sonarqube for application static code analysis. As part of our effort to offer a ready best-practices platform we'll setup Sonarqube and tie it into template or default CI/CD pipelines.</p>","title":"Decision Outcome"},{"location":"adr/0015-sonarqube-for-application-static-code-analysis/#links","text":"<ul> <li>Sonarqube</li> </ul>","title":"Links"},{"location":"adr/0016-elastic-cloud-for-observability-data-aggregation-and-visualization/","text":"<ul> <li>Status: accepted</li> <li>Deciders: @jam01, @k2merlinsix</li> <li>Date: 2020-10</li> </ul>","title":"Elastic Cloud for Observability Data Aggregation and Visualization"},{"location":"adr/0016-elastic-cloud-for-observability-data-aggregation-and-visualization/#context-and-problem-statement","text":"<p>In a microservices architectural system observability is imperative, what components should we use for that?</p>","title":"Context and Problem Statement"},{"location":"adr/0016-elastic-cloud-for-observability-data-aggregation-and-visualization/#decision-drivers","text":"<ul> <li>Cost</li> <li>Feature set</li> </ul>","title":"Decision Drivers"},{"location":"adr/0016-elastic-cloud-for-observability-data-aggregation-and-visualization/#considered-options","text":"<ul> <li>Elastic Cloud</li> <li>Jaeger</li> </ul>","title":"Considered Options"},{"location":"adr/0016-elastic-cloud-for-observability-data-aggregation-and-visualization/#decision-outcome","text":"<p>We'll use Elastic Cloud on Kubernetes for Observability Data Aggregation and Visualization. Elastic, Logstash and Kibana offer what we need for logging data. Aditionally, we can use APM server to get trace data from either Elastic's own apm agent or a Jaeger client.</p>","title":"Decision Outcome"},{"location":"adr/0016-elastic-cloud-for-observability-data-aggregation-and-visualization/#positive-consequences","text":"<ul> <li>A single pane of glass for observability</li> <li>Less components to coordinate</li> </ul>","title":"Positive Consequences"},{"location":"adr/0016-elastic-cloud-for-observability-data-aggregation-and-visualization/#negative-consequences","text":"<ul> <li>Valuable service dependency DAG only on license subscription</li> </ul>","title":"Negative Consequences"},{"location":"adr/0016-elastic-cloud-for-observability-data-aggregation-and-visualization/#links","text":"<ul> <li>Elastic Cloud on Kubernetes</li> <li>Elastic Stack Pricing</li> <li>Elastic with Jaeger</li> <li>ECK project</li> <li>Follow up decision to use Jaeger for Tracing ADR-0017</li> </ul>","title":"Links"},{"location":"adr/0017-jaeger-for-tracing-with-elasticsearch-backend/","text":"<ul> <li>Status: accepted</li> <li>Deciders: @jam01</li> <li>Date: 2020-10</li> </ul>","title":"Jaeger for Tracing with Elasticsearch Backend"},{"location":"adr/0017-jaeger-for-tracing-with-elasticsearch-backend/#context-and-problem-statement","text":"<p>In a microservices architectural system observability is imperative, and Elastic Stack Open Source does not offer service dependency DAG. Can/should we fill in that feature with another component?</p>","title":"Context and Problem Statement"},{"location":"adr/0017-jaeger-for-tracing-with-elasticsearch-backend/#decision-drivers","text":"<ul> <li>Cost</li> <li>Feature set</li> </ul>","title":"Decision Drivers"},{"location":"adr/0017-jaeger-for-tracing-with-elasticsearch-backend/#considered-options","text":"<ul> <li>Elastic Stack</li> <li>Jaeger</li> </ul>","title":"Considered Options"},{"location":"adr/0017-jaeger-for-tracing-with-elasticsearch-backend/#decision-outcome","text":"<p>We'll use Jaeger by default for tracing data, with Elasticsearch as the backend. Using Jaeger enables a service DAG that's very valuable and using elasticsearch as the backend enables data aggregation and analysis in Kibana.</p>","title":"Decision Outcome"},{"location":"adr/0017-jaeger-for-tracing-with-elasticsearch-backend/#positive-consequences","text":"<ul> <li>Value of the service DAG dependency graph</li> <li>Maintain the ability to cross reference logs and trace data in a single pane</li> <li>Jaeger has closer participation to OpenTracing/Telemetry projects than Elastic</li> </ul>","title":"Positive Consequences"},{"location":"adr/0017-jaeger-for-tracing-with-elasticsearch-backend/#negative-consequences","text":"<ul> <li>Another integration point</li> <li>Must correlate logs and traces in Camel through MDC</li> </ul>","title":"Negative Consequences"},{"location":"adr/0017-jaeger-for-tracing-with-elasticsearch-backend/#links","text":"<ul> <li>Jaeger</li> <li>Elastic with Jaeger</li> <li>Jaeger Operator</li> <li>Article Jaeger Elasticsearch and Kibana</li> <li>Article Distributed Tracing with Jaeger and the ELK Stack</li> <li>Article Exploring Jaeger traces with Elastic APM</li> </ul>","title":"Links"},{"location":"adr/0018-nexus-repository-manager-for-artifact-management/","text":"<ul> <li>Status: accepted</li> <li>Deciders: @jam01, @k2merlinsix</li> <li>Date: 2020-10</li> </ul>","title":"Nexus Repository Manager for Artifact Management"},{"location":"adr/0018-nexus-repository-manager-for-artifact-management/#context-and-problem-statement","text":"<p>In a solid continuous delivery configuration an enterprise needs to have a history of application builds an ability to rollback deployments as necessary. What artifact manager component should we use?</p>","title":"Context and Problem Statement"},{"location":"adr/0018-nexus-repository-manager-for-artifact-management/#decision-drivers","text":"<ul> <li>Stability</li> </ul>","title":"Decision Drivers"},{"location":"adr/0018-nexus-repository-manager-for-artifact-management/#considered-options","text":"<ul> <li>Nexus Repository Manager</li> <li>JFrog Artifactory</li> </ul>","title":"Considered Options"},{"location":"adr/0018-nexus-repository-manager-for-artifact-management/#decision-outcome","text":"<p>We'll use Nexus repository manager for artifact management. Sonatype is one of the main stewards/contributors of Maven and therefore their platform is one of the most mature. In order to deliver a best practices continuous delivery configuration we'll tie in Nexus into our CI/CD pipelines.</p>","title":"Decision Outcome"},{"location":"adr/0018-nexus-repository-manager-for-artifact-management/#positive-consequences","text":"<ul> <li>Available commercial support from Nexus</li> </ul>","title":"Positive Consequences"},{"location":"adr/0018-nexus-repository-manager-for-artifact-management/#links","text":"<ul> <li>Nexus Repository Manager OSS</li> <li>JFrog Artifactory</li> </ul>","title":"Links"},{"location":"adr/0019-prefer-daemonsets-over-sidecars/","text":"<ul> <li>Status: accepted</li> <li>Deciders: @jam01</li> <li>Date: 2020-11</li> </ul>","title":"Prefer Daemonsets over Sidecars"},{"location":"adr/0019-prefer-daemonsets-over-sidecars/#context-and-problem-statement","text":"<p>Kubernetes supports deploying workloads as daemonsets or sidecars. For example, when deploying Jaeger Agent for reporting trace data, in a DaemonSet strategy there will be a single Agent deployment in every Kubernetes node, so all applications' Jaeger Client in a single node share the same agent. Conversely, in a side-car strategy each application will have its own dedicated Jaeger Agent deployment, requiring extra resources.</p> <p>Which should we favor for cross cutting concern deployments?</p>","title":"Context and Problem Statement"},{"location":"adr/0019-prefer-daemonsets-over-sidecars/#decision-drivers","text":"<ul> <li>Cost</li> </ul>","title":"Decision Drivers"},{"location":"adr/0019-prefer-daemonsets-over-sidecars/#considered-options","text":"<ul> <li>Sidecars</li> <li>Daemonsets</li> </ul>","title":"Considered Options"},{"location":"adr/0019-prefer-daemonsets-over-sidecars/#decision-outcome","text":"<p>We'll prefer daemonsets over sidecar deployments whenever there is the option. Given that Tavros is designed as a single tenant platform there are computing resource savings when using daemonsets (deployment per node) vs sidecars (deployment per service).</p>","title":"Decision Outcome"},{"location":"adr/0019-prefer-daemonsets-over-sidecars/#positive-consequences","text":"<ul> <li>Less resource utilization</li> </ul>","title":"Positive Consequences"},{"location":"adr/0019-prefer-daemonsets-over-sidecars/#negative-consequences","text":"<ul> <li>Would have to refactor in order to support multi-tenancy</li> </ul>","title":"Negative Consequences"},{"location":"adr/0019-prefer-daemonsets-over-sidecars/#links","text":"<ul> <li>DaemonSet</li> <li>See about single tenancy in ADR-0029</li> </ul>","title":"Links"},{"location":"adr/0020-spring-cloud-config-for-application-configuration-management/","text":"<ul> <li>Status: accepted</li> <li>Deciders: @jam01</li> <li>Date: 2020-11</li> </ul>","title":"Spring Cloud Config for Application Configuration Management"},{"location":"adr/0020-spring-cloud-config-for-application-configuration-management/#context-and-problem-statement","text":"<p>In a solid continuous delivery configuration an enterprise needs to manage application configuration properties independently of the application source code. What component should we use?</p>","title":"Context and Problem Statement"},{"location":"adr/0020-spring-cloud-config-for-application-configuration-management/#decision-drivers","text":"<ul> <li>Flexible backend support</li> <li>Easy integration with Camel and Spring Boot</li> </ul>","title":"Decision Drivers"},{"location":"adr/0020-spring-cloud-config-for-application-configuration-management/#considered-options","text":"<ul> <li>Spring Cloud Config</li> </ul>","title":"Considered Options"},{"location":"adr/0020-spring-cloud-config-for-application-configuration-management/#decision-outcome","text":"<p>We'll use spring cloud config as our application configuration manager. Spring cloud config is very simple to integrate since we chose Spring Boot as our base application framework. We'll use a Git backend from Gitea which will allow our customers to keep a history of changes and enable rollback.</p>","title":"Decision Outcome"},{"location":"adr/0020-spring-cloud-config-for-application-configuration-management/#positive-consequences","text":"<ul> <li>Simple integration to Spring Boot</li> </ul>","title":"Positive Consequences"},{"location":"adr/0020-spring-cloud-config-for-application-configuration-management/#links","text":"<ul> <li>Spring Cloud Config</li> </ul>","title":"Links"},{"location":"adr/0021-prefer-kong-enterprise-edition/","text":"<ul> <li>Status: accepted</li> <li>Deciders: @k2merlinsix</li> <li>Date: 2020-11</li> </ul>","title":"Prefer Kong Enterprise Edition"},{"location":"adr/0021-prefer-kong-enterprise-edition/#context-and-problem-statement","text":"<p>Given that we've chosen Kong as our Ingress Controller and API Gateway, but we're still missing an API Manager and Developer Portal.</p>","title":"Context and Problem Statement"},{"location":"adr/0021-prefer-kong-enterprise-edition/#decision-drivers","text":"<ul> <li>Feature set</li> </ul>","title":"Decision Drivers"},{"location":"adr/0021-prefer-kong-enterprise-edition/#decision-outcome","text":"<p>We'll recommend Kong enterprise edition in order to enable API manager and developer portal features. API manager and developer portal features are not necessary but they are valuable, supporting Kong EE as an optional component is an acceptable compromise to offer that value to our customers.</p>","title":"Decision Outcome"},{"location":"adr/0021-prefer-kong-enterprise-edition/#positive-consequences","text":"<ul> <li>Single component for all API related functionality</li> </ul>","title":"Positive Consequences"},{"location":"adr/0021-prefer-kong-enterprise-edition/#negative-consequences","text":"<ul> <li>Requires a license</li> </ul>","title":"Negative Consequences"},{"location":"adr/0021-prefer-kong-enterprise-edition/#links","text":"<ul> <li>Kong Enterprise</li> </ul>","title":"Links"},{"location":"adr/0022-use-ansible-as-the-provisioning-engine/","text":"<ul> <li>Status: accepted</li> <li>Deciders: Mohammad Naeem, @jam01</li> <li>Date: 2020-11</li> </ul>","title":"Use Ansible as Provisioning Engine"},{"location":"adr/0022-use-ansible-as-the-provisioning-engine/#context-and-problem-statement","text":"<p>[Describe the context and problem statement, e.g., in free form using two to three sentences. You may want to articulate the problem in form of a question.]</p>","title":"Context and Problem Statement"},{"location":"adr/0022-use-ansible-as-the-provisioning-engine/#decision-drivers","text":"<ul> <li>Flexibility</li> <li>Maintainability</li> </ul>","title":"Decision Drivers"},{"location":"adr/0022-use-ansible-as-the-provisioning-engine/#considered-options","text":"<ul> <li>Bash</li> <li>Ansible</li> </ul>","title":"Considered Options"},{"location":"adr/0022-use-ansible-as-the-provisioning-engine/#decision-outcome","text":"<p>We'll use Ansible as the provisioning engine. Ansible modules, variable handling, Jinja 2 templating, and Kubernetes module make it easier to install and configure components. Helm Charts use the same templating language, and the Operator SDK has support for Ansible, if we decide to build an Operator.</p>","title":"Decision Outcome"},{"location":"adr/0022-use-ansible-as-the-provisioning-engine/#positive-consequences","text":"<ul> <li>Ansible being a desired-state engine enables idempotency</li> <li>Simpler setup</li> </ul>","title":"Positive Consequences"},{"location":"adr/0022-use-ansible-as-the-provisioning-engine/#negative-consequences","text":"<ul> <li>A learning curve to Ansible, playbooks, roles, etc</li> </ul>","title":"Negative Consequences"},{"location":"adr/0022-use-ansible-as-the-provisioning-engine/#links","text":"<ul> <li>Ansible</li> <li>Kubernetes Ansible</li> <li>Ansible Operator SDK</li> </ul>","title":"Links"},{"location":"adr/0023-helm-and-operators-for-component-installation-and-management/","text":"<ul> <li>Status: accepted</li> <li>Deciders: @jam01, @rmccright-ms3</li> <li>Date: 2020-11</li> </ul>","title":"Helm and Operators for Component Installation and Management"},{"location":"adr/0023-helm-and-operators-for-component-installation-and-management/#context-and-problem-statement","text":"<p>We're currently installing components ad-hoc through directly modified Kubernetes manifests from helm charts. This removes the ability to use Helm's upgrade features. This is done because we can't use Helm until Flux is up and running, and Flux depends on other components being installed before.</p>","title":"Context and Problem Statement"},{"location":"adr/0023-helm-and-operators-for-component-installation-and-management/#decision-drivers","text":"<ul> <li>Ability to use Helm upgrades</li> <li>Minimize hand crafted manifests</li> </ul>","title":"Decision Drivers"},{"location":"adr/0023-helm-and-operators-for-component-installation-and-management/#considered-options","text":"<ul> <li>Helm releases through Flux v2</li> <li>Operators</li> </ul>","title":"Considered Options"},{"location":"adr/0023-helm-and-operators-for-component-installation-and-management/#decision-outcome","text":"<p>We'll use Helm releases and Operators custom resources for component installation and management. Given that we're now using Flux v2 we can use their Helm release functionality before any Git repository is available, this way we can do Helm releases through Flux and eventually commit them to Git to enable GitOps from that point on. Kubernets Operators enable a higher level of component lifecycle management, these should always be preferred to Helm whenever available.</p>","title":"Decision Outcome"},{"location":"adr/0023-helm-and-operators-for-component-installation-and-management/#positive-consequences","text":"<ul> <li>Upon provisioning the platform it will be entirely driven by GitOps</li> <li>Will be able to do component upgrades through Helm releases</li> <li>Less custom code by using official functionality as available</li> </ul>","title":"Positive Consequences"},{"location":"adr/0023-helm-and-operators-for-component-installation-and-management/#links","text":"<ul> <li>Helm</li> <li>Operator Pattern</li> <li>Operator Hub</li> <li>Flux v2 Helm Controller</li> </ul>","title":"Links"},{"location":"adr/0024-use-ansible-collection-to-structure-and-package-ansible-code/","text":"<ul> <li>Status: accepted</li> <li>Deciders: @jam01</li> <li>Date: 2020-11</li> </ul>","title":"Use Ansible Collection to Structure and Package Ansible Code"},{"location":"adr/0024-use-ansible-collection-to-structure-and-package-ansible-code/#context-and-problem-statement","text":"<p>How do we package multiple playbooks, plugins, and how do we distribute them when creating a customer's platform?</p> <p>Designing pre-configured components and their extension points through Kustomizations is increasingly complex. Is there a way to simplify and make it more maintainable?</p>","title":"Context and Problem Statement"},{"location":"adr/0024-use-ansible-collection-to-structure-and-package-ansible-code/#decision-drivers","text":"<ul> <li>Maintainability of the code</li> <li>Easier to add customer configurability of components</li> <li>Support for distribution</li> </ul>","title":"Decision Drivers"},{"location":"adr/0024-use-ansible-collection-to-structure-and-package-ansible-code/#considered-options","text":"<ul> <li>Ansible Collection</li> </ul>","title":"Considered Options"},{"location":"adr/0024-use-ansible-collection-to-structure-and-package-ansible-code/#decision-outcome","text":"<p>We'll use Ansible Collection structure and packaging for our Ansible code. We'll refactor the platform from multiple layers of Kustomizations to be entirely driven by an Ansible Collection. Ansible is migrating all their re-usable artifacts to be Collections so that seems to be where all support and tooling is to be found, including distribution from a git repository. Moving the component configuration and extension points to Ansible makes it much easier to structure and maintain, as well as add points of extension.</p>","title":"Decision Outcome"},{"location":"adr/0024-use-ansible-collection-to-structure-and-package-ansible-code/#positive-consequences","text":"<ul> <li>Higher maintainability as it's all Ansible</li> <li>Easier to add customer configurability as everything can be templated</li> </ul>","title":"Positive Consequences"},{"location":"adr/0024-use-ansible-collection-to-structure-and-package-ansible-code/#negative-consequences","text":"<ul> <li>A bit more complexity</li> </ul>","title":"Negative Consequences"},{"location":"adr/0024-use-ansible-collection-to-structure-and-package-ansible-code/#links","text":"<ul> <li>Using Collections</li> <li>Blog The Future of Ansible Content Delivery</li> <li>Blog Hands on with Ansible collections</li> </ul>","title":"Links"},{"location":"adr/0025-setup-sandbox-and-production-kuma-meshes-and-kong-ingress-controllers/","text":"<ul> <li>Status: accepted</li> <li>Deciders: @jam01, @rmccright-ms3</li> <li>Date: 2020-11</li> </ul>","title":"Setup Sandbox and Production Kuma Meshes and Kong Ingress Controllers"},{"location":"adr/0025-setup-sandbox-and-production-kuma-meshes-and-kong-ingress-controllers/#context-and-problem-statement","text":"<p>What should be our default service mesh and application environments look like? Given that we'll enable mutual TLS on the meshes, each mesh will require a Kong Ingress Controller which in turn requires a Load Balancer from the cloud provider.</p>","title":"Context and Problem Statement"},{"location":"adr/0025-setup-sandbox-and-production-kuma-meshes-and-kong-ingress-controllers/#decision-drivers","text":"<ul> <li>Must reflect best practice configuration</li> <li>Segregate production from non-production workloads as much as possible</li> <li>Satisfy 'common' enterprise requirements</li> <li>Cost</li> </ul>","title":"Decision Drivers"},{"location":"adr/0025-setup-sandbox-and-production-kuma-meshes-and-kong-ingress-controllers/#considered-options","text":"<ul> <li>One dev, one test, and one production environment, all segregated through Kuma meshes</li> <li>Dev and test environments separated by kuma meshes in one cluster, production in another</li> <li>Dev and test environments in one 'sandbox' kuma mesh, production in a 'production' mesh</li> </ul>","title":"Considered Options"},{"location":"adr/0025-setup-sandbox-and-production-kuma-meshes-and-kong-ingress-controllers/#decision-outcome","text":"<p>We'll setup a Sandbox and Production Kuma mesh, sandbox will have a dev and test namespaced environment, and production will have the production namespaced environment. The service mesh and mutual TLS plugin enforces the segregation of non-production (aka sandbox) environments and the production environment to where we don't fuctionally need a separate cluster. Moreover aggregating dev and test into a sandbox mesh saves us provisioning a load balancer for each environment, so we could support any arbitrary environment configuration needs.</p>","title":"Decision Outcome"},{"location":"adr/0025-setup-sandbox-and-production-kuma-meshes-and-kong-ingress-controllers/#positive-consequences","text":"<ul> <li>Reduced cost of extra load balancer</li> <li>Reduced complexity of dedicated cluster</li> </ul>","title":"Positive Consequences"},{"location":"adr/0025-setup-sandbox-and-production-kuma-meshes-and-kong-ingress-controllers/#negative-consequences","text":"<ul> <li>Learning curve of service mesh mutual TLS enforcement</li> <li>Sandboxed environments can still communicate with each other</li> </ul>","title":"Negative Consequences"},{"location":"adr/0025-setup-sandbox-and-production-kuma-meshes-and-kong-ingress-controllers/#links","text":"<ul> <li>Kuma mTLS</li> <li>Kuma Gateway</li> </ul>","title":"Links"},{"location":"adr/0026-setup-sandbox-and-production-keycloak-realms/","text":"<ul> <li>Status: accepted</li> <li>Deciders: @jam01, @rmccright-ms3</li> <li>Date: 2020-11</li> </ul>","title":"Setup Sandbox and Production Keycloak Realms"},{"location":"adr/0026-setup-sandbox-and-production-keycloak-realms/#context-and-problem-statement","text":"<p>Keycloak enables separation of sets of users, groups, roles, etc. through Realms. Should we create separate realms by default, which ones?</p>","title":"Context and Problem Statement"},{"location":"adr/0026-setup-sandbox-and-production-keycloak-realms/#decision-drivers","text":"<ul> <li>Must reflect best practice configuration</li> <li>Segregate production from non-production workloads as much as possible</li> <li>Satisfy 'common' enterprise requirements</li> </ul>","title":"Decision Drivers"},{"location":"adr/0026-setup-sandbox-and-production-keycloak-realms/#considered-options","text":"<ul> <li>Leave single Master realm</li> <li>Create one production realm</li> <li>Create sandbox and production realms</li> </ul>","title":"Considered Options"},{"location":"adr/0026-setup-sandbox-and-production-keycloak-realms/#decision-outcome","text":"<p>We'll create sandbox and production keycloak realms. Given the existing inclusion of sandbox and production concepts through service mesh and ingress controllers, these realms make a simple and easy to understand separation of users that allows customers to also test and promote identity and access management policies in a similar way to application workloads. We've seen enterprises do this with okta and okta preview instances for example.</p>","title":"Decision Outcome"},{"location":"adr/0026-setup-sandbox-and-production-keycloak-realms/#positive-consequences","text":"<ul> <li>Simple, easy to understand</li> <li>Enables identity and access management separation</li> </ul>","title":"Positive Consequences"},{"location":"adr/0026-setup-sandbox-and-production-keycloak-realms/#negative-consequences","text":"<ul> <li>May be unnecessary for some organizations</li> </ul>","title":"Negative Consequences"},{"location":"adr/0026-setup-sandbox-and-production-keycloak-realms/#links","text":"<ul> <li>Keycloak Concetps</li> </ul>","title":"Links"},{"location":"adr/0027-cert-manager-for-certificate-management/","text":"<ul> <li>Status: accepted</li> <li>Deciders: @jam01</li> <li>Date: 2020-11</li> </ul>","title":"cert-manager for Certificate Management"},{"location":"adr/0027-cert-manager-for-certificate-management/#context-and-problem-statement","text":"<p>The platform will required TLS certificates to signed by well known CAs. What tool do we use for generate those certificates?</p>","title":"Context and Problem Statement"},{"location":"adr/0027-cert-manager-for-certificate-management/#decision-drivers","text":"<ul> <li>Automation, including rotation before expiration</li> <li>Cost</li> </ul>","title":"Decision Drivers"},{"location":"adr/0027-cert-manager-for-certificate-management/#considered-options","text":"<ul> <li>cert-manager</li> </ul>","title":"Considered Options"},{"location":"adr/0027-cert-manager-for-certificate-management/#decision-outcome","text":"<p>We'll use cert-manager as our certificate manager. cert-manager is the best known certificate manager for Kubernetes, it will automatically generate certificates as they're request by Ingress TLS configuration and will automatically re-generate them before they expire. For CA we'll use Let's Encrypt which is free.</p>","title":"Decision Outcome"},{"location":"adr/0027-cert-manager-for-certificate-management/#positive-consequences","text":"<ul> <li>Automatic generation and re-generation</li> </ul>","title":"Positive Consequences"},{"location":"adr/0027-cert-manager-for-certificate-management/#negative-consequences","text":"<ul> <li>Let's Encrypt limit of 50 certificates per week</li> </ul>","title":"Negative Consequences"},{"location":"adr/0027-cert-manager-for-certificate-management/#links","text":"<ul> <li>cert-manager</li> <li>Securing Ingress Resources</li> <li>ACME Issuers</li> <li>Let's Encrypt Docs</li> </ul>","title":"Links"},{"location":"adr/0028-use-markdown-architectural-decision-records/","text":"","title":"Use Markdown Architectural Decision Records"},{"location":"adr/0028-use-markdown-architectural-decision-records/#context-and-problem-statement","text":"<p>We want to record architectural decisions made in this project. Which format and structure should these records follow?</p>","title":"Context and Problem Statement"},{"location":"adr/0028-use-markdown-architectural-decision-records/#considered-options","text":"<ul> <li>MADR 2.1.2 \u2013 The Markdown Architectural Decision Records</li> <li>Michael Nygard's template \u2013 The first incarnation of the term \"ADR\"</li> <li>Sustainable Architectural Decisions \u2013 The Y-Statements</li> <li>Other templates listed at https://github.com/joelparkerhenderson/architecture_decision_record</li> <li>Formless \u2013 No conventions for file format and structure</li> </ul>","title":"Considered Options"},{"location":"adr/0028-use-markdown-architectural-decision-records/#decision-outcome","text":"<p>Chosen option: \"MADR 2.1.2\", because</p> <ul> <li>Implicit assumptions should be made explicit.   Design documentation is important to enable people understanding the decisions later on.   See also A rational design process: How and why to fake it.</li> <li>The MADR format is lean and fits our development style.</li> <li>The MADR structure is comprehensible and facilitates usage &amp; maintenance.</li> <li>The MADR project is vivid.</li> <li>Version 2.1.2 is the latest one available when starting to document ADRs.</li> </ul>","title":"Decision Outcome"},{"location":"adr/0029-tavros-as-a-single-tenant-platform/","text":"<ul> <li>Status: accepted</li> <li>Deciders: @jam01</li> <li>Date: 2020-11</li> </ul>","title":"Tavros as a Single Tenant Platform"},{"location":"adr/0029-tavros-as-a-single-tenant-platform/#context-and-problem-statement","text":"<p>A single platform for an indefinite amount of tenants would allow us to provide Tavros in a cloud 'as-a-service' offering to our customers, instead of only as managed services. However, there is an unknown complexity and level of effort behind multi-tenancy.</p>","title":"Context and Problem Statement"},{"location":"adr/0029-tavros-as-a-single-tenant-platform/#decision-drivers","text":"<ul> <li>Scope creep</li> <li>Speed of delivery</li> <li>Complexity</li> </ul>","title":"Decision Drivers"},{"location":"adr/0029-tavros-as-a-single-tenant-platform/#considered-options","text":"<ul> <li>Build multi-tenancy from the ground up</li> <li>Automated single-tenant offered as PaaS</li> </ul>","title":"Considered Options"},{"location":"adr/0029-tavros-as-a-single-tenant-platform/#decision-outcome","text":"<p>We'll build Tavros as a single tenant platform. The Ansible automation can be developed in a way that accommodates two modes of operation:</p> <ul> <li>Build a tavros cluster to be owned by the client and optionally operated by us, as was the original objective</li> <li>Build a tavros cluster to be owned and operated by us, transparently to the client.</li> </ul> <p>The second mode allows us to offer a PaaS while keeping the platform simple.</p>","title":"Decision Outcome"},{"location":"adr/0029-tavros-as-a-single-tenant-platform/#positive-consequences","text":"<ul> <li>Explicit separation to other clusters</li> <li>Simpler to build and consequently faster to deliver</li> <li>Can still offer as PaaS</li> </ul>","title":"Positive Consequences"},{"location":"adr/0029-tavros-as-a-single-tenant-platform/#negative-consequences","text":"<ul> <li>May complicate day-2 operations on multiple clusters at once</li> </ul>","title":"Negative Consequences"},{"location":"adr/template/","text":"<ul> <li>Status: [proposed | rejected | accepted | deprecated | \u2026 | superseded by ADR-0005] </li> <li>Deciders: [list everyone involved in the decision] </li> <li>Date: [YYYY-MM-DD when the decision was last updated] </li> </ul> <p>Technical Story: [description | ticket/issue URL] </p>","title":"[short title of solved problem and solution]"},{"location":"adr/template/#context-and-problem-statement","text":"<p>[Describe the context and problem statement, e.g., in free form using two to three sentences. You may want to articulate the problem in form of a question.]</p>","title":"Context and Problem Statement"},{"location":"adr/template/#decision-drivers","text":"<ul> <li>[driver 1, e.g., a force, facing concern, \u2026]</li> <li>[driver 2, e.g., a force, facing concern, \u2026]</li> <li>\u2026 </li> </ul>","title":"Decision Drivers"},{"location":"adr/template/#considered-options","text":"<ul> <li>[option 1]</li> <li>[option 2]</li> <li>[option 3]</li> <li>\u2026 </li> </ul>","title":"Considered Options"},{"location":"adr/template/#decision-outcome","text":"<p>Chosen option: \"[option 1]\", because [justification. e.g., only option, which meets k.o. criterion decision driver | which resolves force force | \u2026 | comes out best (see below)].</p>","title":"Decision Outcome"},{"location":"adr/template/#positive-consequences","text":"<ul> <li>[e.g., improvement of quality attribute satisfaction, follow-up decisions required, \u2026]</li> <li>\u2026</li> </ul>","title":"Positive Consequences"},{"location":"adr/template/#negative-consequences","text":"<ul> <li>[e.g., compromising quality attribute, follow-up decisions required, \u2026]</li> <li>\u2026</li> </ul>","title":"Negative Consequences"},{"location":"adr/template/#pros-and-cons-of-the-options","text":"","title":"Pros and Cons of the Options"},{"location":"adr/template/#option-1","text":"<p>[example | description | pointer to more information | \u2026] </p> <ul> <li>Good, because [argument a]</li> <li>Good, because [argument b]</li> <li>Bad, because [argument c]</li> <li>\u2026 </li> </ul>","title":"[option 1]"},{"location":"adr/template/#option-2","text":"<p>[example | description | pointer to more information | \u2026] </p> <ul> <li>Good, because [argument a]</li> <li>Good, because [argument b]</li> <li>Bad, because [argument c]</li> <li>\u2026 </li> </ul>","title":"[option 2]"},{"location":"adr/template/#option-3","text":"<p>[example | description | pointer to more information | \u2026] </p> <ul> <li>Good, because [argument a]</li> <li>Good, because [argument b]</li> <li>Bad, because [argument c]</li> <li>\u2026 </li> </ul>","title":"[option 3]"},{"location":"adr/template/#links","text":"<ul> <li>[Link type] [Link to ADR] </li> <li>\u2026 </li> </ul>","title":"Links"},{"location":"contribute/","text":"<p>We love your input! We want to make contributing to this project as easy and transparent as possible, whether it's:</p> <ul> <li>Reporting a bug</li> <li>Discussing the current state of the code</li> <li>Submitting a fix</li> <li>Proposing new features</li> <li>Becoming a maintainer</li> </ul>","title":"Contributing to Tavros"},{"location":"contribute/#we-develop-with-github","text":"<p>We use github to host code, to track issues and feature requests, as well as accept pull requests.</p>","title":"We Develop with Github"},{"location":"contribute/#we-use-github-flow-so-all-code-changes-happen-through-pull-requests","text":"<p>Pull requests are the best way to propose changes to the codebase (we use Github Flow). We actively welcome your pull requests:</p> <ol> <li>Fork the repo and create your branch from <code>master</code>.</li> <li>If you've added code that should be tested, add tests.</li> <li>If you've changed APIs, update the documentation.</li> <li>Ensure the test suite passes.</li> <li>Make sure your code lints.</li> <li>Issue that pull request!</li> </ol>","title":"We Use Github Flow, So All Code Changes Happen Through Pull Requests"},{"location":"contribute/#any-contributions-you-make-will-be-under-the-mit-software-license","text":"<p>In short, when you submit code changes, your submissions are understood to be under the same MIT License that covers the project. Feel free to contact the maintainers if that's a concern.</p>","title":"Any contributions you make will be under the MIT Software License"},{"location":"contribute/#report-bugs-using-githubs-issues","text":"<p>We use GitHub issues to track public bugs. Report a bug by opening a new issue; it's that easy!</p>","title":"Report bugs using Github's issues"},{"location":"contribute/#write-bug-reports-with-detail-background-and-sample-code","text":"<p>This is an example of a bug report I wrote, and I think it's not a bad model. Here's another example from Craig Hockenberry, an app developer whom I greatly respect.</p> <p>Great Bug Reports tend to have:</p> <ul> <li>A quick summary and/or background</li> <li>Steps to reproduce</li> <li>Be specific!</li> <li>Give sample code if you can. My stackoverflow question includes sample code that anyone with a base R setup can run to reproduce what I was seeing</li> <li>What you expected would happen</li> <li>What actually happens</li> <li>Notes (possibly including why you think this might be happening, or stuff you tried that didn't work)</li> </ul> <p>People love thorough bug reports. I'm not even kidding.</p>","title":"Write bug reports with detail, background, and sample code"},{"location":"contribute/#use-a-consistent-coding-style","text":"<p>I'm again borrowing these from Facebook's Guidelines</p> <ul> <li>2 spaces for indentation rather than tabs</li> <li>You can try running <code>npm run lint</code> for style unification</li> </ul>","title":"Use a Consistent Coding Style"},{"location":"contribute/#license","text":"<p>By contributing, you agree that your contributions will be licensed under its MIT License.</p>","title":"License"},{"location":"contribute/#references","text":"<p>This document was adapted from the open-source contribution guidelines for Facebook's Draft</p>","title":"References"},{"location":"contribute/developing/","text":"","title":"Developing using Docker"},{"location":"contribute/documentation/","text":"","title":"Documentation Guidelines"},{"location":"getting-started/installation/","text":"","title":"Getting started with Tavros"},{"location":"getting-started/installation/#prerequisites","text":"","title":"Prerequisites"},{"location":"getting-started/installation/#choose-a-supported-installation","text":"<p>Tavros is Kubernetes Native and will require Cluster access to provision the various components. You can utilize an existing Cluster or have Tavros provision a new one for you.</p> Existing K8sAKSAWS   <p>To install Tavros on an existing cluster it must meet the following requirements.</p> <ul> <li>K8s 1.19,1.20,1.21</li> <li>Has a default Storage Class </li> <li>Supports Service of Type Loadbalancer</li> </ul>   <p>Tavros will provision an Azure Kubernetes Service with a provided Azure user. Then install your chosen components. </p> <ul> <li>You will need an Azure account with an available Subcription capable of provisioning AKS Clusters, DNS Zones, Resource Groups, and Storage Accounts on demand.</li> </ul>   <p>Tavros will use KOps to provision K8s on Amazon Web Services. Then install your chosen components.</p>","title":"Choose a supported installation"},{"location":"getting-started/installation/#install-a-container-runtime","text":"<p>We provide a Tavros Collection image pre-installed with the latest version and required tooling. To utilize this you will need a Container Runtime such as Docker or Podman</p>","title":"Install a container runtime"},{"location":"getting-started/installation/#prepare-a-fqdn","text":"<p>Tavros requires a FQDN to be provided for its Root Domain. This allows the Gatway to expose deployed components via Sub Domains of the provided FQDN. DNS resolution for these various FQDNs will need to be configured for the corresponding IP of the Gateways LoadBalancer. </p>  <p>Note: If using a Cluster Provisioning Role such as <code>kops</code> or <code>aks</code> this will be configured for you. For installing to existing Clusters the DNS Role will output a list of DNS Records to be created manually durring Playbook execution. DNS Resolution is currently required for select components. Theirfor the DNS Role will wait for you to complete its setup in this case.</p>","title":"Prepare a FQDN"},{"location":"getting-started/installation/#installation","text":"","title":"Installation"},{"location":"getting-started/installation/#pull-the-tavros-collection","text":"<pre><code>docker pull ghcr.io/ms3inc/tavros-collection\n</code></pre>","title":"Pull the Tavros Collection"},{"location":"getting-started/installation/#create-a-working-directory","text":"<p>This folder will be used to provide your Tavros configuration files. The Tavros playbook will also use this directory to store provisoning logs, IAC, and credentials generated through the provisioning process. <pre><code>mkdir tavros\ncd tavros\n</code></pre></p>","title":"Create a working directory"},{"location":"getting-started/installation/#start-a-tavros-collection-instance","text":"<p>We'll mount our current directory into an interactive instance of the Tavros Collection. <pre><code>docker run -it --rm -v $PWD:/tmp/ -w /tmp/ ghcr.io/ms3inc/tavros-collection:latest\n</code></pre></p>","title":"Start a Tavros Collection instance"},{"location":"getting-started/installation/#prepare-deployment-environment","text":"Existing K8sAKSAWS   <p>For existing clusters you will need to provide the Tavros Collection with K8s access. This is done by providing a Kube config at <code>~/.kube/config</code> in the instance. </p>","title":"Prepare deployment environment"},{"location":"getting-started/installation/#provide-kube-config","text":"<p>You can do this by placing the config into the mounted working directory and then copying it to the correct location from the open bash shell. <pre><code>cp config ~/.kube/config\n</code></pre></p> <p>Validate this is succesfull by using <code>kubectl</code> <pre><code>kubectl get nodes -o wide\n</code></pre></p>   <p>When using Tavros to provision Azure Kubernetes Services you will need to login from the Tavros Collection Instance and create a few Azure resources.</p>","title":"Provide Kube Config"},{"location":"getting-started/installation/#login-to-azure","text":"<p>This will redirect you and output your Tennant and Subscription info. <pre><code>az login\n</code></pre></p>","title":"Login to Azure"},{"location":"getting-started/installation/#create-resource-group","text":"<p>This resrouce group will be used to namespace the Azure resource used. <pre><code>az group create -n tavros-aks --location eastus\n</code></pre></p>","title":"Create Resource Group"},{"location":"getting-started/installation/#create-storage-account","text":"<p>You'll also need to provide a storage location for your Tavros configuration. <pre><code>az storage account create -n &lt;tavros-storage&gt; -g tavros-aks\n</code></pre></p>","title":"Create Storage Account"},{"location":"getting-started/installation/#create-dns-zone","text":"<p>The DNS Zone will be used to map your FQDN to the IPs of your configured Gateways. <pre><code>az network dns zone create -n az.ms3-inc.com -g tavros-aks \n</code></pre></p>   <p>KOps Kubernetes on Amazon Web Services</p>","title":"Create DNS Zone"},{"location":"getting-started/installation/#iam","text":"<p>For Tavros cluster on AWS, IAM should be configured as follows: <pre><code>#!/bin/bash\naws iam create-group --group-name tavros-provisioner\n\u200b\n# required for kops\n# https://github.com/kubernetes/kops/blob/master/docs/getting_started/aws.md#setup-iam-user\naws iam attach-group-policy --policy-arn arn:aws:iam::aws:policy/AmazonEC2FullAccess --group-name tavros-provisioner\naws iam attach-group-policy --policy-arn arn:aws:iam::aws:policy/AmazonRoute53FullAccess --group-name tavros-provisioner\naws iam attach-group-policy --policy-arn arn:aws:iam::aws:policy/AmazonS3FullAccess --group-name tavros-provisioner\naws iam attach-group-policy --policy-arn arn:aws:iam::aws:policy/IAMFullAccess --group-name tavros-provisioner\naws iam attach-group-policy --policy-arn arn:aws:iam::aws:policy/AmazonVPCFullAccess --group-name tavros-provisioner\n\u200b\naws iam create-user --user-name tavros-ci\naws iam add-user-to-group --user-name tavros-ci --group-name tavros-provisioner\naws iam create-access-key --user-name tavros-ci\n</code></pre></p> <p>The resulting Access Key and Secret should be passed to the Ansible Playbook.</p> <p>For more detailed information see https://kops.sigs.k8s.io/getting_started/aws/</p>","title":"IAM"},{"location":"getting-started/installation/#route53","text":"<p>Route53 should manage the domain to be used for the cluster as a Hosted Zone. It is not necessary for Route53 to serve as the root domain registrar. For more information see Configuring Amazon Route 53 as your DNS service.</p> <p>For more detailed information see https://kops.sigs.k8s.io/getting_started/aws/</p>","title":"Route53"},{"location":"getting-started/installation/#select-a-base-inventory","text":"<p>Tavros is designed to use an Ansible Inventory for its base config. This file specifies default settings for each component in Tavros. We provide a set of Inventory files to choose from as your starting config.</p>  <ul> <li>Inventory files are documented in the reference docs for each Playbook. </li> <li>Advanced users may want to create custom Inventories to meet their needs</li> </ul>     Type Path Overview     <code>Minimal</code>     <code>Standard</code>     <code>Single</code>","title":"Select a base Inventory"},{"location":"getting-started/installation/#create-an-instance-config","text":"<p>You will need to create an instance configuration which overlays the base. At minimum you will need to provide a FQDN, Admin Email, and Credentials for accessing/generating the K8s Cluster.</p> Existing K8sAKSAWS   <pre><code>cluster_fqdn: k8s.ms3-inc.com\ncluster_admin_email: rmccright@ms3-inc.com\nkubernetes_cluster:\n    cloud_provider: 'existing'\nkops:\n    enabled: false \n</code></pre>   <pre><code>cluster_fqdn: az.ms3-inc.com\ncluster_admin_email: rmccright@ms3-inc.com\nkubernetes_cluster:\n    cloud_provider: 'aks'\nkops:\n    enabled: false \naks:\n    enabled: true\n    name: az-tavros\n    resource_group: tavros-aks\n    storage_account_name: tavros01234\n    node_count: 2\n    node_size: Standard_B4ms\n</code></pre>   <pre><code>cluster_fqdn: az.ms3-inc.com\ncluster_admin_email: rmccright@ms3-inc.com\n</code></pre>","title":"Create an Instance Config"},{"location":"getting-started/installation/#run-tavros","text":"<p>You can dry run first to make sure there are no issues with the Templeting phase <pre><code>ansible-playbook ms3_inc.tavros.provision_playbook.yaml -i &lt;inventory&gt; -e &lt;instance_config&gt; --tags all,dry-run | tee $(date '+%s')_tavros_dryrun.log\n</code></pre> Provision the Tavros Cluster by removing the <code>dry-run</code> tag. <pre><code>ansible-playbook ms3_inc.tavros.provision_playbook.yaml -i &lt;inventory&gt; -e &lt;instance_config&gt; --tags all | tee $(date '+%s')_tavros.log\n</code></pre> Optionaly you can use Staging Lets Encrypt certs by adding the <code>test-run</code> tag. <pre><code>ansible-playbook ms3_inc.tavros.provision_playbook.yaml -i &lt;inventory&gt; -e &lt;instance_config&gt; --tags all | tee $(date '+%s')_tavros_testrun.log\n</code></pre></p>","title":"Run Tavros"},{"location":"getting-started/installation/#track-install-progress","text":"<p>From here you can see the progress of the Tavros Playbook in the Tavros Collection stdout.</p> <p>You can also use <code>kubectl</code> to observe the progress. https://kubernetes.io/docs/tasks/tools/#kubectl</p> <p>Other tools such as <code>k9s</code> are useful for mirnigoring progress and interacting with the cluster. https://github.com/derailed/k9s</p>","title":"Track install progress"},{"location":"reference/overview/","text":"","title":"Playbooks and Roles Reference"},{"location":"reference/playbooks/provision_playbook/","text":"<ul> <li>Requirements</li> <li>For clusters on AWS<ul> <li>IAM</li> <li>Route53</li> </ul> </li> <li>Default Configuration</li> <li>Configuration Variables</li> <li>Kubernetes Cluster Object</li> <li>Kong Object</li> <li>Kong EE Credentials Object</li> <li>Image Registry Object</li> <li>Kong Instance Object</li> <li>Kong Instance EE Object</li> <li>Kuma Object</li> <li>Kuma Mesh Object</li> <li>Kuma mTLS Object</li> <li>Namespace Object</li> <li>Keycloak Object</li> <li>Nexus Object</li> <li>Elastic Cloud Object</li> <li>Gitea</li> <li>Jaeger</li> </ul> <p>Table of contents generated with markdown-toc</p> <p>This playbook will use provision a Kubernetes Cluster on AWS. It will then configure the platform components sequentially as configured, and finally commit all resource manifests to Git, for Flux to manage from that point on.</p> <p>The order of component configuration is as follows: * Flux v2 Toolkit - In order to provide platform GitOps * Kubeseal - In order to safely store secrets in GitOps * PostgreSQL - A central configuration database for multiple components * Namespaces - Application namespaced environments * Kuma - Service Meshes * cert-manager - TLS certificate manager for the given domain * Kong - As a API Gateway and Manager, with enterprise edition features if that is enabled * Keycloak - To provide Identity and Access Management, if enabled * Nexus - To provide repository for varios formats, if enabled * Elastic Cloud - To provide observability, if enabled * Gitea - To provide source control, if enabled * Jaeger - To provide observability, if enabled</p>","title":"Tavros Provision Playbook"},{"location":"reference/playbooks/provision_playbook/#requirements","text":"","title":"Requirements"},{"location":"reference/playbooks/provision_playbook/#for-clusters-on-aws","text":"","title":"For clusters on AWS"},{"location":"reference/playbooks/provision_playbook/#iam","text":"<p>For Tavros cluster on AWS, IAM should be configured as follows: <pre><code>#!/bin/bash\naws iam create-group --group-name tavros-provisioner\n\u200b\n# required for kops\n# https://github.com/kubernetes/kops/blob/master/docs/getting_started/aws.md#setup-iam-user\naws iam attach-group-policy --policy-arn arn:aws:iam::aws:policy/AmazonEC2FullAccess --group-name tavros-provisioner\naws iam attach-group-policy --policy-arn arn:aws:iam::aws:policy/AmazonRoute53FullAccess --group-name tavros-provisioner\naws iam attach-group-policy --policy-arn arn:aws:iam::aws:policy/AmazonS3FullAccess --group-name tavros-provisioner\naws iam attach-group-policy --policy-arn arn:aws:iam::aws:policy/IAMFullAccess --group-name tavros-provisioner\naws iam attach-group-policy --policy-arn arn:aws:iam::aws:policy/AmazonVPCFullAccess --group-name tavros-provisioner\n\u200b\naws iam create-user --user-name tavros-ci\naws iam add-user-to-group --user-name tavros-ci --group-name tavros-provisioner\naws iam create-access-key --user-name tavros-ci\n</code></pre></p> <p>The resulting Access Key and Secret should be passed to the Ansible Playbook.</p> <p>For more detailed information see https://kops.sigs.k8s.io/getting_started/aws/</p>","title":"IAM"},{"location":"reference/playbooks/provision_playbook/#route53","text":"<p>Route53 should manage the domain to be used for the cluster as a Hosted Zone. It is not necessary for Route53 to serve as the root domain registrar. For more information see Configuring Amazon Route 53 as your DNS service.</p> <p>For more detailed information see https://kops.sigs.k8s.io/getting_started/aws/</p>","title":"Route53"},{"location":"reference/playbooks/provision_playbook/#default-configuration","text":"<p>There is a default configuration vars file that results in the following: * A Kubernetes cluster on AWS with 3x T2.XLarge masters and 2x T2.Large worker nodes. * A single Keycloak instance with two realms: 'sandbox' and 'prod'. * 2x Kuma meshes: 'sandbox' and 'prod'. * 2x Kong ingress controllers: 'sandbox' and 'prod'. The ingress controllers are part of the Kuma meshes, respectively. * 3x application namespaced environments: 'dev', 'test', and 'prod'. 'dev' and 'test' belong to the 'sandbox' Kuma mesh, and 'prod' to the 'prod' Kuma mesh.</p> <p>To use the default configuration:</p> <pre><code>ansible-playbook playbooks/provision_playbook.yaml \\\n  --extra-vars '{\"cluster_name\":\"tavros\",\"cluster_domain\":\"example.com\",\"cluster_admin_email\":\"ops@example.com\"}' \\\n  --inventory \"playbooks/provision_playbook/default_vars.yaml\"\n</code></pre>","title":"Default Configuration"},{"location":"reference/playbooks/provision_playbook/#configuration-variables","text":"Field Name Type Description Default Value     cluster_name String Required The name of the Tavros Kubernetes cluster    cluster_domain String Required The domain name to use for the platform. This should be managed by the cloud provider chosen in order to setup routes and certificates    cluster_admin_email String Required The email for alerts and general notifications.    kubernetes_cluster Kubernetes Cluster Object Required Configuration for the Kubernetes Cluster to be provisioned    kong Kong Object Configuration for Kong    kuma Kuma Object Configuration for Kuma    namespaces [Namespace Object] An array of Namespace configurations    keycloak Keycloak Object Configuration for Keycloak","title":"Configuration Variables"},{"location":"reference/playbooks/provision_playbook/#kubernetes-cluster-object","text":"Field Name Type Description Default Value     cloud String The cloud provider to provision the cluster in 'aws'   master_count Integer The number of master nodes 3   master_size String The machine instance type for master nodes 'T2.Large'   node_count Integer The number of worker nodes 2   node_size String The machine instance type for worker nodes 'T2.XLarge'   zones String A comma separated list of availability zones in which to place the machines 'us-east-1,us-east-2'   state_bucket String The name of the S3 bucket to place the cluster state in 'troubaodur'   ssh_public_key String The SSH public key to setup as authorized user on provisioned machines read from ~/.ssh/id_rsa.pub   aws_access_key_id String The AWS IAM AccessKeyId uses aws cli logged in user   aws_secret_access_key The AWS IAM SecretAccessKey uses aws cli logged in user    keycloak Kubernetes Cluster Keycloak Object Keycloak Config { \"realm\": \"\", \"client_secret\": \"\" }","title":"Kubernetes Cluster Object"},{"location":"reference/playbooks/provision_playbook/#kubernetes-cluster-keycloak-object","text":"Field Name Type Description Default Value     realm String Keycloak Realm Name    client_secret String Client Secret","title":"Kubernetes Cluster Keycloak Object"},{"location":"reference/playbooks/provision_playbook/#kong-object","text":"Field Name Type Description Default Value     default_ingress_class String The default ingress controller class for other components to use 'prod'   ee_creds [Kong EE Credentials Object] An array of Kong Enterprise Edition Credentials available for Kong instances to use    instances [Kong Instance Object] An array of Kong instance object to be configured","title":"Kong Object"},{"location":"reference/playbooks/provision_playbook/#kong-ee-credentials-object","text":"Field Name Type Description Default Value     license String Required The Enterprise Edition license    name String Required Identifier for EE Kong Instance","title":"Kong EE Credentials Object"},{"location":"reference/playbooks/provision_playbook/#kong-instance-object","text":"Field Name Type Description Default Value     name String Required The name of the Kong instance    hybrid Boolean Required Deployment Type    ingress_class String Required  The name of the ingress class    kuma_mesh_name String The name of the Kuma mesh that the Kong instance should be part of    ee Kong Instance EE Object The EE configuration for the Kong instance","title":"Kong Instance Object"},{"location":"reference/playbooks/provision_playbook/#kong-instance-ee-object","text":"Field Name Type Description Default Value     enabled Boolean Whether to use Enterprise Edition false   creds String The name of the Kong EE Credentials resource to use 'default'   keycloak Kong Keycloak Object Keycloak Config { \"realm\": \"\", \"client_secret\": \"\" }","title":"Kong Instance EE Object"},{"location":"reference/playbooks/provision_playbook/#kong-keycloak-object","text":"Field Name Type Description Default Value     realm String Keycloak Realm Name    client_secret String Client Secret","title":"Kong Keycloak Object"},{"location":"reference/playbooks/provision_playbook/#kuma-object","text":"Field Name Type Description Default Value     meshes [Kuma Mesh Object] The Kuma mesh configuration object","title":"Kuma Object"},{"location":"reference/playbooks/provision_playbook/#kuma-mesh-object","text":"Field Name Type Description Default Value     name String Required The name of the Kuma mesh    mtls Kuma mTLS Object The mTLS configuration for the Kuma mesh","title":"Kuma Mesh Object"},{"location":"reference/playbooks/provision_playbook/#kuma-mtls-object","text":"Field Name Type Description Default Value     enabled Boolean Whether to enable mTLS false","title":"Kuma mTLS Object"},{"location":"reference/playbooks/provision_playbook/#namespace-object","text":"Field Name Type Description Default Value     name String Required The name of the Namespace    kuma_mesh_name String The name of the Kuma mesh this namespace should be a part of","title":"Namespace Object"},{"location":"reference/playbooks/provision_playbook/#keycloak-object","text":"Field Name Type Description Default Value     enabled Boolean Whether to use Keycloak true   realms Array of Keycloak Realms Object Enumeration of Desired Realms [{\"name\": \"sandbox\"}, {\"name\": \"prod\"}]","title":"Keycloak Object"},{"location":"reference/playbooks/provision_playbook/#keycloak-realms-object","text":"Field Name Type Description Default Value     name Boolean Whether to use Keycloak","title":"Keycloak Realms Object"},{"location":"reference/playbooks/provision_playbook/#nexus-object","text":"Field Name Type Description Default Value     enabled Boolean Whether to use Elastic Cloud true   keycloak Nexus Keycloak Object Keycloak Config { \"realm\": \"\", \"client_secret\": \"\" }","title":"Nexus Object"},{"location":"reference/playbooks/provision_playbook/#nexus-keycloak-object","text":"Field Name Type Description Default Value     realm String Keycloak Realm Name    client_secret String Client Secret","title":"Nexus Keycloak Object"},{"location":"reference/playbooks/provision_playbook/#elastic-cloud-object","text":"Field Name Type Description Default Value     enabled Boolean Whether to use Elastic Cloud true   ee Elastic Cloud EE Object EE Config { \"enabled\": false }","title":"Elastic Cloud Object"},{"location":"reference/playbooks/provision_playbook/#elastic-cloud-ee-object","text":"Field Name Type Description Default Value     enabled Boolean Whether to use EE    trial Boolean Whether to use 30 day cluster trial license    licnese String License JSON    keycloak Elastic Cloud Keycloak Object Keycloak Config { \"realm\": \"\", \"client_secret\": \"\" }","title":"Elastic Cloud EE Object"},{"location":"reference/playbooks/provision_playbook/#elastic-cloud-keycloak-object","text":"Field Name Type Description Default Value     realm String Keycloak Realm Name    client_secret String Client Secret","title":"Elastic Cloud Keycloak Object"},{"location":"reference/playbooks/provision_playbook/#gitea-object","text":"Field Name Type Description Default Value     enabled Boolean Whether to use Gitea true","title":"Gitea Object"},{"location":"reference/playbooks/provision_playbook/#jaeger-object","text":"Field Name Type Description Default Value     enabled Boolean Whether to use Jaeger true   keycloak Jaeger Keycloak Object Keycloak Config { \"realm\": \"\", \"client_secret\": \"\" }","title":"Jaeger Object"},{"location":"reference/playbooks/provision_playbook/#jaeger-keycloak-object","text":"Field Name Type Description Default Value     realm String Keycloak Realm Name    client_secret String Client Secret","title":"Jaeger Keycloak Object"},{"location":"reference/playbooks/provision_playbook/#jenkins-object","text":"Field Name Type Description Default Value     enabled Boolean Whether to use Jenkins true   keycloak Jenkins Keycloak Object Keycloak Config { \"realm\": \"\" }","title":"Jenkins Object"},{"location":"reference/playbooks/provision_playbook/#jenkins-keycloak-object","text":"Field Name Type Description Default Value     realm String Keycloak Realm Name","title":"Jenkins Keycloak Object"},{"location":"releases/0.1-NOTES/","text":"<p>All notable changes to this project will be documented in this file.</p> <p>The format is based on Keep a Changelog, and this project adheres to Semantic Versioning.</p>","title":"Changelog"},{"location":"releases/0.1-NOTES/#unreleased","text":"","title":"Unreleased"},{"location":"releases/0.1-NOTES/#010-2021-10-24","text":"","title":"0.1.0 - 2021-10-24"},{"location":"releases/0.1-NOTES/#added","text":"","title":"Added"},{"location":"releases/0.1-NOTES/#changed","text":"","title":"Changed"},{"location":"releases/0.1-NOTES/#removed","text":"","title":"Removed"},{"location":"support/","text":"<p>https://www.ms3-inc.com/</p>","title":"Enterprise Support"},{"location":"welcome/concepts/","text":"","title":"Tavros Core Concepts"},{"location":"welcome/concepts/#cloud-deployments","text":"","title":"Cloud Deployments"},{"location":"welcome/concepts/#infrastructure-networking","text":"","title":"Infrastructure Networking"},{"location":"welcome/concepts/#ansible","text":"","title":"Ansible"},{"location":"welcome/concepts/#kubernetes","text":"","title":"Kubernetes"},{"location":"welcome/concepts/#kustomize","text":"","title":"Kustomize"},{"location":"welcome/concepts/#helm","text":"","title":"Helm"},{"location":"welcome/license/","text":"<pre><code>                             Apache License\n                       Version 2.0, January 2004\n                    http://www.apache.org/licenses/\n</code></pre> <p>TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION</p> <ol> <li> <p>Definitions.</p> <p>\"License\" shall mean the terms and conditions for use, reproduction,   and distribution as defined by Sections 1 through 9 of this document.</p> <p>\"Licensor\" shall mean the copyright owner or entity authorized by   the copyright owner that is granting the License.</p> <p>\"Legal Entity\" shall mean the union of the acting entity and all   other entities that control, are controlled by, or are under common   control with that entity. For the purposes of this definition,   \"control\" means (i) the power, direct or indirect, to cause the   direction or management of such entity, whether by contract or   otherwise, or (ii) ownership of fifty percent (50%) or more of the   outstanding shares, or (iii) beneficial ownership of such entity.</p> <p>\"You\" (or \"Your\") shall mean an individual or Legal Entity   exercising permissions granted by this License.</p> <p>\"Source\" form shall mean the preferred form for making modifications,   including but not limited to software source code, documentation   source, and configuration files.</p> <p>\"Object\" form shall mean any form resulting from mechanical   transformation or translation of a Source form, including but   not limited to compiled object code, generated documentation,   and conversions to other media types.</p> <p>\"Work\" shall mean the work of authorship, whether in Source or   Object form, made available under the License, as indicated by a   copyright notice that is included in or attached to the work   (an example is provided in the Appendix below).</p> <p>\"Derivative Works\" shall mean any work, whether in Source or Object   form, that is based on (or derived from) the Work and for which the   editorial revisions, annotations, elaborations, or other modifications   represent, as a whole, an original work of authorship. For the purposes   of this License, Derivative Works shall not include works that remain   separable from, or merely link (or bind by name) to the interfaces of,   the Work and Derivative Works thereof.</p> <p>\"Contribution\" shall mean any work of authorship, including   the original version of the Work and any modifications or additions   to that Work or Derivative Works thereof, that is intentionally   submitted to Licensor for inclusion in the Work by the copyright owner   or by an individual or Legal Entity authorized to submit on behalf of   the copyright owner. For the purposes of this definition, \"submitted\"   means any form of electronic, verbal, or written communication sent   to the Licensor or its representatives, including but not limited to   communication on electronic mailing lists, source code control systems,   and issue tracking systems that are managed by, or on behalf of, the   Licensor for the purpose of discussing and improving the Work, but   excluding communication that is conspicuously marked or otherwise   designated in writing by the copyright owner as \"Not a Contribution.\"</p> <p>\"Contributor\" shall mean Licensor and any individual or Legal Entity   on behalf of whom a Contribution has been received by Licensor and   subsequently incorporated within the Work.</p> </li> <li> <p>Grant of Copyright License. Subject to the terms and conditions of       this License, each Contributor hereby grants to You a perpetual,       worldwide, non-exclusive, no-charge, royalty-free, irrevocable       copyright license to reproduce, prepare Derivative Works of,       publicly display, publicly perform, sublicense, and distribute the       Work and such Derivative Works in Source or Object form.</p> </li> <li> <p>Grant of Patent License. Subject to the terms and conditions of       this License, each Contributor hereby grants to You a perpetual,       worldwide, non-exclusive, no-charge, royalty-free, irrevocable       (except as stated in this section) patent license to make, have made,       use, offer to sell, sell, import, and otherwise transfer the Work,       where such license applies only to those patent claims licensable       by such Contributor that are necessarily infringed by their       Contribution(s) alone or by combination of their Contribution(s)       with the Work to which such Contribution(s) was submitted. If You       institute patent litigation against any entity (including a       cross-claim or counterclaim in a lawsuit) alleging that the Work       or a Contribution incorporated within the Work constitutes direct       or contributory patent infringement, then any patent licenses       granted to You under this License for that Work shall terminate       as of the date such litigation is filed.</p> </li> <li> <p>Redistribution. You may reproduce and distribute copies of the       Work or Derivative Works thereof in any medium, with or without       modifications, and in Source or Object form, provided that You       meet the following conditions:</p> <p>(a) You must give any other recipients of the Work or       Derivative Works a copy of this License; and</p> <p>(b) You must cause any modified files to carry prominent notices       stating that You changed the files; and</p> <p>(c) You must retain, in the Source form of any Derivative Works       that You distribute, all copyright, patent, trademark, and       attribution notices from the Source form of the Work,       excluding those notices that do not pertain to any part of       the Derivative Works; and</p> <p>(d) If the Work includes a \"NOTICE\" text file as part of its       distribution, then any Derivative Works that You distribute must       include a readable copy of the attribution notices contained       within such NOTICE file, excluding those notices that do not       pertain to any part of the Derivative Works, in at least one       of the following places: within a NOTICE text file distributed       as part of the Derivative Works; within the Source form or       documentation, if provided along with the Derivative Works; or,       within a display generated by the Derivative Works, if and       wherever such third-party notices normally appear. The contents       of the NOTICE file are for informational purposes only and       do not modify the License. You may add Your own attribution       notices within Derivative Works that You distribute, alongside       or as an addendum to the NOTICE text from the Work, provided       that such additional attribution notices cannot be construed       as modifying the License.</p> <p>You may add Your own copyright statement to Your modifications and   may provide additional or different license terms and conditions   for use, reproduction, or distribution of Your modifications, or   for any such Derivative Works as a whole, provided Your use,   reproduction, and distribution of the Work otherwise complies with   the conditions stated in this License.</p> </li> <li> <p>Submission of Contributions. Unless You explicitly state otherwise,       any Contribution intentionally submitted for inclusion in the Work       by You to the Licensor shall be under the terms and conditions of       this License, without any additional terms or conditions.       Notwithstanding the above, nothing herein shall supersede or modify       the terms of any separate license agreement you may have executed       with Licensor regarding such Contributions.</p> </li> <li> <p>Trademarks. This License does not grant permission to use the trade       names, trademarks, service marks, or product names of the Licensor,       except as required for reasonable and customary use in describing the       origin of the Work and reproducing the content of the NOTICE file.</p> </li> <li> <p>Disclaimer of Warranty. Unless required by applicable law or       agreed to in writing, Licensor provides the Work (and each       Contributor provides its Contributions) on an \"AS IS\" BASIS,       WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or       implied, including, without limitation, any warranties or conditions       of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A       PARTICULAR PURPOSE. You are solely responsible for determining the       appropriateness of using or redistributing the Work and assume any       risks associated with Your exercise of permissions under this License.</p> </li> <li> <p>Limitation of Liability. In no event and under no legal theory,       whether in tort (including negligence), contract, or otherwise,       unless required by applicable law (such as deliberate and grossly       negligent acts) or agreed to in writing, shall any Contributor be       liable to You for damages, including any direct, indirect, special,       incidental, or consequential damages of any character arising as a       result of this License or out of the use or inability to use the       Work (including but not limited to damages for loss of goodwill,       work stoppage, computer failure or malfunction, or any and all       other commercial damages or losses), even if such Contributor       has been advised of the possibility of such damages.</p> </li> <li> <p>Accepting Warranty or Additional Liability. While redistributing       the Work or Derivative Works thereof, You may choose to offer,       and charge a fee for, acceptance of support, warranty, indemnity,       or other liability obligations and/or rights consistent with this       License. However, in accepting such obligations, You may act only       on Your own behalf and on Your sole responsibility, not on behalf       of any other Contributor, and only if You agree to indemnify,       defend, and hold each Contributor harmless for any liability       incurred by, or claims asserted against, such Contributor by reason       of your accepting any such warranty or additional liability.</p> </li> </ol> <p>END OF TERMS AND CONDITIONS</p> <p>APPENDIX: How to apply the Apache License to your work.</p> <pre><code>  To apply the Apache License to your work, attach the following\n  boilerplate notice, with the fields enclosed by brackets \"[]\"\n  replaced with your own identifying information. (Don't include\n  the brackets!)  The text should be enclosed in the appropriate\n  comment syntax for the file format. We also recommend that a\n  file or class name and description of purpose be included on the\n  same \"printed page\" as the copyright notice for easier\n  identification within third-party archives.\n</code></pre> <p>Copyright [yyyy] [name of copyright owner]</p> <p>Licensed under the Apache License, Version 2.0 (the \"License\");    you may not use this file except in compliance with the License.    You may obtain a copy of the License at</p> <pre><code>   http://www.apache.org/licenses/LICENSE-2.0\n</code></pre> <p>Unless required by applicable law or agreed to in writing, software    distributed under the License is distributed on an \"AS IS\" BASIS,    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.    See the License for the specific language governing permissions and    limitations under the License.</p>","title":"License"}]}